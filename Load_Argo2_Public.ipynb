{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        if normalized:\n",
    "            mean = np.mean(trajectories, axis=0)\n",
    "            std = np.std(trajectories, axis=0)\n",
    "            trajectories = (trajectories - mean) / std\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for trajectory in trajectories:\n",
    "            for i in range(trajectory.shape[0] - 50):\n",
    "                inputs.append(trajectory[i:i+50])\n",
    "                outputs.append(trajectory[i+50])\n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "# intialize each dataset\n",
    "# train_austin = ArgoverseDataset(city = \"austin\", split = \"train\")\n",
    "# train_miami = ArgoverseDataset(city = \"miami\", split = \"train\")\n",
    "train_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"train\")\n",
    "# train_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"train\")\n",
    "# train_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"train\")\n",
    "# train_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"train\")\n",
    "\n",
    "# austin_mean, austin_std = train_austin.get_mean_std()[0][0]\n",
    "# miami_mean, miami_std = train_miami.get_mean_std()[0][0]\n",
    "palo_alto_mean, palo_alto_std = train_palo_alto.get_mean_std()[0][0]\n",
    "# pittsburgh_mean, pittsburgh_std = train_pittsburgh.get_mean_std()[0][0]\n",
    "# dearborn_mean, dearborn_std = train_dearborn.get_mean_std()[0][0]\n",
    "# washington_dc_mean, washington_dc_std = train_washington_dc.get_mean_std()[0][0]\n",
    "\n",
    "# test_austin = ArgoverseDataset(city = \"austin\", split = \"test\")\n",
    "# test_miami = ArgoverseDataset(city = \"miami\", split = \"test\")\n",
    "test_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"test\")\n",
    "# test_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"test\")\n",
    "# test_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"test\")\n",
    "# test_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "# train_austin, val_austin = torch.utils.data.random_split(train_austin, [len(train_austin) - len(train_austin)//5, len(train_austin)//5])\n",
    "# train_miami, val_miami = torch.utils.data.random_split(train_miami, [len(train_miami) - len(train_miami)//5, len(train_miami)//5])\n",
    "train_palo_alto, val_palo_alto = torch.utils.data.random_split(train_palo_alto, [len(train_palo_alto) - len(train_palo_alto)//5, len(train_palo_alto)//5])\n",
    "# train_pittsburgh, val_pittsburgh = torch.utils.data.random_split(train_pittsburgh, [len(train_pittsburgh) - len(train_pittsburgh)//5, len(train_pittsburgh)//5])\n",
    "# train_dearborn, val_dearborn = torch.utils.data.random_split(train_dearborn, [len(train_dearborn) - len(train_dearborn)//5, len(train_dearborn)//5])\n",
    "# train_washington_dc, val_washington_dc = torch.utils.data.random_split(train_washington_dc, [len(train_washington_dc) - len(train_washington_dc)//5, len(train_washington_dc)//5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 10  # batch size \n",
    "train_loader = DataLoader(train_palo_alto,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(val_palo_alto,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_palo_alto,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,0], out[i,1], c='r')\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 50: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a53b5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c6a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=512, num_layers=3, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(512, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(256, 2)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, h, c\n",
    "\n",
    "    def predict(self, x, h=None, c=None):\n",
    "        output, h, c = self.forward(x, h, c)\n",
    "        output = output[-1]\n",
    "        output = output.cpu().detach().numpy()\n",
    "            \n",
    "        return output, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf38ed7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e605e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp = inp.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            output = output[:, -1, :]\n",
    "            loss = loss_fn(output, label)\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(val_loader)}, Loss: {loss.item()}\")\n",
    "            break\n",
    "\n",
    "torch.save(lstm.state_dict(), \"models/palo_alto_model.pt\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae6203",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de312802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=3, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(\"models/palo_alto_model.pt\", map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac0370",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a571d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    x = x.to(device)\n",
    "    x = x.float()\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        elem = output[:, -1, :]\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "        x = output\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9c395",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15b2920a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=2'>3</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m palo_alto_mean) \u001b[39m/\u001b[39m palo_alto_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=3'>4</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m palo_alto_std \u001b[39m+\u001b[39m palo_alto_mean\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=5'>6</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=9'>10</a>\u001b[0m     elem \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=19'>20</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, inp in enumerate(test_loader):\n",
    "    inp = inp.to(device)\n",
    "    inp = (inp - palo_alto_mean) / palo_alto_std\n",
    "    inp = inp.float()\n",
    "    output = sample(inp, lstm)\n",
    "\n",
    "    output = np.array(output)\n",
    "    output = output * palo_alto_std + palo_alto_mean\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(output[:, 0], output[:, 1], c='r')\n",
    "    plt.savefig(f\"outputs/palo_alto_prediction_{i}.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfaea13b2c70b10e61fc5114159871c988fdb8a8d57529e1e6239db333764196"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
