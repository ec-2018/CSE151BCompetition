{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129123, 50, 2) (129123, 2)\n",
      "(29843, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        if normalized:\n",
    "            mean = np.mean(trajectories, axis=0)\n",
    "            std = np.std(trajectories, axis=0)\n",
    "            trajectories = (trajectories - mean) / std\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for trajectory in trajectories:\n",
    "            for i in range(0, trajectory.shape[0] - 50, 25):\n",
    "                inputs.append(trajectory[i:i+50])\n",
    "                outputs.append(trajectory[i+50])\n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=\"austin\", split=\"train\")\n",
    "# train_austin = ArgoverseDataset(city = \"austin\", split = \"train\")\n",
    "# train_miami = ArgoverseDataset(city = \"miami\", split = \"train\")\n",
    "# train_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"train\")\n",
    "# train_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"train\")\n",
    "# train_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"train\")\n",
    "# train_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"train\")\n",
    "\n",
    "data_mean, data_std = train_dataset.get_mean_std()[0][0]\n",
    "# austin_mean, austin_std = train_austin.get_mean_std()[0][0]\n",
    "# miami_mean, miami_std = train_miami.get_mean_std()[0][0]\n",
    "# palo_alto_mean, palo_alto_std = train_palo_alto.get_mean_std()[0][0]\n",
    "# pittsburgh_mean, pittsburgh_std = train_pittsburgh.get_mean_std()[0][0]\n",
    "# dearborn_mean, dearborn_std = train_dearborn.get_mean_std()[0][0]\n",
    "# washington_dc_mean, washington_dc_std = train_washington_dc.get_mean_std()[0][0]\n",
    "\n",
    "test_dataset = ArgoverseDataset(city=\"all\", split=\"test\")\n",
    "# test_austin = ArgoverseDataset(city = \"austin\", split = \"test\")\n",
    "# test_miami = ArgoverseDataset(city = \"miami\", split = \"test\")\n",
    "# test_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"test\")\n",
    "# test_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"test\")\n",
    "# test_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"test\")\n",
    "# test_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "# train_austin, val_austin = torch.utils.data.random_split(train_austin, [len(train_austin) - len(train_austin)//5, len(train_austin)//5])\n",
    "# train_miami, val_miami = torch.utils.data.random_split(train_miami, [len(train_miami) - len(train_miami)//5, len(train_miami)//5])\n",
    "# train_palo_alto, val_palo_alto = torch.utils.data.random_split(train_palo_alto, [len(train_palo_alto) - len(train_palo_alto)//5, len(train_palo_alto)//5])\n",
    "# train_pittsburgh, val_pittsburgh = torch.utils.data.random_split(train_pittsburgh, [len(train_pittsburgh) - len(train_pittsburgh)//5, len(train_pittsburgh)//5])\n",
    "# train_dearborn, val_dearborn = torch.utils.data.random_split(train_dearborn, [len(train_dearborn) - len(train_dearborn)//5, len(train_dearborn)//5])\n",
    "# train_washington_dc, val_washington_dc = torch.utils.data.random_split(train_washington_dc, [len(train_washington_dc) - len(train_washington_dc)//5, len(train_washington_dc)//5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 10  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,0], out[i,1], c='r')\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a53b5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56c6a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=512, num_layers=3, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(512, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(256, 2)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, h, c\n",
    "\n",
    "    def predict(self, x, h=None, c=None):\n",
    "        output, h, c = self.forward(x, h, c)\n",
    "        output = output[-1]\n",
    "        output = output.cpu().detach().numpy()\n",
    "            \n",
    "        return output, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf38ed7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e605e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            output = output[:, -1, :]\n",
    "            loss = loss_fn(output, label)\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(val_loader)}, Loss: {loss.item()}\")\n",
    "            break\n",
    "\n",
    "torch.save(lstm.state_dict(), \"models/palo_alto_model.pt\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae6203",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de312802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=3, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(\"models/palo_alto_model.pt\", map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac0370",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    x = x.to(device)\n",
    "    x = x.float()\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        elem = output[:, -1, :]\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "        x = output\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9c395",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2920a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=2'>3</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m palo_alto_mean) \u001b[39m/\u001b[39m palo_alto_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=3'>4</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m palo_alto_std \u001b[39m+\u001b[39m palo_alto_mean\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=5'>6</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=9'>10</a>\u001b[0m     elem \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=19'>20</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, inp in enumerate(test_loader):\n",
    "    inp = inp.to(device)\n",
    "    inp = (inp - palo_alto_mean) / palo_alto_std\n",
    "    inp = inp.float()\n",
    "    output = sample(inp, lstm)\n",
    "\n",
    "    output = np.array(output)\n",
    "    output = output * palo_alto_std + palo_alto_mean\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(output[:, 0], output[:, 1], c='r')\n",
    "    plt.savefig(f\"outputs/palo_alto_prediction_{i}.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
