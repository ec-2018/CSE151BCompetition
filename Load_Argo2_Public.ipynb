{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9791bc6e",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8cf13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1d132",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6df1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11993, 50, 2) (11993, 60, 2)\n",
      "(1686, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\"):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        # trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        # trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        # trajectories = trajectories.astype(np.float32)\n",
    "            \n",
    "        # inputs = []\n",
    "        # outputs = []\n",
    "        # for trajectory in trajectories:\n",
    "        #     inputs.append(trajectory[0:109])\n",
    "        #     outputs.append(trajectory[1:110])\n",
    "                \n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "curr_city = cities[5]\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=curr_city, split=\"train\")\n",
    "test_dataset = ArgoverseDataset(city=curr_city, split=\"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbacf98",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13a6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4e2ea",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d040b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='r', s=20)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='b', s=20)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852f474",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "855d92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.output_size = 60\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=256, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(256, 128)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(128, self.output_size*2)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        input_offset =  x[:,0,:].unsqueeze(1).repeat(1,x.size(1),1)\n",
    "        output_offset = x[:,0,:].unsqueeze(1).repeat(1,self.output_size,1)\n",
    "        x = x - input_offset\n",
    "        x, (h, c) = self.lstm(x)  \n",
    "        # Take last element of the sequence\n",
    "        x = x[:,-1,:]\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        # reshape\n",
    "        x = x.view(x.size(0), -1, 2)\n",
    "        x = x + output_offset\n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9639d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "609e6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Batch: 10/2399, Loss: 43.42970657348633\n",
      "Epoch: 1/200, Batch: 20/2399, Loss: 9.601761817932129\n",
      "Epoch: 1/200, Batch: 30/2399, Loss: 10.507905960083008\n",
      "Epoch: 1/200, Batch: 40/2399, Loss: 27.44137954711914\n",
      "Epoch: 1/200, Batch: 50/2399, Loss: 29.62881851196289\n",
      "Epoch: 1/200, Batch: 60/2399, Loss: 25.122888565063477\n",
      "Epoch: 1/200, Batch: 70/2399, Loss: 19.59554100036621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.25, verbose=True)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1, 1):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output = lstm(inp.float())\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch: {epoch}/{num_epochs}, Val Loss: {val_loss}\")\n",
    "\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "torch.save(lstm.state_dict(), f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e9c24",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(f, map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c1a47",
   "metadata": {},
   "source": [
    "## Validation Data Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_outputs = []\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, label = sample_batch\n",
    "    inp = inp.to(device)\n",
    "    output = lstm(inp.float())\n",
    "    validation_outputs.append((inp.cpu().numpy(), output.detach().cpu().numpy(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation results     \n",
    "data = validation_outputs[0]\n",
    "inp, output, label = data\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "plt.plot(label[0,:,0], label[0,:,1], c='b', label=\"Ground Truth\")\n",
    "plt.plot(output[0,:,0], output[0,:,1], c='g', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21917c88",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbb2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m austin_mean) \u001b[39m/\u001b[39m austin_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m austin_std \u001b[39m+\u001b[39m austin_mean     \n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=3'>4</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=5'>6</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=6'>7</a>\u001b[0m     \u001b[39m# if i == 0:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=7'>8</a>\u001b[0m     \u001b[39m#     print(x[0][40:-1], output[0][40:-1])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = f\"{curr_city}_trajectory.csv\"\n",
    "\n",
    "with open(f, \"w\") as f:\n",
    "    for i, inp in enumerate(test_loader):\n",
    "        inp = inp.to(device)\n",
    "        inp = inp.float()\n",
    "        output = lstm(inp)\n",
    "\n",
    "        output = np.array(output)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        inp = inp.squeeze().detach().cpu().numpy()\n",
    "        output = output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            plt.figure(figsize=(15, 3))\n",
    "            plt.scatter(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "            plt.scatter(output[:,0], output[:,1], c='g', label=\"Prediction\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{curr_city}_trajectory_{i}.png\")\n",
    "\n",
    "        f.write(f\"{i}_{curr_city}\")\n",
    "        for pos in output:\n",
    "            f.write(f\",{pos[0]},{pos[1]}\")\n",
    "        f.write(\"\\n\")\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(test_loader)}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
