{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9791bc6e",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8cf13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1d132",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6df1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11993, 109, 2) (11993, 109, 2)\n",
      "(1686, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\"):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "            \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for trajectory in trajectories:\n",
    "            inputs.append(trajectory[0:109])\n",
    "            outputs.append(trajectory[1:110])\n",
    "                \n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "curr_city = cities[5]\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=curr_city, split=\"train\")\n",
    "test_dataset = ArgoverseDataset(city=curr_city, split=\"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbacf98",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13a6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4e2ea",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d040b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='r', s=20)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='b', s=20)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852f474",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855d92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=256, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(256, 128)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        offset =  x[:,0,:].unsqueeze(1).repeat(1,x.size(1),1)\n",
    "        x = x - offset\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        x = x + offset\n",
    "        return x, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9639d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609e6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Batch: 10/2399, Loss: 38.00171661376953\n",
      "Epoch: 1/200, Batch: 20/2399, Loss: 15.152118682861328\n",
      "Epoch: 1/200, Batch: 30/2399, Loss: 25.888534545898438\n",
      "Epoch: 1/200, Batch: 40/2399, Loss: 37.764549255371094\n",
      "Epoch: 1/200, Batch: 50/2399, Loss: 30.85585594177246\n",
      "Epoch: 1/200, Batch: 60/2399, Loss: 23.08806610107422\n",
      "Epoch: 1/200, Batch: 70/2399, Loss: 32.00446701049805\n",
      "Epoch: 1/200, Batch: 80/2399, Loss: 29.849929809570312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.25, verbose=True)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1, 1):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch: {epoch}/{num_epochs}, Val Loss: {val_loss}\")\n",
    "\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "torch.save(lstm.state_dict(), f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e9c24",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(f, map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c1a47",
   "metadata": {},
   "source": [
    "## Validation Data Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_outputs = []\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, label = sample_batch\n",
    "    inp = inp.to(device)\n",
    "    output, h, c = lstm(inp.float())\n",
    "    validation_outputs.append((inp.cpu().numpy(), output.detach().cpu().numpy(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation results     \n",
    "data = validation_outputs[0]\n",
    "inp, output, label = data\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "plt.plot(label[0,:,0], label[0,:,1], c='b', label=\"Ground Truth\")\n",
    "plt.plot(output[0,:,0], output[0,:,1], c='g', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b363f4",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e551d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        elem = output[:, -1, :]\n",
    "        x = elem.unsqueeze(1)\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21917c88",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbb2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m austin_mean) \u001b[39m/\u001b[39m austin_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m austin_std \u001b[39m+\u001b[39m austin_mean     \n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=3'>4</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=5'>6</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=6'>7</a>\u001b[0m     \u001b[39m# if i == 0:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=7'>8</a>\u001b[0m     \u001b[39m#     print(x[0][40:-1], output[0][40:-1])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = f\"{curr_city}_trajectory.csv\"\n",
    "\n",
    "with open(f, \"w\") as f:\n",
    "    for i, inp in enumerate(test_loader):\n",
    "        inp = inp.to(device)\n",
    "        inp = inp.float()\n",
    "        output = sample(inp, lstm)\n",
    "\n",
    "        output = np.array(output)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            plt.figure(figsize=(15, 3))\n",
    "            plt.scatter(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "            plt.scatter(output[:,0], output[:,1], c='g', label=\"Prediction\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{curr_city}_trajectory_{i}.png\")\n",
    "\n",
    "        f.write(f\"{i}_{curr_city}\")\n",
    "        for pos in output:\n",
    "            f.write(f\",{pos[0]},{pos[1]}\")\n",
    "        f.write(\"\\n\")\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(test_loader)}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
