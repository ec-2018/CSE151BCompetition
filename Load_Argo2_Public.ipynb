{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43041, 50, 2) (43041, 60, 2)\n",
      "(6325, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        if normalized:\n",
    "            mean = np.mean(trajectories, axis=0)\n",
    "            std = np.std(trajectories, axis=0)\n",
    "            trajectories = (trajectories - mean) / std\n",
    "            mean = mean[0]\n",
    "            std = std[0]\n",
    "\n",
    "        inputs = [trajectory[:50] for trajectory in trajectories]\n",
    "        outputs = [trajectory[50:] for trajectory in trajectories]\n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "# intialize each dataset\n",
    "# train_dataset = ArgoverseDataset(city=\"all\", split=\"train\")\n",
    "train_austin = ArgoverseDataset(city = \"austin\", split = \"train\")\n",
    "# train_miami = ArgoverseDataset(city = \"miami\", split = \"train\")\n",
    "# train_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"train\")\n",
    "# train_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"train\")\n",
    "# train_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"train\")\n",
    "# train_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"train\")\n",
    "\n",
    "# data_mean, data_std = train_dataset.get_mean_std()\n",
    "austin_mean, austin_std = train_austin.get_mean_std()\n",
    "# miami_mean, miami_std = train_miami.get_mean_std()\n",
    "# palo_alto_mean, palo_alto_std = train_palo_alto.get_mean_std()\n",
    "# pittsburgh_mean, pittsburgh_std = train_pittsburgh.get_mean_std()\n",
    "# dearborn_mean, dearborn_std = train_dearborn.get_mean_std()\n",
    "# washington_dc_mean, washington_dc_std = train_washington_dc.get_mean_std()\n",
    "\n",
    "# test_dataset = ArgoverseDataset(city=\"all\", split=\"test\")\n",
    "test_austin = ArgoverseDataset(city = \"austin\", split = \"test\")\n",
    "# test_miami = ArgoverseDataset(city = \"miami\", split = \"test\")\n",
    "# test_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"test\")\n",
    "# test_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"test\")\n",
    "# test_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"test\")\n",
    "# test_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_austin))\n",
    "valid_size = len(train_austin) - train_size\n",
    "# train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "train_austin, val_austin = torch.utils.data.random_split(train_austin, [train_size, valid_size])\n",
    "# train_miami, val_miami = torch.utils.data.random_split(train_miami, [train_size, valid_size])\n",
    "# train_palo_alto, val_palo_alto = torch.utils.data.random_split(train_palo_alto, [train_size, valid_size])\n",
    "# train_pittsburgh, val_pittsburgh = torch.utils.data.random_split(train_pittsburgh, [train_size, valid_size])\n",
    "# train_dearborn, val_dearborn = torch.utils.data.random_split(train_dearborn, [train_size, valid_size])\n",
    "# train_washington_dc, val_washington_dc = torch.utils.data.random_split(train_washington_dc, [train_size, valid_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 10  # batch size \n",
    "train_loader = DataLoader(train_austin,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(val_austin,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_austin,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='b', s=20)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='r', s=20)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a53b5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56c6a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Linear(100, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(256, 120)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        # flatten from [[x, y], [x, y]] to [x, y, x, y]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf38ed7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e605e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/8, Batch: 10/3444, Loss: 0.1577601432800293\n",
      "Epoch: 0/8, Batch: 20/3444, Loss: 0.28750747442245483\n",
      "Epoch: 0/8, Batch: 30/3444, Loss: 0.04756075516343117\n",
      "Epoch: 0/8, Batch: 40/3444, Loss: 0.10290727019309998\n",
      "Epoch: 0/8, Batch: 50/3444, Loss: 0.07102913409471512\n",
      "Epoch: 0/8, Batch: 60/3444, Loss: 0.03879563510417938\n",
      "Epoch: 0/8, Batch: 70/3444, Loss: 0.06346163153648376\n",
      "Epoch: 0/8, Batch: 80/3444, Loss: 0.08752886205911636\n",
      "Epoch: 0/8, Batch: 90/3444, Loss: 0.026569757610559464\n",
      "Epoch: 0/8, Batch: 100/3444, Loss: 0.07012912631034851\n",
      "Epoch: 0/8, Batch: 110/3444, Loss: 0.04567433521151543\n",
      "Epoch: 0/8, Batch: 120/3444, Loss: 0.04153496399521828\n",
      "Epoch: 0/8, Batch: 130/3444, Loss: 0.037748921662569046\n",
      "Epoch: 0/8, Batch: 140/3444, Loss: 0.03215893357992172\n",
      "Epoch: 0/8, Batch: 150/3444, Loss: 0.022990437224507332\n",
      "Epoch: 0/8, Batch: 160/3444, Loss: 0.025638489052653313\n",
      "Epoch: 0/8, Batch: 170/3444, Loss: 0.018393144011497498\n",
      "Epoch: 0/8, Batch: 180/3444, Loss: 0.04570711776614189\n",
      "Epoch: 0/8, Batch: 190/3444, Loss: 0.03780302405357361\n",
      "Epoch: 0/8, Batch: 200/3444, Loss: 0.027670226991176605\n",
      "Epoch: 0/8, Batch: 210/3444, Loss: 0.0395243838429451\n",
      "Epoch: 0/8, Batch: 220/3444, Loss: 0.043012041598558426\n",
      "Epoch: 0/8, Batch: 230/3444, Loss: 0.029449036344885826\n",
      "Epoch: 0/8, Batch: 240/3444, Loss: 0.02567044459283352\n",
      "Epoch: 0/8, Batch: 250/3444, Loss: 0.026284629479050636\n",
      "Epoch: 0/8, Batch: 260/3444, Loss: 0.024750614538788795\n",
      "Epoch: 0/8, Batch: 270/3444, Loss: 0.059723611921072006\n",
      "Epoch: 0/8, Batch: 280/3444, Loss: 0.1100524365901947\n",
      "Epoch: 0/8, Batch: 290/3444, Loss: 0.02619362808763981\n",
      "Epoch: 0/8, Batch: 300/3444, Loss: 0.05735212191939354\n",
      "Epoch: 0/8, Batch: 310/3444, Loss: 0.03730686381459236\n",
      "Epoch: 0/8, Batch: 320/3444, Loss: 0.018745282664895058\n",
      "Epoch: 0/8, Batch: 330/3444, Loss: 0.03684871271252632\n",
      "Epoch: 0/8, Batch: 340/3444, Loss: 0.007993009872734547\n",
      "Epoch: 0/8, Batch: 350/3444, Loss: 0.057731565088033676\n",
      "Epoch: 0/8, Batch: 360/3444, Loss: 0.038319770246744156\n",
      "Epoch: 0/8, Batch: 370/3444, Loss: 0.03038983978331089\n",
      "Epoch: 0/8, Batch: 380/3444, Loss: 0.019183073192834854\n",
      "Epoch: 0/8, Batch: 390/3444, Loss: 0.05353225767612457\n",
      "Epoch: 0/8, Batch: 400/3444, Loss: 0.035595059394836426\n",
      "Epoch: 0/8, Batch: 410/3444, Loss: 0.04499617591500282\n",
      "Epoch: 0/8, Batch: 420/3444, Loss: 0.0858214795589447\n",
      "Epoch: 0/8, Batch: 430/3444, Loss: 0.045783501118421555\n",
      "Epoch: 0/8, Batch: 440/3444, Loss: 0.051694534718990326\n",
      "Epoch: 0/8, Batch: 450/3444, Loss: 0.011940174736082554\n",
      "Epoch: 0/8, Batch: 460/3444, Loss: 0.059970200061798096\n",
      "Epoch: 0/8, Batch: 470/3444, Loss: 0.031701747328042984\n",
      "Epoch: 0/8, Batch: 480/3444, Loss: 0.03242214769124985\n",
      "Epoch: 0/8, Batch: 490/3444, Loss: 0.02654777467250824\n",
      "Epoch: 0/8, Batch: 500/3444, Loss: 0.05204284191131592\n",
      "Epoch: 0/8, Batch: 510/3444, Loss: 0.03681955859065056\n",
      "Epoch: 0/8, Batch: 520/3444, Loss: 0.05101647228002548\n",
      "Epoch: 0/8, Batch: 530/3444, Loss: 0.11023642122745514\n",
      "Epoch: 0/8, Batch: 540/3444, Loss: 0.06545281410217285\n",
      "Epoch: 0/8, Batch: 550/3444, Loss: 0.035189032554626465\n",
      "Epoch: 0/8, Batch: 560/3444, Loss: 0.03490946441888809\n",
      "Epoch: 0/8, Batch: 570/3444, Loss: 0.0646008625626564\n",
      "Epoch: 0/8, Batch: 580/3444, Loss: 0.023241223767399788\n",
      "Epoch: 0/8, Batch: 590/3444, Loss: 0.031047293916344643\n",
      "Epoch: 0/8, Batch: 600/3444, Loss: 0.05596771836280823\n",
      "Epoch: 0/8, Batch: 610/3444, Loss: 0.026192812249064445\n",
      "Epoch: 0/8, Batch: 620/3444, Loss: 0.044055089354515076\n",
      "Epoch: 0/8, Batch: 630/3444, Loss: 0.052978526800870895\n",
      "Epoch: 0/8, Batch: 640/3444, Loss: 0.03954986855387688\n",
      "Epoch: 0/8, Batch: 650/3444, Loss: 0.05728204548358917\n",
      "Epoch: 0/8, Batch: 660/3444, Loss: 0.0960480198264122\n",
      "Epoch: 0/8, Batch: 670/3444, Loss: 0.01656770147383213\n",
      "Epoch: 0/8, Batch: 680/3444, Loss: 0.07160888612270355\n",
      "Epoch: 0/8, Batch: 690/3444, Loss: 0.028841501101851463\n",
      "Epoch: 0/8, Batch: 700/3444, Loss: 0.025518737733364105\n",
      "Epoch: 0/8, Batch: 710/3444, Loss: 0.02170979417860508\n",
      "Epoch: 0/8, Batch: 720/3444, Loss: 0.023437948897480965\n",
      "Epoch: 0/8, Batch: 730/3444, Loss: 0.06208203732967377\n",
      "Epoch: 0/8, Batch: 740/3444, Loss: 0.017629802227020264\n",
      "Epoch: 0/8, Batch: 750/3444, Loss: 0.042621493339538574\n",
      "Epoch: 0/8, Batch: 760/3444, Loss: 0.019944850355386734\n",
      "Epoch: 0/8, Batch: 770/3444, Loss: 0.018920423462986946\n",
      "Epoch: 0/8, Batch: 780/3444, Loss: 0.03920360282063484\n",
      "Epoch: 0/8, Batch: 790/3444, Loss: 0.021900340914726257\n",
      "Epoch: 0/8, Batch: 800/3444, Loss: 0.04740939289331436\n",
      "Epoch: 0/8, Batch: 810/3444, Loss: 0.018040945753455162\n",
      "Epoch: 0/8, Batch: 820/3444, Loss: 0.026545273140072823\n",
      "Epoch: 0/8, Batch: 830/3444, Loss: 0.03283178433775902\n",
      "Epoch: 0/8, Batch: 840/3444, Loss: 0.024925190955400467\n",
      "Epoch: 0/8, Batch: 850/3444, Loss: 0.01030446495860815\n",
      "Epoch: 0/8, Batch: 860/3444, Loss: 0.019364412873983383\n",
      "Epoch: 0/8, Batch: 870/3444, Loss: 0.016959281638264656\n",
      "Epoch: 0/8, Batch: 880/3444, Loss: 0.018573973327875137\n",
      "Epoch: 0/8, Batch: 890/3444, Loss: 0.07094180583953857\n",
      "Epoch: 0/8, Batch: 900/3444, Loss: 0.03676517680287361\n",
      "Epoch: 0/8, Batch: 910/3444, Loss: 0.05120934173464775\n",
      "Epoch: 0/8, Batch: 920/3444, Loss: 0.10533890873193741\n",
      "Epoch: 0/8, Batch: 930/3444, Loss: 0.017433302477002144\n",
      "Epoch: 0/8, Batch: 940/3444, Loss: 0.04310585930943489\n",
      "Epoch: 0/8, Batch: 950/3444, Loss: 0.029796097427606583\n",
      "Epoch: 0/8, Batch: 960/3444, Loss: 0.024519003927707672\n",
      "Epoch: 0/8, Batch: 970/3444, Loss: 0.045095328241586685\n",
      "Epoch: 0/8, Batch: 980/3444, Loss: 0.042752817273139954\n",
      "Epoch: 0/8, Batch: 990/3444, Loss: 0.04564529284834862\n",
      "Epoch: 0/8, Batch: 1000/3444, Loss: 0.011764081194996834\n",
      "Epoch: 0/8, Batch: 1010/3444, Loss: 0.031097538769245148\n",
      "Epoch: 0/8, Batch: 1020/3444, Loss: 0.019039243459701538\n",
      "Epoch: 0/8, Batch: 1030/3444, Loss: 0.014485212974250317\n",
      "Epoch: 0/8, Batch: 1040/3444, Loss: 0.023124437779188156\n",
      "Epoch: 0/8, Batch: 1050/3444, Loss: 0.01906442642211914\n",
      "Epoch: 0/8, Batch: 1060/3444, Loss: 0.06030098721385002\n",
      "Epoch: 0/8, Batch: 1070/3444, Loss: 0.020692376419901848\n",
      "Epoch: 0/8, Batch: 1080/3444, Loss: 0.02108401246368885\n",
      "Epoch: 0/8, Batch: 1090/3444, Loss: 0.023539358749985695\n",
      "Epoch: 0/8, Batch: 1100/3444, Loss: 0.08617284148931503\n",
      "Epoch: 0/8, Batch: 1110/3444, Loss: 0.027466949075460434\n",
      "Epoch: 0/8, Batch: 1120/3444, Loss: 0.036763183772563934\n",
      "Epoch: 0/8, Batch: 1130/3444, Loss: 0.023329634219408035\n",
      "Epoch: 0/8, Batch: 1140/3444, Loss: 0.06901398301124573\n",
      "Epoch: 0/8, Batch: 1150/3444, Loss: 0.017200039699673653\n",
      "Epoch: 0/8, Batch: 1160/3444, Loss: 0.05659646913409233\n",
      "Epoch: 0/8, Batch: 1170/3444, Loss: 0.03028702177107334\n",
      "Epoch: 0/8, Batch: 1180/3444, Loss: 0.016252426430583\n",
      "Epoch: 0/8, Batch: 1190/3444, Loss: 0.03478815034031868\n",
      "Epoch: 0/8, Batch: 1200/3444, Loss: 0.04018570855259895\n",
      "Epoch: 0/8, Batch: 1210/3444, Loss: 0.060839537531137466\n",
      "Epoch: 0/8, Batch: 1220/3444, Loss: 0.04340309649705887\n",
      "Epoch: 0/8, Batch: 1230/3444, Loss: 0.02473445236682892\n",
      "Epoch: 0/8, Batch: 1240/3444, Loss: 0.020433230325579643\n",
      "Epoch: 0/8, Batch: 1250/3444, Loss: 0.07595549523830414\n",
      "Epoch: 0/8, Batch: 1260/3444, Loss: 0.04483756422996521\n",
      "Epoch: 0/8, Batch: 1270/3444, Loss: 0.038473110646009445\n",
      "Epoch: 0/8, Batch: 1280/3444, Loss: 0.023167291656136513\n",
      "Epoch: 0/8, Batch: 1290/3444, Loss: 0.06284145265817642\n",
      "Epoch: 0/8, Batch: 1300/3444, Loss: 0.03294653818011284\n",
      "Epoch: 0/8, Batch: 1310/3444, Loss: 0.10136245936155319\n",
      "Epoch: 0/8, Batch: 1320/3444, Loss: 0.042297542095184326\n",
      "Epoch: 0/8, Batch: 1330/3444, Loss: 0.020634185522794724\n",
      "Epoch: 0/8, Batch: 1340/3444, Loss: 0.03172719478607178\n",
      "Epoch: 0/8, Batch: 1350/3444, Loss: 0.02786608785390854\n",
      "Epoch: 0/8, Batch: 1360/3444, Loss: 0.022442437708377838\n",
      "Epoch: 0/8, Batch: 1370/3444, Loss: 0.06297696381807327\n",
      "Epoch: 0/8, Batch: 1380/3444, Loss: 0.052892714738845825\n",
      "Epoch: 0/8, Batch: 1390/3444, Loss: 0.022631794214248657\n",
      "Epoch: 0/8, Batch: 1400/3444, Loss: 0.04180299490690231\n",
      "Epoch: 0/8, Batch: 1410/3444, Loss: 0.041904520243406296\n",
      "Epoch: 0/8, Batch: 1420/3444, Loss: 0.027589261531829834\n",
      "Epoch: 0/8, Batch: 1430/3444, Loss: 0.03057684935629368\n",
      "Epoch: 0/8, Batch: 1440/3444, Loss: 0.019849875941872597\n",
      "Epoch: 0/8, Batch: 1450/3444, Loss: 0.03193210810422897\n",
      "Epoch: 0/8, Batch: 1460/3444, Loss: 0.019433435052633286\n",
      "Epoch: 0/8, Batch: 1470/3444, Loss: 0.023245202377438545\n",
      "Epoch: 0/8, Batch: 1480/3444, Loss: 0.01862422376871109\n",
      "Epoch: 0/8, Batch: 1490/3444, Loss: 0.0310524869710207\n",
      "Epoch: 0/8, Batch: 1500/3444, Loss: 0.06565802544355392\n",
      "Epoch: 0/8, Batch: 1510/3444, Loss: 0.019404953345656395\n",
      "Epoch: 0/8, Batch: 1520/3444, Loss: 0.03365330398082733\n",
      "Epoch: 0/8, Batch: 1530/3444, Loss: 0.07465995848178864\n",
      "Epoch: 0/8, Batch: 1540/3444, Loss: 0.02178497612476349\n",
      "Epoch: 0/8, Batch: 1550/3444, Loss: 0.03120560012757778\n",
      "Epoch: 0/8, Batch: 1560/3444, Loss: 0.022654084488749504\n",
      "Epoch: 0/8, Batch: 1570/3444, Loss: 0.03890906646847725\n",
      "Epoch: 0/8, Batch: 1580/3444, Loss: 0.024761272594332695\n",
      "Epoch: 0/8, Batch: 1590/3444, Loss: 0.03388756886124611\n",
      "Epoch: 0/8, Batch: 1600/3444, Loss: 0.009826305322349072\n",
      "Epoch: 0/8, Batch: 1610/3444, Loss: 0.030759664252400398\n",
      "Epoch: 0/8, Batch: 1620/3444, Loss: 0.02035342901945114\n",
      "Epoch: 0/8, Batch: 1630/3444, Loss: 0.016079343855381012\n",
      "Epoch: 0/8, Batch: 1640/3444, Loss: 0.010913293808698654\n",
      "Epoch: 0/8, Batch: 1650/3444, Loss: 0.017523828893899918\n",
      "Epoch: 0/8, Batch: 1660/3444, Loss: 0.020423758774995804\n",
      "Epoch: 0/8, Batch: 1670/3444, Loss: 0.034612808376550674\n",
      "Epoch: 0/8, Batch: 1680/3444, Loss: 0.020669320598244667\n",
      "Epoch: 0/8, Batch: 1690/3444, Loss: 0.05046144127845764\n",
      "Epoch: 0/8, Batch: 1700/3444, Loss: 0.03512205556035042\n",
      "Epoch: 0/8, Batch: 1710/3444, Loss: 0.032825544476509094\n",
      "Epoch: 0/8, Batch: 1720/3444, Loss: 0.011800652369856834\n",
      "Epoch: 0/8, Batch: 1730/3444, Loss: 0.012991515919566154\n",
      "Epoch: 0/8, Batch: 1740/3444, Loss: 0.013751869089901447\n",
      "Epoch: 0/8, Batch: 1750/3444, Loss: 0.016449986025691032\n",
      "Epoch: 0/8, Batch: 1760/3444, Loss: 0.0173704382032156\n",
      "Epoch: 0/8, Batch: 1770/3444, Loss: 0.042983733117580414\n",
      "Epoch: 0/8, Batch: 1780/3444, Loss: 0.026244036853313446\n",
      "Epoch: 0/8, Batch: 1790/3444, Loss: 0.02240592986345291\n",
      "Epoch: 0/8, Batch: 1800/3444, Loss: 0.061120275408029556\n",
      "Epoch: 0/8, Batch: 1810/3444, Loss: 0.06301054358482361\n",
      "Epoch: 0/8, Batch: 1820/3444, Loss: 0.03189407289028168\n",
      "Epoch: 0/8, Batch: 1830/3444, Loss: 0.018238097429275513\n",
      "Epoch: 0/8, Batch: 1840/3444, Loss: 0.03653895854949951\n",
      "Epoch: 0/8, Batch: 1850/3444, Loss: 0.05372287705540657\n",
      "Epoch: 0/8, Batch: 1860/3444, Loss: 0.017985999584197998\n",
      "Epoch: 0/8, Batch: 1870/3444, Loss: 0.024300765246152878\n",
      "Epoch: 0/8, Batch: 1880/3444, Loss: 0.02718336135149002\n",
      "Epoch: 0/8, Batch: 1890/3444, Loss: 0.027031686156988144\n",
      "Epoch: 0/8, Batch: 1900/3444, Loss: 0.032632939517498016\n",
      "Epoch: 0/8, Batch: 1910/3444, Loss: 0.02146032266318798\n",
      "Epoch: 0/8, Batch: 1920/3444, Loss: 0.015937648713588715\n",
      "Epoch: 0/8, Batch: 1930/3444, Loss: 0.028855590149760246\n",
      "Epoch: 0/8, Batch: 1940/3444, Loss: 0.028898080810904503\n",
      "Epoch: 0/8, Batch: 1950/3444, Loss: 0.05518123507499695\n",
      "Epoch: 0/8, Batch: 1960/3444, Loss: 0.04672366380691528\n",
      "Epoch: 0/8, Batch: 1970/3444, Loss: 0.04452536255121231\n",
      "Epoch: 0/8, Batch: 1980/3444, Loss: 0.02731367200613022\n",
      "Epoch: 0/8, Batch: 1990/3444, Loss: 0.005030239466577768\n",
      "Epoch: 0/8, Batch: 2000/3444, Loss: 0.03764897212386131\n",
      "Epoch: 0/8, Batch: 2010/3444, Loss: 0.07471583783626556\n",
      "Epoch: 0/8, Batch: 2020/3444, Loss: 0.024708066135644913\n",
      "Epoch: 0/8, Batch: 2030/3444, Loss: 0.02959146909415722\n",
      "Epoch: 0/8, Batch: 2040/3444, Loss: 0.030809523537755013\n",
      "Epoch: 0/8, Batch: 2050/3444, Loss: 0.019062239676713943\n",
      "Epoch: 0/8, Batch: 2060/3444, Loss: 0.019321545958518982\n",
      "Epoch: 0/8, Batch: 2070/3444, Loss: 0.052716828882694244\n",
      "Epoch: 0/8, Batch: 2080/3444, Loss: 0.059404101222753525\n",
      "Epoch: 0/8, Batch: 2090/3444, Loss: 0.029210854321718216\n",
      "Epoch: 0/8, Batch: 2100/3444, Loss: 0.01894948072731495\n",
      "Epoch: 0/8, Batch: 2110/3444, Loss: 0.006451880093663931\n",
      "Epoch: 0/8, Batch: 2120/3444, Loss: 0.023010479286313057\n",
      "Epoch: 0/8, Batch: 2130/3444, Loss: 0.04310618340969086\n",
      "Epoch: 0/8, Batch: 2140/3444, Loss: 0.012388763017952442\n",
      "Epoch: 0/8, Batch: 2150/3444, Loss: 0.02211628295481205\n",
      "Epoch: 0/8, Batch: 2160/3444, Loss: 0.028922948986291885\n",
      "Epoch: 0/8, Batch: 2170/3444, Loss: 0.03345362842082977\n",
      "Epoch: 0/8, Batch: 2180/3444, Loss: 0.020607847720384598\n",
      "Epoch: 0/8, Batch: 2190/3444, Loss: 0.02877098135650158\n",
      "Epoch: 0/8, Batch: 2200/3444, Loss: 0.02024146169424057\n",
      "Epoch: 0/8, Batch: 2210/3444, Loss: 0.012471556663513184\n",
      "Epoch: 0/8, Batch: 2220/3444, Loss: 0.029087234288454056\n",
      "Epoch: 0/8, Batch: 2230/3444, Loss: 0.02932797186076641\n",
      "Epoch: 0/8, Batch: 2240/3444, Loss: 0.0754934549331665\n",
      "Epoch: 0/8, Batch: 2250/3444, Loss: 0.015610422939062119\n",
      "Epoch: 0/8, Batch: 2260/3444, Loss: 0.10941415280103683\n",
      "Epoch: 0/8, Batch: 2270/3444, Loss: 0.10763299465179443\n",
      "Epoch: 0/8, Batch: 2280/3444, Loss: 0.03605705872178078\n",
      "Epoch: 0/8, Batch: 2290/3444, Loss: 0.025002282112836838\n",
      "Epoch: 0/8, Batch: 2300/3444, Loss: 0.07096048444509506\n",
      "Epoch: 0/8, Batch: 2310/3444, Loss: 0.05598768964409828\n",
      "Epoch: 0/8, Batch: 2320/3444, Loss: 0.025876609608530998\n",
      "Epoch: 0/8, Batch: 2330/3444, Loss: 0.023117316886782646\n",
      "Epoch: 0/8, Batch: 2340/3444, Loss: 0.0732603594660759\n",
      "Epoch: 0/8, Batch: 2350/3444, Loss: 0.026287006214261055\n",
      "Epoch: 0/8, Batch: 2360/3444, Loss: 0.0405157245695591\n",
      "Epoch: 0/8, Batch: 2370/3444, Loss: 0.03202412277460098\n",
      "Epoch: 0/8, Batch: 2380/3444, Loss: 0.15117129683494568\n",
      "Epoch: 0/8, Batch: 2390/3444, Loss: 0.03169474005699158\n",
      "Epoch: 0/8, Batch: 2400/3444, Loss: 0.017861172556877136\n",
      "Epoch: 0/8, Batch: 2410/3444, Loss: 0.025728393346071243\n",
      "Epoch: 0/8, Batch: 2420/3444, Loss: 0.04367770999670029\n",
      "Epoch: 0/8, Batch: 2430/3444, Loss: 0.017356790602207184\n",
      "Epoch: 0/8, Batch: 2440/3444, Loss: 0.04553478956222534\n",
      "Epoch: 0/8, Batch: 2450/3444, Loss: 0.037651803344488144\n",
      "Epoch: 0/8, Batch: 2460/3444, Loss: 0.05228989198803902\n",
      "Epoch: 0/8, Batch: 2470/3444, Loss: 0.04290306568145752\n",
      "Epoch: 0/8, Batch: 2480/3444, Loss: 0.036333803087472916\n",
      "Epoch: 0/8, Batch: 2490/3444, Loss: 0.03724469617009163\n",
      "Epoch: 0/8, Batch: 2500/3444, Loss: 0.04792741313576698\n",
      "Epoch: 0/8, Batch: 2510/3444, Loss: 0.06611490994691849\n",
      "Epoch: 0/8, Batch: 2520/3444, Loss: 0.05185487121343613\n",
      "Epoch: 0/8, Batch: 2530/3444, Loss: 0.012500602751970291\n",
      "Epoch: 0/8, Batch: 2540/3444, Loss: 0.04361213371157646\n",
      "Epoch: 0/8, Batch: 2550/3444, Loss: 0.03380652144551277\n",
      "Epoch: 0/8, Batch: 2560/3444, Loss: 0.04132382571697235\n",
      "Epoch: 0/8, Batch: 2570/3444, Loss: 0.03014647401869297\n",
      "Epoch: 0/8, Batch: 2580/3444, Loss: 0.0857081487774849\n",
      "Epoch: 0/8, Batch: 2590/3444, Loss: 0.055563267320394516\n",
      "Epoch: 0/8, Batch: 2600/3444, Loss: 0.05044010654091835\n",
      "Epoch: 0/8, Batch: 2610/3444, Loss: 0.0276727806776762\n",
      "Epoch: 0/8, Batch: 2620/3444, Loss: 0.022069387137889862\n",
      "Epoch: 0/8, Batch: 2630/3444, Loss: 0.01696072332561016\n",
      "Epoch: 0/8, Batch: 2640/3444, Loss: 0.05079876631498337\n",
      "Epoch: 0/8, Batch: 2650/3444, Loss: 0.07501138001680374\n",
      "Epoch: 0/8, Batch: 2660/3444, Loss: 0.024755313992500305\n",
      "Epoch: 0/8, Batch: 2670/3444, Loss: 0.004178822971880436\n",
      "Epoch: 0/8, Batch: 2680/3444, Loss: 0.008631095290184021\n",
      "Epoch: 0/8, Batch: 2690/3444, Loss: 0.07268860191106796\n",
      "Epoch: 0/8, Batch: 2700/3444, Loss: 0.026840461418032646\n",
      "Epoch: 0/8, Batch: 2710/3444, Loss: 0.04172172024846077\n",
      "Epoch: 0/8, Batch: 2720/3444, Loss: 0.05475219711661339\n",
      "Epoch: 0/8, Batch: 2730/3444, Loss: 0.03380456939339638\n",
      "Epoch: 0/8, Batch: 2740/3444, Loss: 0.0238202977925539\n",
      "Epoch: 0/8, Batch: 2750/3444, Loss: 0.018640030175447464\n",
      "Epoch: 0/8, Batch: 2760/3444, Loss: 0.018049662932753563\n",
      "Epoch: 0/8, Batch: 2770/3444, Loss: 0.017918182536959648\n",
      "Epoch: 0/8, Batch: 2780/3444, Loss: 0.03687431663274765\n",
      "Epoch: 0/8, Batch: 2790/3444, Loss: 0.04575195536017418\n",
      "Epoch: 0/8, Batch: 2800/3444, Loss: 0.03144616261124611\n",
      "Epoch: 0/8, Batch: 2810/3444, Loss: 0.018950030207633972\n",
      "Epoch: 0/8, Batch: 2820/3444, Loss: 0.019116703420877457\n",
      "Epoch: 0/8, Batch: 2830/3444, Loss: 0.018850743770599365\n",
      "Epoch: 0/8, Batch: 2840/3444, Loss: 0.0582301951944828\n",
      "Epoch: 0/8, Batch: 2850/3444, Loss: 0.02312524802982807\n",
      "Epoch: 0/8, Batch: 2860/3444, Loss: 0.051455944776535034\n",
      "Epoch: 0/8, Batch: 2870/3444, Loss: 0.03038886748254299\n",
      "Epoch: 0/8, Batch: 2880/3444, Loss: 0.04787459596991539\n",
      "Epoch: 0/8, Batch: 2890/3444, Loss: 0.06730641424655914\n",
      "Epoch: 0/8, Batch: 2900/3444, Loss: 0.025534728541970253\n",
      "Epoch: 0/8, Batch: 2910/3444, Loss: 0.05492021515965462\n",
      "Epoch: 0/8, Batch: 2920/3444, Loss: 0.04039638862013817\n",
      "Epoch: 0/8, Batch: 2930/3444, Loss: 0.05802765488624573\n",
      "Epoch: 0/8, Batch: 2940/3444, Loss: 0.015409723855555058\n",
      "Epoch: 0/8, Batch: 2950/3444, Loss: 0.00984456017613411\n",
      "Epoch: 0/8, Batch: 2960/3444, Loss: 0.008409455418586731\n",
      "Epoch: 0/8, Batch: 2970/3444, Loss: 0.030430812388658524\n",
      "Epoch: 0/8, Batch: 2980/3444, Loss: 0.02783355303108692\n",
      "Epoch: 0/8, Batch: 2990/3444, Loss: 0.008512347936630249\n",
      "Epoch: 0/8, Batch: 3000/3444, Loss: 0.01512276940047741\n",
      "Epoch: 0/8, Batch: 3010/3444, Loss: 0.01871013082563877\n",
      "Epoch: 0/8, Batch: 3020/3444, Loss: 0.017447683960199356\n",
      "Epoch: 0/8, Batch: 3030/3444, Loss: 0.03738577663898468\n",
      "Epoch: 0/8, Batch: 3040/3444, Loss: 0.027059942483901978\n",
      "Epoch: 0/8, Batch: 3050/3444, Loss: 0.025561686605215073\n",
      "Epoch: 0/8, Batch: 3060/3444, Loss: 0.0502873919904232\n",
      "Epoch: 0/8, Batch: 3070/3444, Loss: 0.058014120906591415\n",
      "Epoch: 0/8, Batch: 3080/3444, Loss: 0.020888851955533028\n",
      "Epoch: 0/8, Batch: 3090/3444, Loss: 0.02070731669664383\n",
      "Epoch: 0/8, Batch: 3100/3444, Loss: 0.06555761396884918\n",
      "Epoch: 0/8, Batch: 3110/3444, Loss: 0.05923168361186981\n",
      "Epoch: 0/8, Batch: 3120/3444, Loss: 0.013627758249640465\n",
      "Epoch: 0/8, Batch: 3130/3444, Loss: 0.027582257986068726\n",
      "Epoch: 0/8, Batch: 3140/3444, Loss: 0.060039933770895004\n",
      "Epoch: 0/8, Batch: 3150/3444, Loss: 0.016746897250413895\n",
      "Epoch: 0/8, Batch: 3160/3444, Loss: 0.015406892634928226\n",
      "Epoch: 0/8, Batch: 3170/3444, Loss: 0.020359089598059654\n",
      "Epoch: 0/8, Batch: 3180/3444, Loss: 0.04262258857488632\n",
      "Epoch: 0/8, Batch: 3190/3444, Loss: 0.03585105389356613\n",
      "Epoch: 0/8, Batch: 3200/3444, Loss: 0.024994488805532455\n",
      "Epoch: 0/8, Batch: 3210/3444, Loss: 0.018060194328427315\n",
      "Epoch: 0/8, Batch: 3220/3444, Loss: 0.029153967276215553\n",
      "Epoch: 0/8, Batch: 3230/3444, Loss: 0.04314321652054787\n",
      "Epoch: 0/8, Batch: 3240/3444, Loss: 0.02918265014886856\n",
      "Epoch: 0/8, Batch: 3250/3444, Loss: 0.038206327706575394\n",
      "Epoch: 0/8, Batch: 3260/3444, Loss: 0.06566427648067474\n",
      "Epoch: 0/8, Batch: 3270/3444, Loss: 0.056666385382413864\n",
      "Epoch: 0/8, Batch: 3280/3444, Loss: 0.024782301858067513\n",
      "Epoch: 0/8, Batch: 3290/3444, Loss: 0.029557885602116585\n",
      "Epoch: 0/8, Batch: 3300/3444, Loss: 0.009482328779995441\n",
      "Epoch: 0/8, Batch: 3310/3444, Loss: 0.01746284030377865\n",
      "Epoch: 0/8, Batch: 3320/3444, Loss: 0.023251673206686974\n",
      "Epoch: 0/8, Batch: 3330/3444, Loss: 0.017586994916200638\n",
      "Epoch: 0/8, Batch: 3340/3444, Loss: 0.028949584811925888\n",
      "Epoch: 0/8, Batch: 3350/3444, Loss: 0.049347057938575745\n",
      "Epoch: 0/8, Batch: 3360/3444, Loss: 0.024673424661159515\n",
      "Epoch: 0/8, Batch: 3370/3444, Loss: 0.017957452684640884\n",
      "Epoch: 0/8, Batch: 3380/3444, Loss: 0.011656195856630802\n",
      "Epoch: 0/8, Batch: 3390/3444, Loss: 0.037574559450149536\n",
      "Epoch: 0/8, Batch: 3400/3444, Loss: 0.0525861494243145\n",
      "Epoch: 0/8, Batch: 3410/3444, Loss: 0.017599381506443024\n",
      "Epoch: 0/8, Batch: 3420/3444, Loss: 0.032287973910570145\n",
      "Epoch: 0/8, Batch: 3430/3444, Loss: 0.012772527523338795\n",
      "Epoch: 0/8, Batch: 3440/3444, Loss: 0.015789423137903214\n",
      "Epoch: 0/8, Val Loss: 0.055770567801113606\n",
      "Epoch: 1/8, Batch: 10/3444, Loss: 0.055927447974681854\n",
      "Epoch: 1/8, Batch: 20/3444, Loss: 0.04585237428545952\n",
      "Epoch: 1/8, Batch: 30/3444, Loss: 0.03621010482311249\n",
      "Epoch: 1/8, Batch: 40/3444, Loss: 0.03009490668773651\n",
      "Epoch: 1/8, Batch: 50/3444, Loss: 0.03593477979302406\n",
      "Epoch: 1/8, Batch: 60/3444, Loss: 0.02109905332326889\n",
      "Epoch: 1/8, Batch: 70/3444, Loss: 0.047082215547561646\n",
      "Epoch: 1/8, Batch: 80/3444, Loss: 0.050317611545324326\n",
      "Epoch: 1/8, Batch: 90/3444, Loss: 0.024495258927345276\n",
      "Epoch: 1/8, Batch: 100/3444, Loss: 0.03432728350162506\n",
      "Epoch: 1/8, Batch: 110/3444, Loss: 0.04201003536581993\n",
      "Epoch: 1/8, Batch: 120/3444, Loss: 0.022343479096889496\n",
      "Epoch: 1/8, Batch: 130/3444, Loss: 0.02531614899635315\n",
      "Epoch: 1/8, Batch: 140/3444, Loss: 0.017146585509181023\n",
      "Epoch: 1/8, Batch: 150/3444, Loss: 0.02324896864593029\n",
      "Epoch: 1/8, Batch: 160/3444, Loss: 0.020384138450026512\n",
      "Epoch: 1/8, Batch: 170/3444, Loss: 0.07310730963945389\n",
      "Epoch: 1/8, Batch: 180/3444, Loss: 0.02871083654463291\n",
      "Epoch: 1/8, Batch: 190/3444, Loss: 0.04416113346815109\n",
      "Epoch: 1/8, Batch: 200/3444, Loss: 0.039053600281476974\n",
      "Epoch: 1/8, Batch: 210/3444, Loss: 0.013785465620458126\n",
      "Epoch: 1/8, Batch: 220/3444, Loss: 0.03624176234006882\n",
      "Epoch: 1/8, Batch: 230/3444, Loss: 0.018860653042793274\n",
      "Epoch: 1/8, Batch: 240/3444, Loss: 0.018063465133309364\n",
      "Epoch: 1/8, Batch: 250/3444, Loss: 0.06076131761074066\n",
      "Epoch: 1/8, Batch: 260/3444, Loss: 0.021340826526284218\n",
      "Epoch: 1/8, Batch: 270/3444, Loss: 0.06646683067083359\n",
      "Epoch: 1/8, Batch: 280/3444, Loss: 0.021834557875990868\n",
      "Epoch: 1/8, Batch: 290/3444, Loss: 0.03033383935689926\n",
      "Epoch: 1/8, Batch: 300/3444, Loss: 0.09090325981378555\n",
      "Epoch: 1/8, Batch: 310/3444, Loss: 0.03280976042151451\n",
      "Epoch: 1/8, Batch: 320/3444, Loss: 0.044152844697237015\n",
      "Epoch: 1/8, Batch: 330/3444, Loss: 0.014701860956847668\n",
      "Epoch: 1/8, Batch: 340/3444, Loss: 0.0197672750800848\n",
      "Epoch: 1/8, Batch: 350/3444, Loss: 0.06295466423034668\n",
      "Epoch: 1/8, Batch: 360/3444, Loss: 0.03254895657300949\n",
      "Epoch: 1/8, Batch: 370/3444, Loss: 0.028018582612276077\n",
      "Epoch: 1/8, Batch: 380/3444, Loss: 0.11426455527544022\n",
      "Epoch: 1/8, Batch: 390/3444, Loss: 0.07566668093204498\n",
      "Epoch: 1/8, Batch: 400/3444, Loss: 0.018454797565937042\n",
      "Epoch: 1/8, Batch: 410/3444, Loss: 0.024067191407084465\n",
      "Epoch: 1/8, Batch: 420/3444, Loss: 0.01737757958471775\n",
      "Epoch: 1/8, Batch: 430/3444, Loss: 0.06671938300132751\n",
      "Epoch: 1/8, Batch: 440/3444, Loss: 0.018902787938714027\n",
      "Epoch: 1/8, Batch: 450/3444, Loss: 0.03157857060432434\n",
      "Epoch: 1/8, Batch: 460/3444, Loss: 0.02255781926214695\n",
      "Epoch: 1/8, Batch: 470/3444, Loss: 0.022856522351503372\n",
      "Epoch: 1/8, Batch: 480/3444, Loss: 0.03195735812187195\n",
      "Epoch: 1/8, Batch: 490/3444, Loss: 0.027148013934493065\n",
      "Epoch: 1/8, Batch: 500/3444, Loss: 0.027335625141859055\n",
      "Epoch: 1/8, Batch: 510/3444, Loss: 0.021093791350722313\n",
      "Epoch: 1/8, Batch: 520/3444, Loss: 0.01808091253042221\n",
      "Epoch: 1/8, Batch: 530/3444, Loss: 0.0850299671292305\n",
      "Epoch: 1/8, Batch: 540/3444, Loss: 0.038897160440683365\n",
      "Epoch: 1/8, Batch: 550/3444, Loss: 0.027208475396037102\n",
      "Epoch: 1/8, Batch: 560/3444, Loss: 0.016178607940673828\n",
      "Epoch: 1/8, Batch: 570/3444, Loss: 0.031870659440755844\n",
      "Epoch: 1/8, Batch: 580/3444, Loss: 0.016041770577430725\n",
      "Epoch: 1/8, Batch: 590/3444, Loss: 0.019033975899219513\n",
      "Epoch: 1/8, Batch: 600/3444, Loss: 0.05834076553583145\n",
      "Epoch: 1/8, Batch: 610/3444, Loss: 0.07855195552110672\n",
      "Epoch: 1/8, Batch: 620/3444, Loss: 0.012533272616565228\n",
      "Epoch: 1/8, Batch: 630/3444, Loss: 0.022238465026021004\n",
      "Epoch: 1/8, Batch: 640/3444, Loss: 0.040831830352544785\n",
      "Epoch: 1/8, Batch: 650/3444, Loss: 0.027731260284781456\n",
      "Epoch: 1/8, Batch: 660/3444, Loss: 0.05446909740567207\n",
      "Epoch: 1/8, Batch: 670/3444, Loss: 0.029145406559109688\n",
      "Epoch: 1/8, Batch: 680/3444, Loss: 0.02956453710794449\n",
      "Epoch: 1/8, Batch: 690/3444, Loss: 0.012822977267205715\n",
      "Epoch: 1/8, Batch: 700/3444, Loss: 0.04841647669672966\n",
      "Epoch: 1/8, Batch: 710/3444, Loss: 0.012245265766978264\n",
      "Epoch: 1/8, Batch: 720/3444, Loss: 0.019484268501400948\n",
      "Epoch: 1/8, Batch: 730/3444, Loss: 0.0397639162838459\n",
      "Epoch: 1/8, Batch: 740/3444, Loss: 0.02781207114458084\n",
      "Epoch: 1/8, Batch: 750/3444, Loss: 0.022375958040356636\n",
      "Epoch: 1/8, Batch: 760/3444, Loss: 0.025882139801979065\n",
      "Epoch: 1/8, Batch: 770/3444, Loss: 0.011442029848694801\n",
      "Epoch: 1/8, Batch: 780/3444, Loss: 0.013091236352920532\n",
      "Epoch: 1/8, Batch: 790/3444, Loss: 0.044161900877952576\n",
      "Epoch: 1/8, Batch: 800/3444, Loss: 0.05619771406054497\n",
      "Epoch: 1/8, Batch: 810/3444, Loss: 0.02062605321407318\n",
      "Epoch: 1/8, Batch: 820/3444, Loss: 0.012251623906195164\n",
      "Epoch: 1/8, Batch: 830/3444, Loss: 0.022734083235263824\n",
      "Epoch: 1/8, Batch: 840/3444, Loss: 0.023190319538116455\n",
      "Epoch: 1/8, Batch: 850/3444, Loss: 0.010015902109444141\n",
      "Epoch: 1/8, Batch: 860/3444, Loss: 0.02206043154001236\n",
      "Epoch: 1/8, Batch: 870/3444, Loss: 0.030880091711878777\n",
      "Epoch: 1/8, Batch: 880/3444, Loss: 0.030890870839357376\n",
      "Epoch: 1/8, Batch: 890/3444, Loss: 0.0364534892141819\n",
      "Epoch: 1/8, Batch: 900/3444, Loss: 0.1030266284942627\n",
      "Epoch: 1/8, Batch: 910/3444, Loss: 0.049092527478933334\n",
      "Epoch: 1/8, Batch: 920/3444, Loss: 0.014788427390158176\n",
      "Epoch: 1/8, Batch: 930/3444, Loss: 0.06492941081523895\n",
      "Epoch: 1/8, Batch: 940/3444, Loss: 0.018818870186805725\n",
      "Epoch: 1/8, Batch: 950/3444, Loss: 0.01614249125123024\n",
      "Epoch: 1/8, Batch: 960/3444, Loss: 0.022952305153012276\n",
      "Epoch: 1/8, Batch: 970/3444, Loss: 0.03536402806639671\n",
      "Epoch: 1/8, Batch: 980/3444, Loss: 0.0178274717181921\n",
      "Epoch: 1/8, Batch: 990/3444, Loss: 0.02341948263347149\n",
      "Epoch: 1/8, Batch: 1000/3444, Loss: 0.01853763498365879\n",
      "Epoch: 1/8, Batch: 1010/3444, Loss: 0.03866792097687721\n",
      "Epoch: 1/8, Batch: 1020/3444, Loss: 0.02294784039258957\n",
      "Epoch: 1/8, Batch: 1030/3444, Loss: 0.10118924826383591\n",
      "Epoch: 1/8, Batch: 1040/3444, Loss: 0.023571394383907318\n",
      "Epoch: 1/8, Batch: 1050/3444, Loss: 0.015206539072096348\n",
      "Epoch: 1/8, Batch: 1060/3444, Loss: 0.02491142600774765\n",
      "Epoch: 1/8, Batch: 1070/3444, Loss: 0.02519967406988144\n",
      "Epoch: 1/8, Batch: 1080/3444, Loss: 0.04276851564645767\n",
      "Epoch: 1/8, Batch: 1090/3444, Loss: 0.02269153855741024\n",
      "Epoch: 1/8, Batch: 1100/3444, Loss: 0.06501303613185883\n",
      "Epoch: 1/8, Batch: 1110/3444, Loss: 0.05915872007608414\n",
      "Epoch: 1/8, Batch: 1120/3444, Loss: 0.0749749019742012\n",
      "Epoch: 1/8, Batch: 1130/3444, Loss: 0.11819642037153244\n",
      "Epoch: 1/8, Batch: 1140/3444, Loss: 0.05814381316304207\n",
      "Epoch: 1/8, Batch: 1150/3444, Loss: 0.023730933666229248\n",
      "Epoch: 1/8, Batch: 1160/3444, Loss: 0.06095722317695618\n",
      "Epoch: 1/8, Batch: 1170/3444, Loss: 0.02187902294099331\n",
      "Epoch: 1/8, Batch: 1180/3444, Loss: 0.015021632425487041\n",
      "Epoch: 1/8, Batch: 1190/3444, Loss: 0.029195906594395638\n",
      "Epoch: 1/8, Batch: 1200/3444, Loss: 0.04043564945459366\n",
      "Epoch: 1/8, Batch: 1210/3444, Loss: 0.04893544688820839\n",
      "Epoch: 1/8, Batch: 1220/3444, Loss: 0.04533182829618454\n",
      "Epoch: 1/8, Batch: 1230/3444, Loss: 0.025571566075086594\n",
      "Epoch: 1/8, Batch: 1240/3444, Loss: 0.01673208922147751\n",
      "Epoch: 1/8, Batch: 1250/3444, Loss: 0.019223136827349663\n",
      "Epoch: 1/8, Batch: 1260/3444, Loss: 0.0483308807015419\n",
      "Epoch: 1/8, Batch: 1270/3444, Loss: 0.02663336507976055\n",
      "Epoch: 1/8, Batch: 1280/3444, Loss: 0.018546778708696365\n",
      "Epoch: 1/8, Batch: 1290/3444, Loss: 0.02023334428668022\n",
      "Epoch: 1/8, Batch: 1300/3444, Loss: 0.049606677144765854\n",
      "Epoch: 1/8, Batch: 1310/3444, Loss: 0.024704918265342712\n",
      "Epoch: 1/8, Batch: 1320/3444, Loss: 0.031610578298568726\n",
      "Epoch: 1/8, Batch: 1330/3444, Loss: 0.037926480174064636\n",
      "Epoch: 1/8, Batch: 1340/3444, Loss: 0.07172396034002304\n",
      "Epoch: 1/8, Batch: 1350/3444, Loss: 0.027231959626078606\n",
      "Epoch: 1/8, Batch: 1360/3444, Loss: 0.024208609014749527\n",
      "Epoch: 1/8, Batch: 1370/3444, Loss: 0.0182940736413002\n",
      "Epoch: 1/8, Batch: 1380/3444, Loss: 0.053179167211055756\n",
      "Epoch: 1/8, Batch: 1390/3444, Loss: 0.021792082116007805\n",
      "Epoch: 1/8, Batch: 1400/3444, Loss: 0.03899312764406204\n",
      "Epoch: 1/8, Batch: 1410/3444, Loss: 0.050933197140693665\n",
      "Epoch: 1/8, Batch: 1420/3444, Loss: 0.03850720822811127\n",
      "Epoch: 1/8, Batch: 1430/3444, Loss: 0.02793377824127674\n",
      "Epoch: 1/8, Batch: 1440/3444, Loss: 0.015492563135921955\n",
      "Epoch: 1/8, Batch: 1450/3444, Loss: 0.012358072213828564\n",
      "Epoch: 1/8, Batch: 1460/3444, Loss: 0.018605723977088928\n",
      "Epoch: 1/8, Batch: 1470/3444, Loss: 0.012162753380835056\n",
      "Epoch: 1/8, Batch: 1480/3444, Loss: 0.012260573916137218\n",
      "Epoch: 1/8, Batch: 1490/3444, Loss: 0.019261430948972702\n",
      "Epoch: 1/8, Batch: 1500/3444, Loss: 0.03446219488978386\n",
      "Epoch: 1/8, Batch: 1510/3444, Loss: 0.0283867996186018\n",
      "Epoch: 1/8, Batch: 1520/3444, Loss: 0.021044842898845673\n",
      "Epoch: 1/8, Batch: 1530/3444, Loss: 0.02785252220928669\n",
      "Epoch: 1/8, Batch: 1540/3444, Loss: 0.028723401948809624\n",
      "Epoch: 1/8, Batch: 1550/3444, Loss: 0.048362914472818375\n",
      "Epoch: 1/8, Batch: 1560/3444, Loss: 0.07669512927532196\n",
      "Epoch: 1/8, Batch: 1570/3444, Loss: 0.03372498229146004\n",
      "Epoch: 1/8, Batch: 1580/3444, Loss: 0.020678134635090828\n",
      "Epoch: 1/8, Batch: 1590/3444, Loss: 0.022799739614129066\n",
      "Epoch: 1/8, Batch: 1600/3444, Loss: 0.03943675011396408\n",
      "Epoch: 1/8, Batch: 1610/3444, Loss: 0.019872767850756645\n",
      "Epoch: 1/8, Batch: 1620/3444, Loss: 0.03247130662202835\n",
      "Epoch: 1/8, Batch: 1630/3444, Loss: 0.053717970848083496\n",
      "Epoch: 1/8, Batch: 1640/3444, Loss: 0.022849878296256065\n",
      "Epoch: 1/8, Batch: 1650/3444, Loss: 0.024376390501856804\n",
      "Epoch: 1/8, Batch: 1660/3444, Loss: 0.036523718386888504\n",
      "Epoch: 1/8, Batch: 1670/3444, Loss: 0.07508302479982376\n",
      "Epoch: 1/8, Batch: 1680/3444, Loss: 0.03569277748465538\n",
      "Epoch: 1/8, Batch: 1690/3444, Loss: 0.024874409660696983\n",
      "Epoch: 1/8, Batch: 1700/3444, Loss: 0.039939071983098984\n",
      "Epoch: 1/8, Batch: 1710/3444, Loss: 0.02866005338728428\n",
      "Epoch: 1/8, Batch: 1720/3444, Loss: 0.01839281991124153\n",
      "Epoch: 1/8, Batch: 1730/3444, Loss: 0.016840362921357155\n",
      "Epoch: 1/8, Batch: 1740/3444, Loss: 0.033826276659965515\n",
      "Epoch: 1/8, Batch: 1750/3444, Loss: 0.024167532101273537\n",
      "Epoch: 1/8, Batch: 1760/3444, Loss: 0.014321603812277317\n",
      "Epoch: 1/8, Batch: 1770/3444, Loss: 0.041753340512514114\n",
      "Epoch: 1/8, Batch: 1780/3444, Loss: 0.015633724629878998\n",
      "Epoch: 1/8, Batch: 1790/3444, Loss: 0.03781876713037491\n",
      "Epoch: 1/8, Batch: 1800/3444, Loss: 0.03297651931643486\n",
      "Epoch: 1/8, Batch: 1810/3444, Loss: 0.06586532294750214\n",
      "Epoch: 1/8, Batch: 1820/3444, Loss: 0.0444001629948616\n",
      "Epoch: 1/8, Batch: 1830/3444, Loss: 0.11315157264471054\n",
      "Epoch: 1/8, Batch: 1840/3444, Loss: 0.04002934321761131\n",
      "Epoch: 1/8, Batch: 1850/3444, Loss: 0.029996274039149284\n",
      "Epoch: 1/8, Batch: 1860/3444, Loss: 0.036342695355415344\n",
      "Epoch: 1/8, Batch: 1870/3444, Loss: 0.05253620818257332\n",
      "Epoch: 1/8, Batch: 1880/3444, Loss: 0.019080979749560356\n",
      "Epoch: 1/8, Batch: 1890/3444, Loss: 0.0276170801371336\n",
      "Epoch: 1/8, Batch: 1900/3444, Loss: 0.02364061214029789\n",
      "Epoch: 1/8, Batch: 1910/3444, Loss: 0.04026348143815994\n",
      "Epoch: 1/8, Batch: 1920/3444, Loss: 0.03993098437786102\n",
      "Epoch: 1/8, Batch: 1930/3444, Loss: 0.0579402782022953\n",
      "Epoch: 1/8, Batch: 1940/3444, Loss: 0.0434001125395298\n",
      "Epoch: 1/8, Batch: 1950/3444, Loss: 0.03273327648639679\n",
      "Epoch: 1/8, Batch: 1960/3444, Loss: 0.0196571946144104\n",
      "Epoch: 1/8, Batch: 1970/3444, Loss: 0.013205128721892834\n",
      "Epoch: 1/8, Batch: 1980/3444, Loss: 0.0204643364995718\n",
      "Epoch: 1/8, Batch: 1990/3444, Loss: 0.061256103217601776\n",
      "Epoch: 1/8, Batch: 2000/3444, Loss: 0.041351716965436935\n",
      "Epoch: 1/8, Batch: 2010/3444, Loss: 0.03340720385313034\n",
      "Epoch: 1/8, Batch: 2020/3444, Loss: 0.022005576640367508\n",
      "Epoch: 1/8, Batch: 2030/3444, Loss: 0.01564260944724083\n",
      "Epoch: 1/8, Batch: 2040/3444, Loss: 0.02476334199309349\n",
      "Epoch: 1/8, Batch: 2050/3444, Loss: 0.038214392960071564\n",
      "Epoch: 1/8, Batch: 2060/3444, Loss: 0.04790458083152771\n",
      "Epoch: 1/8, Batch: 2070/3444, Loss: 0.04079768434166908\n",
      "Epoch: 1/8, Batch: 2080/3444, Loss: 0.021826742216944695\n",
      "Epoch: 1/8, Batch: 2090/3444, Loss: 0.020425163209438324\n",
      "Epoch: 1/8, Batch: 2100/3444, Loss: 0.0283758956938982\n",
      "Epoch: 1/8, Batch: 2110/3444, Loss: 0.08384931087493896\n",
      "Epoch: 1/8, Batch: 2120/3444, Loss: 0.033276159316301346\n",
      "Epoch: 1/8, Batch: 2130/3444, Loss: 0.029321670532226562\n",
      "Epoch: 1/8, Batch: 2140/3444, Loss: 0.0608024075627327\n",
      "Epoch: 1/8, Batch: 2150/3444, Loss: 0.046553466469049454\n",
      "Epoch: 1/8, Batch: 2160/3444, Loss: 0.04726444184780121\n",
      "Epoch: 1/8, Batch: 2170/3444, Loss: 0.0483715757727623\n",
      "Epoch: 1/8, Batch: 2180/3444, Loss: 0.024050483480095863\n",
      "Epoch: 1/8, Batch: 2190/3444, Loss: 0.019367894157767296\n",
      "Epoch: 1/8, Batch: 2200/3444, Loss: 0.023695634678006172\n",
      "Epoch: 1/8, Batch: 2210/3444, Loss: 0.012775632552802563\n",
      "Epoch: 1/8, Batch: 2220/3444, Loss: 0.016051307320594788\n",
      "Epoch: 1/8, Batch: 2230/3444, Loss: 0.028836233541369438\n",
      "Epoch: 1/8, Batch: 2240/3444, Loss: 0.039367981255054474\n",
      "Epoch: 1/8, Batch: 2250/3444, Loss: 0.02237127162516117\n",
      "Epoch: 1/8, Batch: 2260/3444, Loss: 0.038983140140771866\n",
      "Epoch: 1/8, Batch: 2270/3444, Loss: 0.040413931012153625\n",
      "Epoch: 1/8, Batch: 2280/3444, Loss: 0.03443821519613266\n",
      "Epoch: 1/8, Batch: 2290/3444, Loss: 0.06313390284776688\n",
      "Epoch: 1/8, Batch: 2300/3444, Loss: 0.030000200495123863\n",
      "Epoch: 1/8, Batch: 2310/3444, Loss: 0.04220714047551155\n",
      "Epoch: 1/8, Batch: 2320/3444, Loss: 0.03592303767800331\n",
      "Epoch: 1/8, Batch: 2330/3444, Loss: 0.03982491418719292\n",
      "Epoch: 1/8, Batch: 2340/3444, Loss: 0.04013907536864281\n",
      "Epoch: 1/8, Batch: 2350/3444, Loss: 0.010341489687561989\n",
      "Epoch: 1/8, Batch: 2360/3444, Loss: 0.035600803792476654\n",
      "Epoch: 1/8, Batch: 2370/3444, Loss: 0.03925774246454239\n",
      "Epoch: 1/8, Batch: 2380/3444, Loss: 0.0436759851872921\n",
      "Epoch: 1/8, Batch: 2390/3444, Loss: 0.020205188542604446\n",
      "Epoch: 1/8, Batch: 2400/3444, Loss: 0.029444653540849686\n",
      "Epoch: 1/8, Batch: 2410/3444, Loss: 0.04037812724709511\n",
      "Epoch: 1/8, Batch: 2420/3444, Loss: 0.037524815648794174\n",
      "Epoch: 1/8, Batch: 2430/3444, Loss: 0.013225752860307693\n",
      "Epoch: 1/8, Batch: 2440/3444, Loss: 0.011756304651498795\n",
      "Epoch: 1/8, Batch: 2450/3444, Loss: 0.016090452671051025\n",
      "Epoch: 1/8, Batch: 2460/3444, Loss: 0.01720401830971241\n",
      "Epoch: 1/8, Batch: 2470/3444, Loss: 0.05881514400243759\n",
      "Epoch: 1/8, Batch: 2480/3444, Loss: 0.09382013976573944\n",
      "Epoch: 1/8, Batch: 2490/3444, Loss: 0.10119397938251495\n",
      "Epoch: 1/8, Batch: 2500/3444, Loss: 0.024077406153082848\n",
      "Epoch: 1/8, Batch: 2510/3444, Loss: 0.01881687343120575\n",
      "Epoch: 1/8, Batch: 2520/3444, Loss: 0.0380014143884182\n",
      "Epoch: 1/8, Batch: 2530/3444, Loss: 0.014690559357404709\n",
      "Epoch: 1/8, Batch: 2540/3444, Loss: 0.03599255904555321\n",
      "Epoch: 1/8, Batch: 2550/3444, Loss: 0.039264973253011703\n",
      "Epoch: 1/8, Batch: 2560/3444, Loss: 0.057477593421936035\n",
      "Epoch: 1/8, Batch: 2570/3444, Loss: 0.020714987069368362\n",
      "Epoch: 1/8, Batch: 2580/3444, Loss: 0.02520590089261532\n",
      "Epoch: 1/8, Batch: 2590/3444, Loss: 0.0346190370619297\n",
      "Epoch: 1/8, Batch: 2600/3444, Loss: 0.029213326051831245\n",
      "Epoch: 1/8, Batch: 2610/3444, Loss: 0.01905009336769581\n",
      "Epoch: 1/8, Batch: 2620/3444, Loss: 0.06980715692043304\n",
      "Epoch: 1/8, Batch: 2630/3444, Loss: 0.021503642201423645\n",
      "Epoch: 1/8, Batch: 2640/3444, Loss: 0.040751054883003235\n",
      "Epoch: 1/8, Batch: 2650/3444, Loss: 0.0240430049598217\n",
      "Epoch: 1/8, Batch: 2660/3444, Loss: 0.04026484116911888\n",
      "Epoch: 1/8, Batch: 2670/3444, Loss: 0.01367369294166565\n",
      "Epoch: 1/8, Batch: 2680/3444, Loss: 0.024425659328699112\n",
      "Epoch: 1/8, Batch: 2690/3444, Loss: 0.06261315941810608\n",
      "Epoch: 1/8, Batch: 2700/3444, Loss: 0.027607787400484085\n",
      "Epoch: 1/8, Batch: 2710/3444, Loss: 0.03749433159828186\n",
      "Epoch: 1/8, Batch: 2720/3444, Loss: 0.01759534887969494\n",
      "Epoch: 1/8, Batch: 2730/3444, Loss: 0.018174665048718452\n",
      "Epoch: 1/8, Batch: 2740/3444, Loss: 0.02934281900525093\n",
      "Epoch: 1/8, Batch: 2750/3444, Loss: 0.013570445589721203\n",
      "Epoch: 1/8, Batch: 2760/3444, Loss: 0.02303077094256878\n",
      "Epoch: 1/8, Batch: 2770/3444, Loss: 0.03386121988296509\n",
      "Epoch: 1/8, Batch: 2780/3444, Loss: 0.019249912351369858\n",
      "Epoch: 1/8, Batch: 2790/3444, Loss: 0.04249218851327896\n",
      "Epoch: 1/8, Batch: 2800/3444, Loss: 0.024959590286016464\n",
      "Epoch: 1/8, Batch: 2810/3444, Loss: 0.011103076860308647\n",
      "Epoch: 1/8, Batch: 2820/3444, Loss: 0.042727138847112656\n",
      "Epoch: 1/8, Batch: 2830/3444, Loss: 0.040873933583498\n",
      "Epoch: 1/8, Batch: 2840/3444, Loss: 0.026814131066203117\n",
      "Epoch: 1/8, Batch: 2850/3444, Loss: 0.032571155577898026\n",
      "Epoch: 1/8, Batch: 2860/3444, Loss: 0.01943480409681797\n",
      "Epoch: 1/8, Batch: 2870/3444, Loss: 0.015540779568254948\n",
      "Epoch: 1/8, Batch: 2880/3444, Loss: 0.035014715045690536\n",
      "Epoch: 1/8, Batch: 2890/3444, Loss: 0.018421264365315437\n",
      "Epoch: 1/8, Batch: 2900/3444, Loss: 0.02243214286863804\n",
      "Epoch: 1/8, Batch: 2910/3444, Loss: 0.030751578509807587\n",
      "Epoch: 1/8, Batch: 2920/3444, Loss: 0.035672277212142944\n",
      "Epoch: 1/8, Batch: 2930/3444, Loss: 0.047807976603507996\n",
      "Epoch: 1/8, Batch: 2940/3444, Loss: 0.02277585119009018\n",
      "Epoch: 1/8, Batch: 2950/3444, Loss: 0.030427666381001472\n",
      "Epoch: 1/8, Batch: 2960/3444, Loss: 0.030447248369455338\n",
      "Epoch: 1/8, Batch: 2970/3444, Loss: 0.021983472630381584\n",
      "Epoch: 1/8, Batch: 2980/3444, Loss: 0.021048113703727722\n",
      "Epoch: 1/8, Batch: 2990/3444, Loss: 0.02227705344557762\n",
      "Epoch: 1/8, Batch: 3000/3444, Loss: 0.0412948802113533\n",
      "Epoch: 1/8, Batch: 3010/3444, Loss: 0.06678495556116104\n",
      "Epoch: 1/8, Batch: 3020/3444, Loss: 0.02894892729818821\n",
      "Epoch: 1/8, Batch: 3030/3444, Loss: 0.038158200681209564\n",
      "Epoch: 1/8, Batch: 3040/3444, Loss: 0.02144421637058258\n",
      "Epoch: 1/8, Batch: 3050/3444, Loss: 0.027622753754258156\n",
      "Epoch: 1/8, Batch: 3060/3444, Loss: 0.03978883475065231\n",
      "Epoch: 1/8, Batch: 3070/3444, Loss: 0.028568750247359276\n",
      "Epoch: 1/8, Batch: 3080/3444, Loss: 0.03239745274186134\n",
      "Epoch: 1/8, Batch: 3090/3444, Loss: 0.014718325808644295\n",
      "Epoch: 1/8, Batch: 3100/3444, Loss: 0.015000835992395878\n",
      "Epoch: 1/8, Batch: 3110/3444, Loss: 0.025029687210917473\n",
      "Epoch: 1/8, Batch: 3120/3444, Loss: 0.028630360960960388\n",
      "Epoch: 1/8, Batch: 3130/3444, Loss: 0.0415898822247982\n",
      "Epoch: 1/8, Batch: 3140/3444, Loss: 0.017899032682180405\n",
      "Epoch: 1/8, Batch: 3150/3444, Loss: 0.014644676819443703\n",
      "Epoch: 1/8, Batch: 3160/3444, Loss: 0.09511371701955795\n",
      "Epoch: 1/8, Batch: 3170/3444, Loss: 0.013476000167429447\n",
      "Epoch: 1/8, Batch: 3180/3444, Loss: 0.042277876287698746\n",
      "Epoch: 1/8, Batch: 3190/3444, Loss: 0.039327044039964676\n",
      "Epoch: 1/8, Batch: 3200/3444, Loss: 0.029061928391456604\n",
      "Epoch: 1/8, Batch: 3210/3444, Loss: 0.012485948391258717\n",
      "Epoch: 1/8, Batch: 3220/3444, Loss: 0.02109186351299286\n",
      "Epoch: 1/8, Batch: 3230/3444, Loss: 0.02971677854657173\n",
      "Epoch: 1/8, Batch: 3240/3444, Loss: 0.028406931087374687\n",
      "Epoch: 1/8, Batch: 3250/3444, Loss: 0.04691509157419205\n",
      "Epoch: 1/8, Batch: 3260/3444, Loss: 0.038296233862638474\n",
      "Epoch: 1/8, Batch: 3270/3444, Loss: 0.014101257547736168\n",
      "Epoch: 1/8, Batch: 3280/3444, Loss: 0.022945169359445572\n",
      "Epoch: 1/8, Batch: 3290/3444, Loss: 0.021591613069176674\n",
      "Epoch: 1/8, Batch: 3300/3444, Loss: 0.030298538506031036\n",
      "Epoch: 1/8, Batch: 3310/3444, Loss: 0.025762414559721947\n",
      "Epoch: 1/8, Batch: 3320/3444, Loss: 0.01732691191136837\n",
      "Epoch: 1/8, Batch: 3330/3444, Loss: 0.017434146255254745\n",
      "Epoch: 1/8, Batch: 3340/3444, Loss: 0.006725294515490532\n",
      "Epoch: 1/8, Batch: 3350/3444, Loss: 0.04338665306568146\n",
      "Epoch: 1/8, Batch: 3360/3444, Loss: 0.032322291284799576\n",
      "Epoch: 1/8, Batch: 3370/3444, Loss: 0.021771997213363647\n",
      "Epoch: 1/8, Batch: 3380/3444, Loss: 0.03446382284164429\n",
      "Epoch: 1/8, Batch: 3390/3444, Loss: 0.04280317574739456\n",
      "Epoch: 1/8, Batch: 3400/3444, Loss: 0.035573575645685196\n",
      "Epoch: 1/8, Batch: 3410/3444, Loss: 0.043472569435834885\n",
      "Epoch: 1/8, Batch: 3420/3444, Loss: 0.013722676783800125\n",
      "Epoch: 1/8, Batch: 3430/3444, Loss: 0.027986424043774605\n",
      "Epoch: 1/8, Batch: 3440/3444, Loss: 0.03713509440422058\n",
      "Epoch: 1/8, Val Loss: 0.019850965957324974\n",
      "Epoch: 2/8, Batch: 10/3444, Loss: 0.0335422158241272\n",
      "Epoch: 2/8, Batch: 20/3444, Loss: 0.049814675003290176\n",
      "Epoch: 2/8, Batch: 30/3444, Loss: 0.012092245742678642\n",
      "Epoch: 2/8, Batch: 40/3444, Loss: 0.07687780261039734\n",
      "Epoch: 2/8, Batch: 50/3444, Loss: 0.04083993285894394\n",
      "Epoch: 2/8, Batch: 60/3444, Loss: 0.027734698727726936\n",
      "Epoch: 2/8, Batch: 70/3444, Loss: 0.022864261642098427\n",
      "Epoch: 2/8, Batch: 80/3444, Loss: 0.019454048946499825\n",
      "Epoch: 2/8, Batch: 90/3444, Loss: 0.05007927492260933\n",
      "Epoch: 2/8, Batch: 100/3444, Loss: 0.12479013949632645\n",
      "Epoch: 2/8, Batch: 110/3444, Loss: 0.030927492305636406\n",
      "Epoch: 2/8, Batch: 120/3444, Loss: 0.04689914733171463\n",
      "Epoch: 2/8, Batch: 130/3444, Loss: 0.027649113908410072\n",
      "Epoch: 2/8, Batch: 140/3444, Loss: 0.03193604201078415\n",
      "Epoch: 2/8, Batch: 150/3444, Loss: 0.025223903357982635\n",
      "Epoch: 2/8, Batch: 160/3444, Loss: 0.03497590869665146\n",
      "Epoch: 2/8, Batch: 170/3444, Loss: 0.04379011318087578\n",
      "Epoch: 2/8, Batch: 180/3444, Loss: 0.0475422665476799\n",
      "Epoch: 2/8, Batch: 190/3444, Loss: 0.03239225968718529\n",
      "Epoch: 2/8, Batch: 200/3444, Loss: 0.03353725001215935\n",
      "Epoch: 2/8, Batch: 210/3444, Loss: 0.01932806335389614\n",
      "Epoch: 2/8, Batch: 220/3444, Loss: 0.02771614119410515\n",
      "Epoch: 2/8, Batch: 230/3444, Loss: 0.039500802755355835\n",
      "Epoch: 2/8, Batch: 240/3444, Loss: 0.022594522684812546\n",
      "Epoch: 2/8, Batch: 250/3444, Loss: 0.013851935043931007\n",
      "Epoch: 2/8, Batch: 260/3444, Loss: 0.022874031215906143\n",
      "Epoch: 2/8, Batch: 270/3444, Loss: 0.03753672167658806\n",
      "Epoch: 2/8, Batch: 280/3444, Loss: 0.07071171700954437\n",
      "Epoch: 2/8, Batch: 290/3444, Loss: 0.025575432926416397\n",
      "Epoch: 2/8, Batch: 300/3444, Loss: 0.036539435386657715\n",
      "Epoch: 2/8, Batch: 310/3444, Loss: 0.029868341982364655\n",
      "Epoch: 2/8, Batch: 320/3444, Loss: 0.08688981831073761\n",
      "Epoch: 2/8, Batch: 330/3444, Loss: 0.07325929403305054\n",
      "Epoch: 2/8, Batch: 340/3444, Loss: 0.0350685715675354\n",
      "Epoch: 2/8, Batch: 350/3444, Loss: 0.012226376682519913\n",
      "Epoch: 2/8, Batch: 360/3444, Loss: 0.06630498915910721\n",
      "Epoch: 2/8, Batch: 370/3444, Loss: 0.026006584987044334\n",
      "Epoch: 2/8, Batch: 380/3444, Loss: 0.037904273718595505\n",
      "Epoch: 2/8, Batch: 390/3444, Loss: 0.019518684595823288\n",
      "Epoch: 2/8, Batch: 400/3444, Loss: 0.011053255759179592\n",
      "Epoch: 2/8, Batch: 410/3444, Loss: 0.0333070382475853\n",
      "Epoch: 2/8, Batch: 420/3444, Loss: 0.06531482189893723\n",
      "Epoch: 2/8, Batch: 430/3444, Loss: 0.03137609735131264\n",
      "Epoch: 2/8, Batch: 440/3444, Loss: 0.08311251550912857\n",
      "Epoch: 2/8, Batch: 450/3444, Loss: 0.02663934789597988\n",
      "Epoch: 2/8, Batch: 460/3444, Loss: 0.03488296642899513\n",
      "Epoch: 2/8, Batch: 470/3444, Loss: 0.019543545320630074\n",
      "Epoch: 2/8, Batch: 480/3444, Loss: 0.016123920679092407\n",
      "Epoch: 2/8, Batch: 490/3444, Loss: 0.02131236344575882\n",
      "Epoch: 2/8, Batch: 500/3444, Loss: 0.02641228586435318\n",
      "Epoch: 2/8, Batch: 510/3444, Loss: 0.024003393948078156\n",
      "Epoch: 2/8, Batch: 520/3444, Loss: 0.02143477462232113\n",
      "Epoch: 2/8, Batch: 530/3444, Loss: 0.016978882253170013\n",
      "Epoch: 2/8, Batch: 540/3444, Loss: 0.01901065930724144\n",
      "Epoch: 2/8, Batch: 550/3444, Loss: 0.01396836619824171\n",
      "Epoch: 2/8, Batch: 560/3444, Loss: 0.14425788819789886\n",
      "Epoch: 2/8, Batch: 570/3444, Loss: 0.04887665808200836\n",
      "Epoch: 2/8, Batch: 580/3444, Loss: 0.029293477535247803\n",
      "Epoch: 2/8, Batch: 590/3444, Loss: 0.03547026589512825\n",
      "Epoch: 2/8, Batch: 600/3444, Loss: 0.0287974551320076\n",
      "Epoch: 2/8, Batch: 610/3444, Loss: 0.048767685890197754\n",
      "Epoch: 2/8, Batch: 620/3444, Loss: 0.03394560515880585\n",
      "Epoch: 2/8, Batch: 630/3444, Loss: 0.022534320130944252\n",
      "Epoch: 2/8, Batch: 640/3444, Loss: 0.022899990901350975\n",
      "Epoch: 2/8, Batch: 650/3444, Loss: 0.029649674892425537\n",
      "Epoch: 2/8, Batch: 660/3444, Loss: 0.04538526013493538\n",
      "Epoch: 2/8, Batch: 670/3444, Loss: 0.01852804236114025\n",
      "Epoch: 2/8, Batch: 680/3444, Loss: 0.034955814480781555\n",
      "Epoch: 2/8, Batch: 690/3444, Loss: 0.033545732498168945\n",
      "Epoch: 2/8, Batch: 700/3444, Loss: 0.03247220814228058\n",
      "Epoch: 2/8, Batch: 710/3444, Loss: 0.023396456614136696\n",
      "Epoch: 2/8, Batch: 720/3444, Loss: 0.02481970377266407\n",
      "Epoch: 2/8, Batch: 730/3444, Loss: 0.0290085319429636\n",
      "Epoch: 2/8, Batch: 740/3444, Loss: 0.02745508775115013\n",
      "Epoch: 2/8, Batch: 750/3444, Loss: 0.042920079082250595\n",
      "Epoch: 2/8, Batch: 760/3444, Loss: 0.018748681992292404\n",
      "Epoch: 2/8, Batch: 770/3444, Loss: 0.059943534433841705\n",
      "Epoch: 2/8, Batch: 780/3444, Loss: 0.05734629184007645\n",
      "Epoch: 2/8, Batch: 790/3444, Loss: 0.047615718096494675\n",
      "Epoch: 2/8, Batch: 800/3444, Loss: 0.03202683851122856\n",
      "Epoch: 2/8, Batch: 810/3444, Loss: 0.01254796702414751\n",
      "Epoch: 2/8, Batch: 820/3444, Loss: 0.04500417783856392\n",
      "Epoch: 2/8, Batch: 830/3444, Loss: 0.027968410402536392\n",
      "Epoch: 2/8, Batch: 840/3444, Loss: 0.04073464497923851\n",
      "Epoch: 2/8, Batch: 850/3444, Loss: 0.07545152306556702\n",
      "Epoch: 2/8, Batch: 860/3444, Loss: 0.04523336887359619\n",
      "Epoch: 2/8, Batch: 870/3444, Loss: 0.04776851087808609\n",
      "Epoch: 2/8, Batch: 880/3444, Loss: 0.030259856954216957\n",
      "Epoch: 2/8, Batch: 890/3444, Loss: 0.024158407002687454\n",
      "Epoch: 2/8, Batch: 900/3444, Loss: 0.01062307320535183\n",
      "Epoch: 2/8, Batch: 910/3444, Loss: 0.032509781420230865\n",
      "Epoch: 2/8, Batch: 920/3444, Loss: 0.04095759242773056\n",
      "Epoch: 2/8, Batch: 930/3444, Loss: 0.07045622915029526\n",
      "Epoch: 2/8, Batch: 940/3444, Loss: 0.0190252885222435\n",
      "Epoch: 2/8, Batch: 950/3444, Loss: 0.023353824391961098\n",
      "Epoch: 2/8, Batch: 960/3444, Loss: 0.06834539771080017\n",
      "Epoch: 2/8, Batch: 970/3444, Loss: 0.04131545126438141\n",
      "Epoch: 2/8, Batch: 980/3444, Loss: 0.012911807745695114\n",
      "Epoch: 2/8, Batch: 990/3444, Loss: 0.04416895657777786\n",
      "Epoch: 2/8, Batch: 1000/3444, Loss: 0.033394329249858856\n",
      "Epoch: 2/8, Batch: 1010/3444, Loss: 0.03146013990044594\n",
      "Epoch: 2/8, Batch: 1020/3444, Loss: 0.02425626665353775\n",
      "Epoch: 2/8, Batch: 1030/3444, Loss: 0.03266727924346924\n",
      "Epoch: 2/8, Batch: 1040/3444, Loss: 0.0165349543094635\n",
      "Epoch: 2/8, Batch: 1050/3444, Loss: 0.012206722982227802\n",
      "Epoch: 2/8, Batch: 1060/3444, Loss: 0.04154479503631592\n",
      "Epoch: 2/8, Batch: 1070/3444, Loss: 0.025821208953857422\n",
      "Epoch: 2/8, Batch: 1080/3444, Loss: 0.019362948834896088\n",
      "Epoch: 2/8, Batch: 1090/3444, Loss: 0.039436910301446915\n",
      "Epoch: 2/8, Batch: 1100/3444, Loss: 0.026167893782258034\n",
      "Epoch: 2/8, Batch: 1110/3444, Loss: 0.02980010397732258\n",
      "Epoch: 2/8, Batch: 1120/3444, Loss: 0.03249848261475563\n",
      "Epoch: 2/8, Batch: 1130/3444, Loss: 0.03971168398857117\n",
      "Epoch: 2/8, Batch: 1140/3444, Loss: 0.02487499639391899\n",
      "Epoch: 2/8, Batch: 1150/3444, Loss: 0.04558102414011955\n",
      "Epoch: 2/8, Batch: 1160/3444, Loss: 0.02995087020099163\n",
      "Epoch: 2/8, Batch: 1170/3444, Loss: 0.03376765176653862\n",
      "Epoch: 2/8, Batch: 1180/3444, Loss: 0.037582919001579285\n",
      "Epoch: 2/8, Batch: 1190/3444, Loss: 0.03648950532078743\n",
      "Epoch: 2/8, Batch: 1200/3444, Loss: 0.03540990501642227\n",
      "Epoch: 2/8, Batch: 1210/3444, Loss: 0.07058307528495789\n",
      "Epoch: 2/8, Batch: 1220/3444, Loss: 0.03973773121833801\n",
      "Epoch: 2/8, Batch: 1230/3444, Loss: 0.010706583969295025\n",
      "Epoch: 2/8, Batch: 1240/3444, Loss: 0.031934790313243866\n",
      "Epoch: 2/8, Batch: 1250/3444, Loss: 0.02598843351006508\n",
      "Epoch: 2/8, Batch: 1260/3444, Loss: 0.05639699473977089\n",
      "Epoch: 2/8, Batch: 1270/3444, Loss: 0.02466616965830326\n",
      "Epoch: 2/8, Batch: 1280/3444, Loss: 0.021877899765968323\n",
      "Epoch: 2/8, Batch: 1290/3444, Loss: 0.05414905026555061\n",
      "Epoch: 2/8, Batch: 1300/3444, Loss: 0.021636800840497017\n",
      "Epoch: 2/8, Batch: 1310/3444, Loss: 0.05170759558677673\n",
      "Epoch: 2/8, Batch: 1320/3444, Loss: 0.0328839085996151\n",
      "Epoch: 2/8, Batch: 1330/3444, Loss: 0.030505666509270668\n",
      "Epoch: 2/8, Batch: 1340/3444, Loss: 0.018736740574240685\n",
      "Epoch: 2/8, Batch: 1350/3444, Loss: 0.03317521885037422\n",
      "Epoch: 2/8, Batch: 1360/3444, Loss: 0.06479945778846741\n",
      "Epoch: 2/8, Batch: 1370/3444, Loss: 0.0400172583758831\n",
      "Epoch: 2/8, Batch: 1380/3444, Loss: 0.039815038442611694\n",
      "Epoch: 2/8, Batch: 1390/3444, Loss: 0.053874943405389786\n",
      "Epoch: 2/8, Batch: 1400/3444, Loss: 0.029296601191163063\n",
      "Epoch: 2/8, Batch: 1410/3444, Loss: 0.03731352463364601\n",
      "Epoch: 2/8, Batch: 1420/3444, Loss: 0.08550374954938889\n",
      "Epoch: 2/8, Batch: 1430/3444, Loss: 0.07391417026519775\n",
      "Epoch: 2/8, Batch: 1440/3444, Loss: 0.025856494903564453\n",
      "Epoch: 2/8, Batch: 1450/3444, Loss: 0.03338320180773735\n",
      "Epoch: 2/8, Batch: 1460/3444, Loss: 0.03737727925181389\n",
      "Epoch: 2/8, Batch: 1470/3444, Loss: 0.02372058480978012\n",
      "Epoch: 2/8, Batch: 1480/3444, Loss: 0.03332303464412689\n",
      "Epoch: 2/8, Batch: 1490/3444, Loss: 0.022962668910622597\n",
      "Epoch: 2/8, Batch: 1500/3444, Loss: 0.023610766977071762\n",
      "Epoch: 2/8, Batch: 1510/3444, Loss: 0.03130577504634857\n",
      "Epoch: 2/8, Batch: 1520/3444, Loss: 0.036319125443696976\n",
      "Epoch: 2/8, Batch: 1530/3444, Loss: 0.027442242950201035\n",
      "Epoch: 2/8, Batch: 1540/3444, Loss: 0.012768284417688847\n",
      "Epoch: 2/8, Batch: 1550/3444, Loss: 0.017221208661794662\n",
      "Epoch: 2/8, Batch: 1560/3444, Loss: 0.01334614772349596\n",
      "Epoch: 2/8, Batch: 1570/3444, Loss: 0.020655693486332893\n",
      "Epoch: 2/8, Batch: 1580/3444, Loss: 0.03338463604450226\n",
      "Epoch: 2/8, Batch: 1590/3444, Loss: 0.02436867170035839\n",
      "Epoch: 2/8, Batch: 1600/3444, Loss: 0.027823107317090034\n",
      "Epoch: 2/8, Batch: 1610/3444, Loss: 0.021599719300866127\n",
      "Epoch: 2/8, Batch: 1620/3444, Loss: 0.02019365318119526\n",
      "Epoch: 2/8, Batch: 1630/3444, Loss: 0.03200599551200867\n",
      "Epoch: 2/8, Batch: 1640/3444, Loss: 0.030308425426483154\n",
      "Epoch: 2/8, Batch: 1650/3444, Loss: 0.01886744797229767\n",
      "Epoch: 2/8, Batch: 1660/3444, Loss: 0.04397733509540558\n",
      "Epoch: 2/8, Batch: 1670/3444, Loss: 0.0198171678930521\n",
      "Epoch: 2/8, Batch: 1680/3444, Loss: 0.04560239613056183\n",
      "Epoch: 2/8, Batch: 1690/3444, Loss: 0.023793954402208328\n",
      "Epoch: 2/8, Batch: 1700/3444, Loss: 0.10674125701189041\n",
      "Epoch: 2/8, Batch: 1710/3444, Loss: 0.010421973653137684\n",
      "Epoch: 2/8, Batch: 1720/3444, Loss: 0.03210420534014702\n",
      "Epoch: 2/8, Batch: 1730/3444, Loss: 0.05717148631811142\n",
      "Epoch: 2/8, Batch: 1740/3444, Loss: 0.03055669739842415\n",
      "Epoch: 2/8, Batch: 1750/3444, Loss: 0.03127153217792511\n",
      "Epoch: 2/8, Batch: 1760/3444, Loss: 0.0162823386490345\n",
      "Epoch: 2/8, Batch: 1770/3444, Loss: 0.02119920775294304\n",
      "Epoch: 2/8, Batch: 1780/3444, Loss: 0.015279965475201607\n",
      "Epoch: 2/8, Batch: 1790/3444, Loss: 0.01801718771457672\n",
      "Epoch: 2/8, Batch: 1800/3444, Loss: 0.03431768715381622\n",
      "Epoch: 2/8, Batch: 1810/3444, Loss: 0.03799869492650032\n",
      "Epoch: 2/8, Batch: 1820/3444, Loss: 0.024541165679693222\n",
      "Epoch: 2/8, Batch: 1830/3444, Loss: 0.04077468812465668\n",
      "Epoch: 2/8, Batch: 1840/3444, Loss: 0.022439489141106606\n",
      "Epoch: 2/8, Batch: 1850/3444, Loss: 0.03312376141548157\n",
      "Epoch: 2/8, Batch: 1860/3444, Loss: 0.049033623188734055\n",
      "Epoch: 2/8, Batch: 1870/3444, Loss: 0.0317344032227993\n",
      "Epoch: 2/8, Batch: 1880/3444, Loss: 0.01742149144411087\n",
      "Epoch: 2/8, Batch: 1890/3444, Loss: 0.025868790224194527\n",
      "Epoch: 2/8, Batch: 1900/3444, Loss: 0.0667673647403717\n",
      "Epoch: 2/8, Batch: 1910/3444, Loss: 0.012034574523568153\n",
      "Epoch: 2/8, Batch: 1920/3444, Loss: 0.015120758675038815\n",
      "Epoch: 2/8, Batch: 1930/3444, Loss: 0.05375313386321068\n",
      "Epoch: 2/8, Batch: 1940/3444, Loss: 0.012576709501445293\n",
      "Epoch: 2/8, Batch: 1950/3444, Loss: 0.068067766726017\n",
      "Epoch: 2/8, Batch: 1960/3444, Loss: 0.0406891331076622\n",
      "Epoch: 2/8, Batch: 1970/3444, Loss: 0.05342448502779007\n",
      "Epoch: 2/8, Batch: 1980/3444, Loss: 0.036911848932504654\n",
      "Epoch: 2/8, Batch: 1990/3444, Loss: 0.03441488742828369\n",
      "Epoch: 2/8, Batch: 2000/3444, Loss: 0.017286255955696106\n",
      "Epoch: 2/8, Batch: 2010/3444, Loss: 0.01772361993789673\n",
      "Epoch: 2/8, Batch: 2020/3444, Loss: 0.026676766574382782\n",
      "Epoch: 2/8, Batch: 2030/3444, Loss: 0.026096684858202934\n",
      "Epoch: 2/8, Batch: 2040/3444, Loss: 0.047378357499837875\n",
      "Epoch: 2/8, Batch: 2050/3444, Loss: 0.03366139903664589\n",
      "Epoch: 2/8, Batch: 2060/3444, Loss: 0.014505093917250633\n",
      "Epoch: 2/8, Batch: 2070/3444, Loss: 0.01056220568716526\n",
      "Epoch: 2/8, Batch: 2080/3444, Loss: 0.025939757004380226\n",
      "Epoch: 2/8, Batch: 2090/3444, Loss: 0.023854650557041168\n",
      "Epoch: 2/8, Batch: 2100/3444, Loss: 0.019424082711338997\n",
      "Epoch: 2/8, Batch: 2110/3444, Loss: 0.049327749758958817\n",
      "Epoch: 2/8, Batch: 2120/3444, Loss: 0.061626702547073364\n",
      "Epoch: 2/8, Batch: 2130/3444, Loss: 0.07343762367963791\n",
      "Epoch: 2/8, Batch: 2140/3444, Loss: 0.01991395093500614\n",
      "Epoch: 2/8, Batch: 2150/3444, Loss: 0.04018338397145271\n",
      "Epoch: 2/8, Batch: 2160/3444, Loss: 0.01868620328605175\n",
      "Epoch: 2/8, Batch: 2170/3444, Loss: 0.034854527562856674\n",
      "Epoch: 2/8, Batch: 2180/3444, Loss: 0.01932501792907715\n",
      "Epoch: 2/8, Batch: 2190/3444, Loss: 0.0291037205606699\n",
      "Epoch: 2/8, Batch: 2200/3444, Loss: 0.026563400402665138\n",
      "Epoch: 2/8, Batch: 2210/3444, Loss: 0.011767384596168995\n",
      "Epoch: 2/8, Batch: 2220/3444, Loss: 0.09216675162315369\n",
      "Epoch: 2/8, Batch: 2230/3444, Loss: 0.02664206735789776\n",
      "Epoch: 2/8, Batch: 2240/3444, Loss: 0.09491276741027832\n",
      "Epoch: 2/8, Batch: 2250/3444, Loss: 0.028314856812357903\n",
      "Epoch: 2/8, Batch: 2260/3444, Loss: 0.01964362896978855\n",
      "Epoch: 2/8, Batch: 2270/3444, Loss: 0.05102521553635597\n",
      "Epoch: 2/8, Batch: 2280/3444, Loss: 0.038468144834041595\n",
      "Epoch: 2/8, Batch: 2290/3444, Loss: 0.019831912592053413\n",
      "Epoch: 2/8, Batch: 2300/3444, Loss: 0.016533955931663513\n",
      "Epoch: 2/8, Batch: 2310/3444, Loss: 0.023252446204423904\n",
      "Epoch: 2/8, Batch: 2320/3444, Loss: 0.02364317886531353\n",
      "Epoch: 2/8, Batch: 2330/3444, Loss: 0.021952969953417778\n",
      "Epoch: 2/8, Batch: 2340/3444, Loss: 0.039259422570466995\n",
      "Epoch: 2/8, Batch: 2350/3444, Loss: 0.026081904768943787\n",
      "Epoch: 2/8, Batch: 2360/3444, Loss: 0.009916202165186405\n",
      "Epoch: 2/8, Batch: 2370/3444, Loss: 0.03297882899641991\n",
      "Epoch: 2/8, Batch: 2380/3444, Loss: 0.035624872893095016\n",
      "Epoch: 2/8, Batch: 2390/3444, Loss: 0.04196852818131447\n",
      "Epoch: 2/8, Batch: 2400/3444, Loss: 0.02223922871053219\n",
      "Epoch: 2/8, Batch: 2410/3444, Loss: 0.045444559305906296\n",
      "Epoch: 2/8, Batch: 2420/3444, Loss: 0.03594798222184181\n",
      "Epoch: 2/8, Batch: 2430/3444, Loss: 0.0307026170194149\n",
      "Epoch: 2/8, Batch: 2440/3444, Loss: 0.06814828515052795\n",
      "Epoch: 2/8, Batch: 2450/3444, Loss: 0.024730278179049492\n",
      "Epoch: 2/8, Batch: 2460/3444, Loss: 0.018477575853466988\n",
      "Epoch: 2/8, Batch: 2470/3444, Loss: 0.03432468697428703\n",
      "Epoch: 2/8, Batch: 2480/3444, Loss: 0.05482280254364014\n",
      "Epoch: 2/8, Batch: 2490/3444, Loss: 0.015420729294419289\n",
      "Epoch: 2/8, Batch: 2500/3444, Loss: 0.03465590998530388\n",
      "Epoch: 2/8, Batch: 2510/3444, Loss: 0.01960987225174904\n",
      "Epoch: 2/8, Batch: 2520/3444, Loss: 0.036353398114442825\n",
      "Epoch: 2/8, Batch: 2530/3444, Loss: 0.01837053708732128\n",
      "Epoch: 2/8, Batch: 2540/3444, Loss: 0.02285458706319332\n",
      "Epoch: 2/8, Batch: 2550/3444, Loss: 0.01873285509645939\n",
      "Epoch: 2/8, Batch: 2560/3444, Loss: 0.012216007336974144\n",
      "Epoch: 2/8, Batch: 2570/3444, Loss: 0.019487757235765457\n",
      "Epoch: 2/8, Batch: 2580/3444, Loss: 0.028772780671715736\n",
      "Epoch: 2/8, Batch: 2590/3444, Loss: 0.01605059951543808\n",
      "Epoch: 2/8, Batch: 2600/3444, Loss: 0.0605132021009922\n",
      "Epoch: 2/8, Batch: 2610/3444, Loss: 0.047002989798784256\n",
      "Epoch: 2/8, Batch: 2620/3444, Loss: 0.03282758966088295\n",
      "Epoch: 2/8, Batch: 2630/3444, Loss: 0.01775798387825489\n",
      "Epoch: 2/8, Batch: 2640/3444, Loss: 0.04156569018959999\n",
      "Epoch: 2/8, Batch: 2650/3444, Loss: 0.0335250049829483\n",
      "Epoch: 2/8, Batch: 2660/3444, Loss: 0.02665668912231922\n",
      "Epoch: 2/8, Batch: 2670/3444, Loss: 0.07324226200580597\n",
      "Epoch: 2/8, Batch: 2680/3444, Loss: 0.03131294995546341\n",
      "Epoch: 2/8, Batch: 2690/3444, Loss: 0.021888993680477142\n",
      "Epoch: 2/8, Batch: 2700/3444, Loss: 0.041593290865421295\n",
      "Epoch: 2/8, Batch: 2710/3444, Loss: 0.026675499975681305\n",
      "Epoch: 2/8, Batch: 2720/3444, Loss: 0.020481033250689507\n",
      "Epoch: 2/8, Batch: 2730/3444, Loss: 0.06766261160373688\n",
      "Epoch: 2/8, Batch: 2740/3444, Loss: 0.08792149275541306\n",
      "Epoch: 2/8, Batch: 2750/3444, Loss: 0.014953619800508022\n",
      "Epoch: 2/8, Batch: 2760/3444, Loss: 0.03648589178919792\n",
      "Epoch: 2/8, Batch: 2770/3444, Loss: 0.0826171338558197\n",
      "Epoch: 2/8, Batch: 2780/3444, Loss: 0.03162146359682083\n",
      "Epoch: 2/8, Batch: 2790/3444, Loss: 0.0162645410746336\n",
      "Epoch: 2/8, Batch: 2800/3444, Loss: 0.023286009207367897\n",
      "Epoch: 2/8, Batch: 2810/3444, Loss: 0.03500231355428696\n",
      "Epoch: 2/8, Batch: 2820/3444, Loss: 0.021305885165929794\n",
      "Epoch: 2/8, Batch: 2830/3444, Loss: 0.019524632021784782\n",
      "Epoch: 2/8, Batch: 2840/3444, Loss: 0.06036369875073433\n",
      "Epoch: 2/8, Batch: 2850/3444, Loss: 0.021170176565647125\n",
      "Epoch: 2/8, Batch: 2860/3444, Loss: 0.042101021856069565\n",
      "Epoch: 2/8, Batch: 2870/3444, Loss: 0.0331035852432251\n",
      "Epoch: 2/8, Batch: 2880/3444, Loss: 0.034740474075078964\n",
      "Epoch: 2/8, Batch: 2890/3444, Loss: 0.015371942892670631\n",
      "Epoch: 2/8, Batch: 2900/3444, Loss: 0.036216944456100464\n",
      "Epoch: 2/8, Batch: 2910/3444, Loss: 0.019834883511066437\n",
      "Epoch: 2/8, Batch: 2920/3444, Loss: 0.12975306808948517\n",
      "Epoch: 2/8, Batch: 2930/3444, Loss: 0.07303677499294281\n",
      "Epoch: 2/8, Batch: 2940/3444, Loss: 0.0074851252138614655\n",
      "Epoch: 2/8, Batch: 2950/3444, Loss: 0.02270834520459175\n",
      "Epoch: 2/8, Batch: 2960/3444, Loss: 0.025432778522372246\n",
      "Epoch: 2/8, Batch: 2970/3444, Loss: 0.023065779358148575\n",
      "Epoch: 2/8, Batch: 2980/3444, Loss: 0.05980055406689644\n",
      "Epoch: 2/8, Batch: 2990/3444, Loss: 0.022035816684365273\n",
      "Epoch: 2/8, Batch: 3000/3444, Loss: 0.03975905478000641\n",
      "Epoch: 2/8, Batch: 3010/3444, Loss: 0.05519437789916992\n",
      "Epoch: 2/8, Batch: 3020/3444, Loss: 0.030703287571668625\n",
      "Epoch: 2/8, Batch: 3030/3444, Loss: 0.018349383026361465\n",
      "Epoch: 2/8, Batch: 3040/3444, Loss: 0.023723017424345016\n",
      "Epoch: 2/8, Batch: 3050/3444, Loss: 0.016066856682300568\n",
      "Epoch: 2/8, Batch: 3060/3444, Loss: 0.025412824004888535\n",
      "Epoch: 2/8, Batch: 3070/3444, Loss: 0.03186831250786781\n",
      "Epoch: 2/8, Batch: 3080/3444, Loss: 0.007946417666971684\n",
      "Epoch: 2/8, Batch: 3090/3444, Loss: 0.010960806161165237\n",
      "Epoch: 2/8, Batch: 3100/3444, Loss: 0.050574030727148056\n",
      "Epoch: 2/8, Batch: 3110/3444, Loss: 0.015333861112594604\n",
      "Epoch: 2/8, Batch: 3120/3444, Loss: 0.019929679110646248\n",
      "Epoch: 2/8, Batch: 3130/3444, Loss: 0.028848091140389442\n",
      "Epoch: 2/8, Batch: 3140/3444, Loss: 0.030314667150378227\n",
      "Epoch: 2/8, Batch: 3150/3444, Loss: 0.08172740042209625\n",
      "Epoch: 2/8, Batch: 3160/3444, Loss: 0.030629802495241165\n",
      "Epoch: 2/8, Batch: 3170/3444, Loss: 0.03272075951099396\n",
      "Epoch: 2/8, Batch: 3180/3444, Loss: 0.02855648286640644\n",
      "Epoch: 2/8, Batch: 3190/3444, Loss: 0.058426450937986374\n",
      "Epoch: 2/8, Batch: 3200/3444, Loss: 0.029923267662525177\n",
      "Epoch: 2/8, Batch: 3210/3444, Loss: 0.03389983996748924\n",
      "Epoch: 2/8, Batch: 3220/3444, Loss: 0.028812414035201073\n",
      "Epoch: 2/8, Batch: 3230/3444, Loss: 0.05460294708609581\n",
      "Epoch: 2/8, Batch: 3240/3444, Loss: 0.015472439117729664\n",
      "Epoch: 2/8, Batch: 3250/3444, Loss: 0.04199140518903732\n",
      "Epoch: 2/8, Batch: 3260/3444, Loss: 0.02415713109076023\n",
      "Epoch: 2/8, Batch: 3270/3444, Loss: 0.022621547803282738\n",
      "Epoch: 2/8, Batch: 3280/3444, Loss: 0.031378742307424545\n",
      "Epoch: 2/8, Batch: 3290/3444, Loss: 0.046154219657182693\n",
      "Epoch: 2/8, Batch: 3300/3444, Loss: 0.010622153989970684\n",
      "Epoch: 2/8, Batch: 3310/3444, Loss: 0.029894815757870674\n",
      "Epoch: 2/8, Batch: 3320/3444, Loss: 0.024529313668608665\n",
      "Epoch: 2/8, Batch: 3330/3444, Loss: 0.01686377078294754\n",
      "Epoch: 2/8, Batch: 3340/3444, Loss: 0.021612873300909996\n",
      "Epoch: 2/8, Batch: 3350/3444, Loss: 0.024507617577910423\n",
      "Epoch: 2/8, Batch: 3360/3444, Loss: 0.015468957833945751\n",
      "Epoch: 2/8, Batch: 3370/3444, Loss: 0.028942368924617767\n",
      "Epoch: 2/8, Batch: 3380/3444, Loss: 0.01165755745023489\n",
      "Epoch: 2/8, Batch: 3390/3444, Loss: 0.02521236427128315\n",
      "Epoch: 2/8, Batch: 3400/3444, Loss: 0.08352815359830856\n",
      "Epoch: 2/8, Batch: 3410/3444, Loss: 0.029371630400419235\n",
      "Epoch: 2/8, Batch: 3420/3444, Loss: 0.02682453766465187\n",
      "Epoch: 2/8, Batch: 3430/3444, Loss: 0.02256782166659832\n",
      "Epoch: 2/8, Batch: 3440/3444, Loss: 0.03197122737765312\n",
      "Epoch: 2/8, Val Loss: 0.03729174611278735\n",
      "Epoch: 3/8, Batch: 10/3444, Loss: 0.02597086876630783\n",
      "Epoch: 3/8, Batch: 20/3444, Loss: 0.03746042773127556\n",
      "Epoch: 3/8, Batch: 30/3444, Loss: 0.03555119410157204\n",
      "Epoch: 3/8, Batch: 40/3444, Loss: 0.04772559553384781\n",
      "Epoch: 3/8, Batch: 50/3444, Loss: 0.0640644058585167\n",
      "Epoch: 3/8, Batch: 60/3444, Loss: 0.05722430720925331\n",
      "Epoch: 3/8, Batch: 70/3444, Loss: 0.02330447919666767\n",
      "Epoch: 3/8, Batch: 80/3444, Loss: 0.015753258019685745\n",
      "Epoch: 3/8, Batch: 90/3444, Loss: 0.04125995934009552\n",
      "Epoch: 3/8, Batch: 100/3444, Loss: 0.012297146953642368\n",
      "Epoch: 3/8, Batch: 110/3444, Loss: 0.033147718757390976\n",
      "Epoch: 3/8, Batch: 120/3444, Loss: 0.041933465749025345\n",
      "Epoch: 3/8, Batch: 130/3444, Loss: 0.046004924923181534\n",
      "Epoch: 3/8, Batch: 140/3444, Loss: 0.03327268734574318\n",
      "Epoch: 3/8, Batch: 150/3444, Loss: 0.007711427286267281\n",
      "Epoch: 3/8, Batch: 160/3444, Loss: 0.012211991474032402\n",
      "Epoch: 3/8, Batch: 170/3444, Loss: 0.014299171976745129\n",
      "Epoch: 3/8, Batch: 180/3444, Loss: 0.01364404521882534\n",
      "Epoch: 3/8, Batch: 190/3444, Loss: 0.023017439991235733\n",
      "Epoch: 3/8, Batch: 200/3444, Loss: 0.027525996789336205\n",
      "Epoch: 3/8, Batch: 210/3444, Loss: 0.03224017098546028\n",
      "Epoch: 3/8, Batch: 220/3444, Loss: 0.01547161117196083\n",
      "Epoch: 3/8, Batch: 230/3444, Loss: 0.018326984718441963\n",
      "Epoch: 3/8, Batch: 240/3444, Loss: 0.030348988249897957\n",
      "Epoch: 3/8, Batch: 250/3444, Loss: 0.02365216240286827\n",
      "Epoch: 3/8, Batch: 260/3444, Loss: 0.026049843057990074\n",
      "Epoch: 3/8, Batch: 270/3444, Loss: 0.05875953659415245\n",
      "Epoch: 3/8, Batch: 280/3444, Loss: 0.03321574628353119\n",
      "Epoch: 3/8, Batch: 290/3444, Loss: 0.021416781470179558\n",
      "Epoch: 3/8, Batch: 300/3444, Loss: 0.0318915955722332\n",
      "Epoch: 3/8, Batch: 310/3444, Loss: 0.046661581844091415\n",
      "Epoch: 3/8, Batch: 320/3444, Loss: 0.013183128088712692\n",
      "Epoch: 3/8, Batch: 330/3444, Loss: 0.020785264670848846\n",
      "Epoch: 3/8, Batch: 340/3444, Loss: 0.019703328609466553\n",
      "Epoch: 3/8, Batch: 350/3444, Loss: 0.01954955793917179\n",
      "Epoch: 3/8, Batch: 360/3444, Loss: 0.011113636195659637\n",
      "Epoch: 3/8, Batch: 370/3444, Loss: 0.018369635567069054\n",
      "Epoch: 3/8, Batch: 380/3444, Loss: 0.02094215340912342\n",
      "Epoch: 3/8, Batch: 390/3444, Loss: 0.03764777258038521\n",
      "Epoch: 3/8, Batch: 400/3444, Loss: 0.035405971109867096\n",
      "Epoch: 3/8, Batch: 410/3444, Loss: 0.03193904832005501\n",
      "Epoch: 3/8, Batch: 420/3444, Loss: 0.02883106842637062\n",
      "Epoch: 3/8, Batch: 430/3444, Loss: 0.021530091762542725\n",
      "Epoch: 3/8, Batch: 440/3444, Loss: 0.03583532199263573\n",
      "Epoch: 3/8, Batch: 450/3444, Loss: 0.02799537591636181\n",
      "Epoch: 3/8, Batch: 460/3444, Loss: 0.048042356967926025\n",
      "Epoch: 3/8, Batch: 470/3444, Loss: 0.1030118465423584\n",
      "Epoch: 3/8, Batch: 480/3444, Loss: 0.016545798629522324\n",
      "Epoch: 3/8, Batch: 490/3444, Loss: 0.057876575738191605\n",
      "Epoch: 3/8, Batch: 500/3444, Loss: 0.015862874686717987\n",
      "Epoch: 3/8, Batch: 510/3444, Loss: 0.058356158435344696\n",
      "Epoch: 3/8, Batch: 520/3444, Loss: 0.0548170804977417\n",
      "Epoch: 3/8, Batch: 530/3444, Loss: 0.021129010245203972\n",
      "Epoch: 3/8, Batch: 540/3444, Loss: 0.03868294134736061\n",
      "Epoch: 3/8, Batch: 550/3444, Loss: 0.038293350487947464\n",
      "Epoch: 3/8, Batch: 560/3444, Loss: 0.03665923699736595\n",
      "Epoch: 3/8, Batch: 570/3444, Loss: 0.02860749326646328\n",
      "Epoch: 3/8, Batch: 580/3444, Loss: 0.04180862382054329\n",
      "Epoch: 3/8, Batch: 590/3444, Loss: 0.01304768119007349\n",
      "Epoch: 3/8, Batch: 600/3444, Loss: 0.011961515061557293\n",
      "Epoch: 3/8, Batch: 610/3444, Loss: 0.041079577058553696\n",
      "Epoch: 3/8, Batch: 620/3444, Loss: 0.011908243410289288\n",
      "Epoch: 3/8, Batch: 630/3444, Loss: 0.026671791449189186\n",
      "Epoch: 3/8, Batch: 640/3444, Loss: 0.09367246925830841\n",
      "Epoch: 3/8, Batch: 650/3444, Loss: 0.02690025418996811\n",
      "Epoch: 3/8, Batch: 660/3444, Loss: 0.008487159386277199\n",
      "Epoch: 3/8, Batch: 670/3444, Loss: 0.03287871181964874\n",
      "Epoch: 3/8, Batch: 680/3444, Loss: 0.02149689570069313\n",
      "Epoch: 3/8, Batch: 690/3444, Loss: 0.019275128841400146\n",
      "Epoch: 3/8, Batch: 700/3444, Loss: 0.02204384095966816\n",
      "Epoch: 3/8, Batch: 710/3444, Loss: 0.035872913897037506\n",
      "Epoch: 3/8, Batch: 720/3444, Loss: 0.03541615232825279\n",
      "Epoch: 3/8, Batch: 730/3444, Loss: 0.057251010090112686\n",
      "Epoch: 3/8, Batch: 740/3444, Loss: 0.032493457198143005\n",
      "Epoch: 3/8, Batch: 750/3444, Loss: 0.02407943271100521\n",
      "Epoch: 3/8, Batch: 760/3444, Loss: 0.025081027299165726\n",
      "Epoch: 3/8, Batch: 770/3444, Loss: 0.02530702017247677\n",
      "Epoch: 3/8, Batch: 780/3444, Loss: 0.028636818751692772\n",
      "Epoch: 3/8, Batch: 790/3444, Loss: 0.09551384299993515\n",
      "Epoch: 3/8, Batch: 800/3444, Loss: 0.04634925350546837\n",
      "Epoch: 3/8, Batch: 810/3444, Loss: 0.02227809466421604\n",
      "Epoch: 3/8, Batch: 820/3444, Loss: 0.029417231678962708\n",
      "Epoch: 3/8, Batch: 830/3444, Loss: 0.01827271096408367\n",
      "Epoch: 3/8, Batch: 840/3444, Loss: 0.02138104848563671\n",
      "Epoch: 3/8, Batch: 850/3444, Loss: 0.022976169362664223\n",
      "Epoch: 3/8, Batch: 860/3444, Loss: 0.04124504700303078\n",
      "Epoch: 3/8, Batch: 870/3444, Loss: 0.02206585742533207\n",
      "Epoch: 3/8, Batch: 880/3444, Loss: 0.08134393393993378\n",
      "Epoch: 3/8, Batch: 890/3444, Loss: 0.018880795687437057\n",
      "Epoch: 3/8, Batch: 900/3444, Loss: 0.025475703179836273\n",
      "Epoch: 3/8, Batch: 910/3444, Loss: 0.0283990316092968\n",
      "Epoch: 3/8, Batch: 920/3444, Loss: 0.042782727628946304\n",
      "Epoch: 3/8, Batch: 930/3444, Loss: 0.017757443711161613\n",
      "Epoch: 3/8, Batch: 940/3444, Loss: 0.026219503954052925\n",
      "Epoch: 3/8, Batch: 950/3444, Loss: 0.01895238645374775\n",
      "Epoch: 3/8, Batch: 960/3444, Loss: 0.06986348330974579\n",
      "Epoch: 3/8, Batch: 970/3444, Loss: 0.03363996744155884\n",
      "Epoch: 3/8, Batch: 980/3444, Loss: 0.04119221493601799\n",
      "Epoch: 3/8, Batch: 990/3444, Loss: 0.01927514187991619\n",
      "Epoch: 3/8, Batch: 1000/3444, Loss: 0.028729712590575218\n",
      "Epoch: 3/8, Batch: 1010/3444, Loss: 0.015088355168700218\n",
      "Epoch: 3/8, Batch: 1020/3444, Loss: 0.022856105118989944\n",
      "Epoch: 3/8, Batch: 1030/3444, Loss: 0.05224456638097763\n",
      "Epoch: 3/8, Batch: 1040/3444, Loss: 0.043238550424575806\n",
      "Epoch: 3/8, Batch: 1050/3444, Loss: 0.01687518320977688\n",
      "Epoch: 3/8, Batch: 1060/3444, Loss: 0.02881455421447754\n",
      "Epoch: 3/8, Batch: 1070/3444, Loss: 0.020489972084760666\n",
      "Epoch: 3/8, Batch: 1080/3444, Loss: 0.026715440675616264\n",
      "Epoch: 3/8, Batch: 1090/3444, Loss: 0.038945604115724564\n",
      "Epoch: 3/8, Batch: 1100/3444, Loss: 0.018588431179523468\n",
      "Epoch: 3/8, Batch: 1110/3444, Loss: 0.02275908552110195\n",
      "Epoch: 3/8, Batch: 1120/3444, Loss: 0.01027257926762104\n",
      "Epoch: 3/8, Batch: 1130/3444, Loss: 0.03583719581365585\n",
      "Epoch: 3/8, Batch: 1140/3444, Loss: 0.026973707601428032\n",
      "Epoch: 3/8, Batch: 1150/3444, Loss: 0.09960939735174179\n",
      "Epoch: 3/8, Batch: 1160/3444, Loss: 0.05596981197595596\n",
      "Epoch: 3/8, Batch: 1170/3444, Loss: 0.02792402356863022\n",
      "Epoch: 3/8, Batch: 1180/3444, Loss: 0.034376878291368484\n",
      "Epoch: 3/8, Batch: 1190/3444, Loss: 0.0357070229947567\n",
      "Epoch: 3/8, Batch: 1200/3444, Loss: 0.024457868188619614\n",
      "Epoch: 3/8, Batch: 1210/3444, Loss: 0.014536088332533836\n",
      "Epoch: 3/8, Batch: 1220/3444, Loss: 0.029183022677898407\n",
      "Epoch: 3/8, Batch: 1230/3444, Loss: 0.020001085475087166\n",
      "Epoch: 3/8, Batch: 1240/3444, Loss: 0.04966329038143158\n",
      "Epoch: 3/8, Batch: 1250/3444, Loss: 0.018809258937835693\n",
      "Epoch: 3/8, Batch: 1260/3444, Loss: 0.01909518614411354\n",
      "Epoch: 3/8, Batch: 1270/3444, Loss: 0.030419137328863144\n",
      "Epoch: 3/8, Batch: 1280/3444, Loss: 0.034141745418310165\n",
      "Epoch: 3/8, Batch: 1290/3444, Loss: 0.02409875951707363\n",
      "Epoch: 3/8, Batch: 1300/3444, Loss: 0.030627232044935226\n",
      "Epoch: 3/8, Batch: 1310/3444, Loss: 0.009123524650931358\n",
      "Epoch: 3/8, Batch: 1320/3444, Loss: 0.02600640431046486\n",
      "Epoch: 3/8, Batch: 1330/3444, Loss: 0.05523739382624626\n",
      "Epoch: 3/8, Batch: 1340/3444, Loss: 0.04811643064022064\n",
      "Epoch: 3/8, Batch: 1350/3444, Loss: 0.05855248123407364\n",
      "Epoch: 3/8, Batch: 1360/3444, Loss: 0.015394403599202633\n",
      "Epoch: 3/8, Batch: 1370/3444, Loss: 0.02107439748942852\n",
      "Epoch: 3/8, Batch: 1380/3444, Loss: 0.0214277021586895\n",
      "Epoch: 3/8, Batch: 1390/3444, Loss: 0.05261446163058281\n",
      "Epoch: 3/8, Batch: 1400/3444, Loss: 0.01546232495456934\n",
      "Epoch: 3/8, Batch: 1410/3444, Loss: 0.02602545917034149\n",
      "Epoch: 3/8, Batch: 1420/3444, Loss: 0.0574871189892292\n",
      "Epoch: 3/8, Batch: 1430/3444, Loss: 0.028722839429974556\n",
      "Epoch: 3/8, Batch: 1440/3444, Loss: 0.03973349183797836\n",
      "Epoch: 3/8, Batch: 1450/3444, Loss: 0.04345553740859032\n",
      "Epoch: 3/8, Batch: 1460/3444, Loss: 0.02798803336918354\n",
      "Epoch: 3/8, Batch: 1470/3444, Loss: 0.045917246490716934\n",
      "Epoch: 3/8, Batch: 1480/3444, Loss: 0.039810311049222946\n",
      "Epoch: 3/8, Batch: 1490/3444, Loss: 0.1282801777124405\n",
      "Epoch: 3/8, Batch: 1500/3444, Loss: 0.038801003247499466\n",
      "Epoch: 3/8, Batch: 1510/3444, Loss: 0.027247563004493713\n",
      "Epoch: 3/8, Batch: 1520/3444, Loss: 0.02167363464832306\n",
      "Epoch: 3/8, Batch: 1530/3444, Loss: 0.03295298293232918\n",
      "Epoch: 3/8, Batch: 1540/3444, Loss: 0.027951564639806747\n",
      "Epoch: 3/8, Batch: 1550/3444, Loss: 0.017374424263834953\n",
      "Epoch: 3/8, Batch: 1560/3444, Loss: 0.02133883535861969\n",
      "Epoch: 3/8, Batch: 1570/3444, Loss: 0.021251065656542778\n",
      "Epoch: 3/8, Batch: 1580/3444, Loss: 0.07218585908412933\n",
      "Epoch: 3/8, Batch: 1590/3444, Loss: 0.021927155554294586\n",
      "Epoch: 3/8, Batch: 1600/3444, Loss: 0.03367093577980995\n",
      "Epoch: 3/8, Batch: 1610/3444, Loss: 0.03043401800096035\n",
      "Epoch: 3/8, Batch: 1620/3444, Loss: 0.019323408603668213\n",
      "Epoch: 3/8, Batch: 1630/3444, Loss: 0.016619304195046425\n",
      "Epoch: 3/8, Batch: 1640/3444, Loss: 0.02197045087814331\n",
      "Epoch: 3/8, Batch: 1650/3444, Loss: 0.03312927111983299\n",
      "Epoch: 3/8, Batch: 1660/3444, Loss: 0.01851540245115757\n",
      "Epoch: 3/8, Batch: 1670/3444, Loss: 0.018109073862433434\n",
      "Epoch: 3/8, Batch: 1680/3444, Loss: 0.02341468632221222\n",
      "Epoch: 3/8, Batch: 1690/3444, Loss: 0.03979860246181488\n",
      "Epoch: 3/8, Batch: 1700/3444, Loss: 0.03585948795080185\n",
      "Epoch: 3/8, Batch: 1710/3444, Loss: 0.013517390936613083\n",
      "Epoch: 3/8, Batch: 1720/3444, Loss: 0.02501458115875721\n",
      "Epoch: 3/8, Batch: 1730/3444, Loss: 0.019854942336678505\n",
      "Epoch: 3/8, Batch: 1740/3444, Loss: 0.0432240292429924\n",
      "Epoch: 3/8, Batch: 1750/3444, Loss: 0.02330268919467926\n",
      "Epoch: 3/8, Batch: 1760/3444, Loss: 0.031187264248728752\n",
      "Epoch: 3/8, Batch: 1770/3444, Loss: 0.017528939992189407\n",
      "Epoch: 3/8, Batch: 1780/3444, Loss: 0.018345076590776443\n",
      "Epoch: 3/8, Batch: 1790/3444, Loss: 0.05800445377826691\n",
      "Epoch: 3/8, Batch: 1800/3444, Loss: 0.0284065380692482\n",
      "Epoch: 3/8, Batch: 1810/3444, Loss: 0.02507769875228405\n",
      "Epoch: 3/8, Batch: 1820/3444, Loss: 0.12019125372171402\n",
      "Epoch: 3/8, Batch: 1830/3444, Loss: 0.03166481480002403\n",
      "Epoch: 3/8, Batch: 1840/3444, Loss: 0.01835990883409977\n",
      "Epoch: 3/8, Batch: 1850/3444, Loss: 0.013490564189851284\n",
      "Epoch: 3/8, Batch: 1860/3444, Loss: 0.050047867000103\n",
      "Epoch: 3/8, Batch: 1870/3444, Loss: 0.022483790293335915\n",
      "Epoch: 3/8, Batch: 1880/3444, Loss: 0.0988582968711853\n",
      "Epoch: 3/8, Batch: 1890/3444, Loss: 0.02849872224032879\n",
      "Epoch: 3/8, Batch: 1900/3444, Loss: 0.05167381465435028\n",
      "Epoch: 3/8, Batch: 1910/3444, Loss: 0.028361545875668526\n",
      "Epoch: 3/8, Batch: 1920/3444, Loss: 0.041906096041202545\n",
      "Epoch: 3/8, Batch: 1930/3444, Loss: 0.03453470766544342\n",
      "Epoch: 3/8, Batch: 1940/3444, Loss: 0.052987731993198395\n",
      "Epoch: 3/8, Batch: 1950/3444, Loss: 0.02444731444120407\n",
      "Epoch: 3/8, Batch: 1960/3444, Loss: 0.026027265936136246\n",
      "Epoch: 3/8, Batch: 1970/3444, Loss: 0.017565960064530373\n",
      "Epoch: 3/8, Batch: 1980/3444, Loss: 0.03032037429511547\n",
      "Epoch: 3/8, Batch: 1990/3444, Loss: 0.013360219076275826\n",
      "Epoch: 3/8, Batch: 2000/3444, Loss: 0.028882764279842377\n",
      "Epoch: 3/8, Batch: 2010/3444, Loss: 0.07941724359989166\n",
      "Epoch: 3/8, Batch: 2020/3444, Loss: 0.03420257568359375\n",
      "Epoch: 3/8, Batch: 2030/3444, Loss: 0.025189392268657684\n",
      "Epoch: 3/8, Batch: 2040/3444, Loss: 0.018978558480739594\n",
      "Epoch: 3/8, Batch: 2050/3444, Loss: 0.027074282988905907\n",
      "Epoch: 3/8, Batch: 2060/3444, Loss: 0.023416239768266678\n",
      "Epoch: 3/8, Batch: 2070/3444, Loss: 0.031760118901729584\n",
      "Epoch: 3/8, Batch: 2080/3444, Loss: 0.028292503207921982\n",
      "Epoch: 3/8, Batch: 2090/3444, Loss: 0.01239857543259859\n",
      "Epoch: 3/8, Batch: 2100/3444, Loss: 0.02618272416293621\n",
      "Epoch: 3/8, Batch: 2110/3444, Loss: 0.08748676627874374\n",
      "Epoch: 3/8, Batch: 2120/3444, Loss: 0.023366523906588554\n",
      "Epoch: 3/8, Batch: 2130/3444, Loss: 0.027961714193224907\n",
      "Epoch: 3/8, Batch: 2140/3444, Loss: 0.011154481209814548\n",
      "Epoch: 3/8, Batch: 2150/3444, Loss: 0.016594653949141502\n",
      "Epoch: 3/8, Batch: 2160/3444, Loss: 0.03919846937060356\n",
      "Epoch: 3/8, Batch: 2170/3444, Loss: 0.048186346888542175\n",
      "Epoch: 3/8, Batch: 2180/3444, Loss: 0.015366587787866592\n",
      "Epoch: 3/8, Batch: 2190/3444, Loss: 0.027191035449504852\n",
      "Epoch: 3/8, Batch: 2200/3444, Loss: 0.029480965808033943\n",
      "Epoch: 3/8, Batch: 2210/3444, Loss: 0.029037609696388245\n",
      "Epoch: 3/8, Batch: 2220/3444, Loss: 0.05552492290735245\n",
      "Epoch: 3/8, Batch: 2230/3444, Loss: 0.044567953795194626\n",
      "Epoch: 3/8, Batch: 2240/3444, Loss: 0.05450478941202164\n",
      "Epoch: 3/8, Batch: 2250/3444, Loss: 0.021111484616994858\n",
      "Epoch: 3/8, Batch: 2260/3444, Loss: 0.020944323390722275\n",
      "Epoch: 3/8, Batch: 2270/3444, Loss: 0.010681341402232647\n",
      "Epoch: 3/8, Batch: 2280/3444, Loss: 0.024503227323293686\n",
      "Epoch: 3/8, Batch: 2290/3444, Loss: 0.013337281532585621\n",
      "Epoch: 3/8, Batch: 2300/3444, Loss: 0.04713473096489906\n",
      "Epoch: 3/8, Batch: 2310/3444, Loss: 0.023073704913258553\n",
      "Epoch: 3/8, Batch: 2320/3444, Loss: 0.030960563570261\n",
      "Epoch: 3/8, Batch: 2330/3444, Loss: 0.01675599068403244\n",
      "Epoch: 3/8, Batch: 2340/3444, Loss: 0.011750012636184692\n",
      "Epoch: 3/8, Batch: 2350/3444, Loss: 0.01756671443581581\n",
      "Epoch: 3/8, Batch: 2360/3444, Loss: 0.0206032395362854\n",
      "Epoch: 3/8, Batch: 2370/3444, Loss: 0.015433136373758316\n",
      "Epoch: 3/8, Batch: 2380/3444, Loss: 0.06845006346702576\n",
      "Epoch: 3/8, Batch: 2390/3444, Loss: 0.035197194665670395\n",
      "Epoch: 3/8, Batch: 2400/3444, Loss: 0.028158137574791908\n",
      "Epoch: 3/8, Batch: 2410/3444, Loss: 0.019939351826906204\n",
      "Epoch: 3/8, Batch: 2420/3444, Loss: 0.04088379070162773\n",
      "Epoch: 3/8, Batch: 2430/3444, Loss: 0.021508699283003807\n",
      "Epoch: 3/8, Batch: 2440/3444, Loss: 0.03962240368127823\n",
      "Epoch: 3/8, Batch: 2450/3444, Loss: 0.045876603573560715\n",
      "Epoch: 3/8, Batch: 2460/3444, Loss: 0.02140750363469124\n",
      "Epoch: 3/8, Batch: 2470/3444, Loss: 0.010781179182231426\n",
      "Epoch: 3/8, Batch: 2480/3444, Loss: 0.01787688210606575\n",
      "Epoch: 3/8, Batch: 2490/3444, Loss: 0.037144340574741364\n",
      "Epoch: 3/8, Batch: 2500/3444, Loss: 0.02885965071618557\n",
      "Epoch: 3/8, Batch: 2510/3444, Loss: 0.016466747969388962\n",
      "Epoch: 3/8, Batch: 2520/3444, Loss: 0.025296632200479507\n",
      "Epoch: 3/8, Batch: 2530/3444, Loss: 0.02560199797153473\n",
      "Epoch: 3/8, Batch: 2540/3444, Loss: 0.021578509360551834\n",
      "Epoch: 3/8, Batch: 2550/3444, Loss: 0.013813547790050507\n",
      "Epoch: 3/8, Batch: 2560/3444, Loss: 0.05341747775673866\n",
      "Epoch: 3/8, Batch: 2570/3444, Loss: 0.05154085159301758\n",
      "Epoch: 3/8, Batch: 2580/3444, Loss: 0.0281355157494545\n",
      "Epoch: 3/8, Batch: 2590/3444, Loss: 0.016640223562717438\n",
      "Epoch: 3/8, Batch: 2600/3444, Loss: 0.023789534345269203\n",
      "Epoch: 3/8, Batch: 2610/3444, Loss: 0.0373692624270916\n",
      "Epoch: 3/8, Batch: 2620/3444, Loss: 0.07605476677417755\n",
      "Epoch: 3/8, Batch: 2630/3444, Loss: 0.03007490746676922\n",
      "Epoch: 3/8, Batch: 2640/3444, Loss: 0.02572491578757763\n",
      "Epoch: 3/8, Batch: 2650/3444, Loss: 0.027143379673361778\n",
      "Epoch: 3/8, Batch: 2660/3444, Loss: 0.01162189431488514\n",
      "Epoch: 3/8, Batch: 2670/3444, Loss: 0.011000807397067547\n",
      "Epoch: 3/8, Batch: 2680/3444, Loss: 0.021566594019532204\n",
      "Epoch: 3/8, Batch: 2690/3444, Loss: 0.04009336978197098\n",
      "Epoch: 3/8, Batch: 2700/3444, Loss: 0.10434778779745102\n",
      "Epoch: 3/8, Batch: 2710/3444, Loss: 0.03323078528046608\n",
      "Epoch: 3/8, Batch: 2720/3444, Loss: 0.014690673910081387\n",
      "Epoch: 3/8, Batch: 2730/3444, Loss: 0.027296097949147224\n",
      "Epoch: 3/8, Batch: 2740/3444, Loss: 0.030131712555885315\n",
      "Epoch: 3/8, Batch: 2750/3444, Loss: 0.026896076276898384\n",
      "Epoch: 3/8, Batch: 2760/3444, Loss: 0.017097564414143562\n",
      "Epoch: 3/8, Batch: 2770/3444, Loss: 0.06424090266227722\n",
      "Epoch: 3/8, Batch: 2780/3444, Loss: 0.01843222975730896\n",
      "Epoch: 3/8, Batch: 2790/3444, Loss: 0.014025820419192314\n",
      "Epoch: 3/8, Batch: 2800/3444, Loss: 0.07438982278108597\n",
      "Epoch: 3/8, Batch: 2810/3444, Loss: 0.04750078171491623\n",
      "Epoch: 3/8, Batch: 2820/3444, Loss: 0.02994643896818161\n",
      "Epoch: 3/8, Batch: 2830/3444, Loss: 0.018337884917855263\n",
      "Epoch: 3/8, Batch: 2840/3444, Loss: 0.023799845948815346\n",
      "Epoch: 3/8, Batch: 2850/3444, Loss: 0.044955071061849594\n",
      "Epoch: 3/8, Batch: 2860/3444, Loss: 0.01950746588408947\n",
      "Epoch: 3/8, Batch: 2870/3444, Loss: 0.022262949496507645\n",
      "Epoch: 3/8, Batch: 2880/3444, Loss: 0.0226555448025465\n",
      "Epoch: 3/8, Batch: 2890/3444, Loss: 0.02850736677646637\n",
      "Epoch: 3/8, Batch: 2900/3444, Loss: 0.02113165147602558\n",
      "Epoch: 3/8, Batch: 2910/3444, Loss: 0.045031771063804626\n",
      "Epoch: 3/8, Batch: 2920/3444, Loss: 0.049051087349653244\n",
      "Epoch: 3/8, Batch: 2930/3444, Loss: 0.017980732023715973\n",
      "Epoch: 3/8, Batch: 2940/3444, Loss: 0.028026243671774864\n",
      "Epoch: 3/8, Batch: 2950/3444, Loss: 0.02141728438436985\n",
      "Epoch: 3/8, Batch: 2960/3444, Loss: 0.06447068601846695\n",
      "Epoch: 3/8, Batch: 2970/3444, Loss: 0.04688325524330139\n",
      "Epoch: 3/8, Batch: 2980/3444, Loss: 0.02693847008049488\n",
      "Epoch: 3/8, Batch: 2990/3444, Loss: 0.0436941497027874\n",
      "Epoch: 3/8, Batch: 3000/3444, Loss: 0.021446919068694115\n",
      "Epoch: 3/8, Batch: 3010/3444, Loss: 0.02302507869899273\n",
      "Epoch: 3/8, Batch: 3020/3444, Loss: 0.013916611671447754\n",
      "Epoch: 3/8, Batch: 3030/3444, Loss: 0.04728657752275467\n",
      "Epoch: 3/8, Batch: 3040/3444, Loss: 0.03016110509634018\n",
      "Epoch: 3/8, Batch: 3050/3444, Loss: 0.012039135210216045\n",
      "Epoch: 3/8, Batch: 3060/3444, Loss: 0.05226264148950577\n",
      "Epoch: 3/8, Batch: 3070/3444, Loss: 0.125676691532135\n",
      "Epoch: 3/8, Batch: 3080/3444, Loss: 0.015619113110005856\n",
      "Epoch: 3/8, Batch: 3090/3444, Loss: 0.03149303048849106\n",
      "Epoch: 3/8, Batch: 3100/3444, Loss: 0.0225249994546175\n",
      "Epoch: 3/8, Batch: 3110/3444, Loss: 0.03910914435982704\n",
      "Epoch: 3/8, Batch: 3120/3444, Loss: 0.06649339199066162\n",
      "Epoch: 3/8, Batch: 3130/3444, Loss: 0.02593577466905117\n",
      "Epoch: 3/8, Batch: 3140/3444, Loss: 0.0226767435669899\n",
      "Epoch: 3/8, Batch: 3150/3444, Loss: 0.06625869125127792\n",
      "Epoch: 3/8, Batch: 3160/3444, Loss: 0.022062966600060463\n",
      "Epoch: 3/8, Batch: 3170/3444, Loss: 0.020268408581614494\n",
      "Epoch: 3/8, Batch: 3180/3444, Loss: 0.02719750441610813\n",
      "Epoch: 3/8, Batch: 3190/3444, Loss: 0.13408228754997253\n",
      "Epoch: 3/8, Batch: 3200/3444, Loss: 0.028612496331334114\n",
      "Epoch: 3/8, Batch: 3210/3444, Loss: 0.08974280208349228\n",
      "Epoch: 3/8, Batch: 3220/3444, Loss: 0.05177207291126251\n",
      "Epoch: 3/8, Batch: 3230/3444, Loss: 0.021239064633846283\n",
      "Epoch: 3/8, Batch: 3240/3444, Loss: 0.08004261553287506\n",
      "Epoch: 3/8, Batch: 3250/3444, Loss: 0.08992314338684082\n",
      "Epoch: 3/8, Batch: 3260/3444, Loss: 0.019782166928052902\n",
      "Epoch: 3/8, Batch: 3270/3444, Loss: 0.040358953177928925\n",
      "Epoch: 3/8, Batch: 3280/3444, Loss: 0.07701095938682556\n",
      "Epoch: 3/8, Batch: 3290/3444, Loss: 0.06290273368358612\n",
      "Epoch: 3/8, Batch: 3300/3444, Loss: 0.1071707159280777\n",
      "Epoch: 3/8, Batch: 3310/3444, Loss: 0.052862223237752914\n",
      "Epoch: 3/8, Batch: 3320/3444, Loss: 0.05156846344470978\n",
      "Epoch: 3/8, Batch: 3330/3444, Loss: 0.02513393945991993\n",
      "Epoch: 3/8, Batch: 3340/3444, Loss: 0.05383838713169098\n",
      "Epoch: 3/8, Batch: 3350/3444, Loss: 0.01518272515386343\n",
      "Epoch: 3/8, Batch: 3360/3444, Loss: 0.01490513514727354\n",
      "Epoch: 3/8, Batch: 3370/3444, Loss: 0.05102032795548439\n",
      "Epoch: 3/8, Batch: 3380/3444, Loss: 0.019971180707216263\n",
      "Epoch: 3/8, Batch: 3390/3444, Loss: 0.08936449885368347\n",
      "Epoch: 3/8, Batch: 3400/3444, Loss: 0.0292466189712286\n",
      "Epoch: 3/8, Batch: 3410/3444, Loss: 0.031838174909353256\n",
      "Epoch: 3/8, Batch: 3420/3444, Loss: 0.035637009888887405\n",
      "Epoch: 3/8, Batch: 3430/3444, Loss: 0.02328030951321125\n",
      "Epoch: 3/8, Batch: 3440/3444, Loss: 0.016357064247131348\n",
      "Epoch 00004: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch: 3/8, Val Loss: 0.1283177423845808\n",
      "Epoch: 4/8, Batch: 10/3444, Loss: 0.025953209027647972\n",
      "Epoch: 4/8, Batch: 20/3444, Loss: 0.012530138716101646\n",
      "Epoch: 4/8, Batch: 30/3444, Loss: 0.012987569905817509\n",
      "Epoch: 4/8, Batch: 40/3444, Loss: 0.027137018740177155\n",
      "Epoch: 4/8, Batch: 50/3444, Loss: 0.012147624045610428\n",
      "Epoch: 4/8, Batch: 60/3444, Loss: 0.014526475220918655\n",
      "Epoch: 4/8, Batch: 70/3444, Loss: 0.013234974816441536\n",
      "Epoch: 4/8, Batch: 80/3444, Loss: 0.02121722139418125\n",
      "Epoch: 4/8, Batch: 90/3444, Loss: 0.005551968235522509\n",
      "Epoch: 4/8, Batch: 100/3444, Loss: 0.030557552352547646\n",
      "Epoch: 4/8, Batch: 110/3444, Loss: 0.009509623050689697\n",
      "Epoch: 4/8, Batch: 120/3444, Loss: 0.03388645872473717\n",
      "Epoch: 4/8, Batch: 130/3444, Loss: 0.014576968736946583\n",
      "Epoch: 4/8, Batch: 140/3444, Loss: 0.013598974794149399\n",
      "Epoch: 4/8, Batch: 150/3444, Loss: 0.032269060611724854\n",
      "Epoch: 4/8, Batch: 160/3444, Loss: 0.015672331675887108\n",
      "Epoch: 4/8, Batch: 170/3444, Loss: 0.007546698208898306\n",
      "Epoch: 4/8, Batch: 180/3444, Loss: 0.01599889248609543\n",
      "Epoch: 4/8, Batch: 190/3444, Loss: 0.029294945299625397\n",
      "Epoch: 4/8, Batch: 200/3444, Loss: 0.014112182892858982\n",
      "Epoch: 4/8, Batch: 210/3444, Loss: 0.015247545205056667\n",
      "Epoch: 4/8, Batch: 220/3444, Loss: 0.01190169621258974\n",
      "Epoch: 4/8, Batch: 230/3444, Loss: 0.014945068396627903\n",
      "Epoch: 4/8, Batch: 240/3444, Loss: 0.006441069301217794\n",
      "Epoch: 4/8, Batch: 250/3444, Loss: 0.007506419904530048\n",
      "Epoch: 4/8, Batch: 260/3444, Loss: 0.02220330573618412\n",
      "Epoch: 4/8, Batch: 270/3444, Loss: 0.01925054006278515\n",
      "Epoch: 4/8, Batch: 280/3444, Loss: 0.010654296725988388\n",
      "Epoch: 4/8, Batch: 290/3444, Loss: 0.020113954320549965\n",
      "Epoch: 4/8, Batch: 300/3444, Loss: 0.011649024672806263\n",
      "Epoch: 4/8, Batch: 310/3444, Loss: 0.01348784752190113\n",
      "Epoch: 4/8, Batch: 320/3444, Loss: 0.046266283839941025\n",
      "Epoch: 4/8, Batch: 330/3444, Loss: 0.014461434446275234\n",
      "Epoch: 4/8, Batch: 340/3444, Loss: 0.026312172412872314\n",
      "Epoch: 4/8, Batch: 350/3444, Loss: 0.026093637570738792\n",
      "Epoch: 4/8, Batch: 360/3444, Loss: 0.01587820239365101\n",
      "Epoch: 4/8, Batch: 370/3444, Loss: 0.013260094448924065\n",
      "Epoch: 4/8, Batch: 380/3444, Loss: 0.00787457823753357\n",
      "Epoch: 4/8, Batch: 390/3444, Loss: 0.014265445061028004\n",
      "Epoch: 4/8, Batch: 400/3444, Loss: 0.05014258250594139\n",
      "Epoch: 4/8, Batch: 410/3444, Loss: 0.028800519183278084\n",
      "Epoch: 4/8, Batch: 420/3444, Loss: 0.0095453392714262\n",
      "Epoch: 4/8, Batch: 430/3444, Loss: 0.011155598796904087\n",
      "Epoch: 4/8, Batch: 440/3444, Loss: 0.01303633488714695\n",
      "Epoch: 4/8, Batch: 450/3444, Loss: 0.02140367031097412\n",
      "Epoch: 4/8, Batch: 460/3444, Loss: 0.026505371555685997\n",
      "Epoch: 4/8, Batch: 470/3444, Loss: 0.02619413286447525\n",
      "Epoch: 4/8, Batch: 480/3444, Loss: 0.008122908882796764\n",
      "Epoch: 4/8, Batch: 490/3444, Loss: 0.015438766218721867\n",
      "Epoch: 4/8, Batch: 500/3444, Loss: 0.016646936535835266\n",
      "Epoch: 4/8, Batch: 510/3444, Loss: 0.015821106731891632\n",
      "Epoch: 4/8, Batch: 520/3444, Loss: 0.00935880932956934\n",
      "Epoch: 4/8, Batch: 530/3444, Loss: 0.008400600403547287\n",
      "Epoch: 4/8, Batch: 540/3444, Loss: 0.032612334936857224\n",
      "Epoch: 4/8, Batch: 550/3444, Loss: 0.015541724860668182\n",
      "Epoch: 4/8, Batch: 560/3444, Loss: 0.007320661563426256\n",
      "Epoch: 4/8, Batch: 570/3444, Loss: 0.022065624594688416\n",
      "Epoch: 4/8, Batch: 580/3444, Loss: 0.011348350904881954\n",
      "Epoch: 4/8, Batch: 590/3444, Loss: 0.02708754502236843\n",
      "Epoch: 4/8, Batch: 600/3444, Loss: 0.010069177486002445\n",
      "Epoch: 4/8, Batch: 610/3444, Loss: 0.027096252888441086\n",
      "Epoch: 4/8, Batch: 620/3444, Loss: 0.008647392503917217\n",
      "Epoch: 4/8, Batch: 630/3444, Loss: 0.02133243903517723\n",
      "Epoch: 4/8, Batch: 640/3444, Loss: 0.007494606077671051\n",
      "Epoch: 4/8, Batch: 650/3444, Loss: 0.02501538209617138\n",
      "Epoch: 4/8, Batch: 660/3444, Loss: 0.04490925371646881\n",
      "Epoch: 4/8, Batch: 670/3444, Loss: 0.01253910269588232\n",
      "Epoch: 4/8, Batch: 680/3444, Loss: 0.01631137914955616\n",
      "Epoch: 4/8, Batch: 690/3444, Loss: 0.03312276303768158\n",
      "Epoch: 4/8, Batch: 700/3444, Loss: 0.019740980118513107\n",
      "Epoch: 4/8, Batch: 710/3444, Loss: 0.021855875849723816\n",
      "Epoch: 4/8, Batch: 720/3444, Loss: 0.022855008020997047\n",
      "Epoch: 4/8, Batch: 730/3444, Loss: 0.009948690421879292\n",
      "Epoch: 4/8, Batch: 740/3444, Loss: 0.008206277154386044\n",
      "Epoch: 4/8, Batch: 750/3444, Loss: 0.03882584348320961\n",
      "Epoch: 4/8, Batch: 760/3444, Loss: 0.00981015246361494\n",
      "Epoch: 4/8, Batch: 770/3444, Loss: 0.01735633797943592\n",
      "Epoch: 4/8, Batch: 780/3444, Loss: 0.01420905627310276\n",
      "Epoch: 4/8, Batch: 790/3444, Loss: 0.010347820818424225\n",
      "Epoch: 4/8, Batch: 800/3444, Loss: 0.011455369181931019\n",
      "Epoch: 4/8, Batch: 810/3444, Loss: 0.04048840329051018\n",
      "Epoch: 4/8, Batch: 820/3444, Loss: 0.013817000202834606\n",
      "Epoch: 4/8, Batch: 830/3444, Loss: 0.015600884333252907\n",
      "Epoch: 4/8, Batch: 840/3444, Loss: 0.009142512455582619\n",
      "Epoch: 4/8, Batch: 850/3444, Loss: 0.03802402690052986\n",
      "Epoch: 4/8, Batch: 860/3444, Loss: 0.012057460844516754\n",
      "Epoch: 4/8, Batch: 870/3444, Loss: 0.012715096585452557\n",
      "Epoch: 4/8, Batch: 880/3444, Loss: 0.033259544521570206\n",
      "Epoch: 4/8, Batch: 890/3444, Loss: 0.03863508999347687\n",
      "Epoch: 4/8, Batch: 900/3444, Loss: 0.004745894577354193\n",
      "Epoch: 4/8, Batch: 910/3444, Loss: 0.013443386182188988\n",
      "Epoch: 4/8, Batch: 920/3444, Loss: 0.023181287571787834\n",
      "Epoch: 4/8, Batch: 930/3444, Loss: 0.022295286878943443\n",
      "Epoch: 4/8, Batch: 940/3444, Loss: 0.022339846938848495\n",
      "Epoch: 4/8, Batch: 950/3444, Loss: 0.013931169174611568\n",
      "Epoch: 4/8, Batch: 960/3444, Loss: 0.010215708054602146\n",
      "Epoch: 4/8, Batch: 970/3444, Loss: 0.04417416825890541\n",
      "Epoch: 4/8, Batch: 980/3444, Loss: 0.01312514953315258\n",
      "Epoch: 4/8, Batch: 990/3444, Loss: 0.017562072724103928\n",
      "Epoch: 4/8, Batch: 1000/3444, Loss: 0.01886359415948391\n",
      "Epoch: 4/8, Batch: 1010/3444, Loss: 0.043750569224357605\n",
      "Epoch: 4/8, Batch: 1020/3444, Loss: 0.013691245578229427\n",
      "Epoch: 4/8, Batch: 1030/3444, Loss: 0.02036544866859913\n",
      "Epoch: 4/8, Batch: 1040/3444, Loss: 0.02380404807627201\n",
      "Epoch: 4/8, Batch: 1050/3444, Loss: 0.048347108066082\n",
      "Epoch: 4/8, Batch: 1060/3444, Loss: 0.0073443930596113205\n",
      "Epoch: 4/8, Batch: 1070/3444, Loss: 0.01603158935904503\n",
      "Epoch: 4/8, Batch: 1080/3444, Loss: 0.007511593401432037\n",
      "Epoch: 4/8, Batch: 1090/3444, Loss: 0.013576138764619827\n",
      "Epoch: 4/8, Batch: 1100/3444, Loss: 0.015735138207674026\n",
      "Epoch: 4/8, Batch: 1110/3444, Loss: 0.017827890813350677\n",
      "Epoch: 4/8, Batch: 1120/3444, Loss: 0.01681358739733696\n",
      "Epoch: 4/8, Batch: 1130/3444, Loss: 0.005448704119771719\n",
      "Epoch: 4/8, Batch: 1140/3444, Loss: 0.015961136668920517\n",
      "Epoch: 4/8, Batch: 1150/3444, Loss: 0.004750605206936598\n",
      "Epoch: 4/8, Batch: 1160/3444, Loss: 0.013478782959282398\n",
      "Epoch: 4/8, Batch: 1170/3444, Loss: 0.00977311935275793\n",
      "Epoch: 4/8, Batch: 1180/3444, Loss: 0.011077791452407837\n",
      "Epoch: 4/8, Batch: 1190/3444, Loss: 0.01563475839793682\n",
      "Epoch: 4/8, Batch: 1200/3444, Loss: 0.04704602435231209\n",
      "Epoch: 4/8, Batch: 1210/3444, Loss: 0.02176804281771183\n",
      "Epoch: 4/8, Batch: 1220/3444, Loss: 0.009264346212148666\n",
      "Epoch: 4/8, Batch: 1230/3444, Loss: 0.02155538648366928\n",
      "Epoch: 4/8, Batch: 1240/3444, Loss: 0.031840238720178604\n",
      "Epoch: 4/8, Batch: 1250/3444, Loss: 0.04391540586948395\n",
      "Epoch: 4/8, Batch: 1260/3444, Loss: 0.01769564300775528\n",
      "Epoch: 4/8, Batch: 1270/3444, Loss: 0.009379631839692593\n",
      "Epoch: 4/8, Batch: 1280/3444, Loss: 0.01129648182541132\n",
      "Epoch: 4/8, Batch: 1290/3444, Loss: 0.012866143137216568\n",
      "Epoch: 4/8, Batch: 1300/3444, Loss: 0.008177611045539379\n",
      "Epoch: 4/8, Batch: 1310/3444, Loss: 0.016024015843868256\n",
      "Epoch: 4/8, Batch: 1320/3444, Loss: 0.011084801517426968\n",
      "Epoch: 4/8, Batch: 1330/3444, Loss: 0.02836531028151512\n",
      "Epoch: 4/8, Batch: 1340/3444, Loss: 0.01344505324959755\n",
      "Epoch: 4/8, Batch: 1350/3444, Loss: 0.021540086716413498\n",
      "Epoch: 4/8, Batch: 1360/3444, Loss: 0.010380027815699577\n",
      "Epoch: 4/8, Batch: 1370/3444, Loss: 0.015166069380939007\n",
      "Epoch: 4/8, Batch: 1380/3444, Loss: 0.013582299463450909\n",
      "Epoch: 4/8, Batch: 1390/3444, Loss: 0.013831471092998981\n",
      "Epoch: 4/8, Batch: 1400/3444, Loss: 0.014053932391107082\n",
      "Epoch: 4/8, Batch: 1410/3444, Loss: 0.023006951436400414\n",
      "Epoch: 4/8, Batch: 1420/3444, Loss: 0.01379202026873827\n",
      "Epoch: 4/8, Batch: 1430/3444, Loss: 0.007339967880398035\n",
      "Epoch: 4/8, Batch: 1440/3444, Loss: 0.026525849476456642\n",
      "Epoch: 4/8, Batch: 1450/3444, Loss: 0.014726708643138409\n",
      "Epoch: 4/8, Batch: 1460/3444, Loss: 0.010847978293895721\n",
      "Epoch: 4/8, Batch: 1470/3444, Loss: 0.015616723336279392\n",
      "Epoch: 4/8, Batch: 1480/3444, Loss: 0.005884403828531504\n",
      "Epoch: 4/8, Batch: 1490/3444, Loss: 0.010187370702624321\n",
      "Epoch: 4/8, Batch: 1500/3444, Loss: 0.008867894299328327\n",
      "Epoch: 4/8, Batch: 1510/3444, Loss: 0.008659414015710354\n",
      "Epoch: 4/8, Batch: 1520/3444, Loss: 0.009971695020794868\n",
      "Epoch: 4/8, Batch: 1530/3444, Loss: 0.03337201103568077\n",
      "Epoch: 4/8, Batch: 1540/3444, Loss: 0.015123715624213219\n",
      "Epoch: 4/8, Batch: 1550/3444, Loss: 0.006702116224914789\n",
      "Epoch: 4/8, Batch: 1560/3444, Loss: 0.0045977067202329636\n",
      "Epoch: 4/8, Batch: 1570/3444, Loss: 0.015252113342285156\n",
      "Epoch: 4/8, Batch: 1580/3444, Loss: 0.018234534189105034\n",
      "Epoch: 4/8, Batch: 1590/3444, Loss: 0.011835452169179916\n",
      "Epoch: 4/8, Batch: 1600/3444, Loss: 0.023664889857172966\n",
      "Epoch: 4/8, Batch: 1610/3444, Loss: 0.0069925617426633835\n",
      "Epoch: 4/8, Batch: 1620/3444, Loss: 0.01624237932264805\n",
      "Epoch: 4/8, Batch: 1630/3444, Loss: 0.0340539813041687\n",
      "Epoch: 4/8, Batch: 1640/3444, Loss: 0.00850853230804205\n",
      "Epoch: 4/8, Batch: 1650/3444, Loss: 0.00700351782143116\n",
      "Epoch: 4/8, Batch: 1660/3444, Loss: 0.017687750980257988\n",
      "Epoch: 4/8, Batch: 1670/3444, Loss: 0.02711387909948826\n",
      "Epoch: 4/8, Batch: 1680/3444, Loss: 0.00889897532761097\n",
      "Epoch: 4/8, Batch: 1690/3444, Loss: 0.011453723534941673\n",
      "Epoch: 4/8, Batch: 1700/3444, Loss: 0.007949543185532093\n",
      "Epoch: 4/8, Batch: 1710/3444, Loss: 0.018725315108895302\n",
      "Epoch: 4/8, Batch: 1720/3444, Loss: 0.023668445646762848\n",
      "Epoch: 4/8, Batch: 1730/3444, Loss: 0.011125611141324043\n",
      "Epoch: 4/8, Batch: 1740/3444, Loss: 0.025992918759584427\n",
      "Epoch: 4/8, Batch: 1750/3444, Loss: 0.01420801505446434\n",
      "Epoch: 4/8, Batch: 1760/3444, Loss: 0.011428742669522762\n",
      "Epoch: 4/8, Batch: 1770/3444, Loss: 0.009835847653448582\n",
      "Epoch: 4/8, Batch: 1780/3444, Loss: 0.010384129360318184\n",
      "Epoch: 4/8, Batch: 1790/3444, Loss: 0.02742374688386917\n",
      "Epoch: 4/8, Batch: 1800/3444, Loss: 0.004941415041685104\n",
      "Epoch: 4/8, Batch: 1810/3444, Loss: 0.012695099227130413\n",
      "Epoch: 4/8, Batch: 1820/3444, Loss: 0.01146495621651411\n",
      "Epoch: 4/8, Batch: 1830/3444, Loss: 0.013587686233222485\n",
      "Epoch: 4/8, Batch: 1840/3444, Loss: 0.007924987003207207\n",
      "Epoch: 4/8, Batch: 1850/3444, Loss: 0.01053028553724289\n",
      "Epoch: 4/8, Batch: 1860/3444, Loss: 0.01373815257102251\n",
      "Epoch: 4/8, Batch: 1870/3444, Loss: 0.03770257160067558\n",
      "Epoch: 4/8, Batch: 1880/3444, Loss: 0.016430918127298355\n",
      "Epoch: 4/8, Batch: 1890/3444, Loss: 0.013853952288627625\n",
      "Epoch: 4/8, Batch: 1900/3444, Loss: 0.021194186061620712\n",
      "Epoch: 4/8, Batch: 1910/3444, Loss: 0.019489090889692307\n",
      "Epoch: 4/8, Batch: 1920/3444, Loss: 0.01160181313753128\n",
      "Epoch: 4/8, Batch: 1930/3444, Loss: 0.026458339765667915\n",
      "Epoch: 4/8, Batch: 1940/3444, Loss: 0.009571487084031105\n",
      "Epoch: 4/8, Batch: 1950/3444, Loss: 0.020014191046357155\n",
      "Epoch: 4/8, Batch: 1960/3444, Loss: 0.008044788613915443\n",
      "Epoch: 4/8, Batch: 1970/3444, Loss: 0.019796356558799744\n",
      "Epoch: 4/8, Batch: 1980/3444, Loss: 0.03802555426955223\n",
      "Epoch: 4/8, Batch: 1990/3444, Loss: 0.016614941880106926\n",
      "Epoch: 4/8, Batch: 2000/3444, Loss: 0.024624234065413475\n",
      "Epoch: 4/8, Batch: 2010/3444, Loss: 0.015839094296097755\n",
      "Epoch: 4/8, Batch: 2020/3444, Loss: 0.01872679963707924\n",
      "Epoch: 4/8, Batch: 2030/3444, Loss: 0.02056722529232502\n",
      "Epoch: 4/8, Batch: 2040/3444, Loss: 0.011497706174850464\n",
      "Epoch: 4/8, Batch: 2050/3444, Loss: 0.009088438004255295\n",
      "Epoch: 4/8, Batch: 2060/3444, Loss: 0.004495169501751661\n",
      "Epoch: 4/8, Batch: 2070/3444, Loss: 0.029687268659472466\n",
      "Epoch: 4/8, Batch: 2080/3444, Loss: 0.012311718426644802\n",
      "Epoch: 4/8, Batch: 2090/3444, Loss: 0.014095382764935493\n",
      "Epoch: 4/8, Batch: 2100/3444, Loss: 0.03363030031323433\n",
      "Epoch: 4/8, Batch: 2110/3444, Loss: 0.029997767880558968\n",
      "Epoch: 4/8, Batch: 2120/3444, Loss: 0.024188296869397163\n",
      "Epoch: 4/8, Batch: 2130/3444, Loss: 0.01243699248880148\n",
      "Epoch: 4/8, Batch: 2140/3444, Loss: 0.02626364678144455\n",
      "Epoch: 4/8, Batch: 2150/3444, Loss: 0.00826574768871069\n",
      "Epoch: 4/8, Batch: 2160/3444, Loss: 0.032870419323444366\n",
      "Epoch: 4/8, Batch: 2170/3444, Loss: 0.040957774966955185\n",
      "Epoch: 4/8, Batch: 2180/3444, Loss: 0.02106916718184948\n",
      "Epoch: 4/8, Batch: 2190/3444, Loss: 0.01215305831283331\n",
      "Epoch: 4/8, Batch: 2200/3444, Loss: 0.03665317967534065\n",
      "Epoch: 4/8, Batch: 2210/3444, Loss: 0.011140028946101665\n",
      "Epoch: 4/8, Batch: 2220/3444, Loss: 0.012037020176649094\n",
      "Epoch: 4/8, Batch: 2230/3444, Loss: 0.016597313806414604\n",
      "Epoch: 4/8, Batch: 2240/3444, Loss: 0.010466773062944412\n",
      "Epoch: 4/8, Batch: 2250/3444, Loss: 0.035209398716688156\n",
      "Epoch: 4/8, Batch: 2260/3444, Loss: 0.020266931504011154\n",
      "Epoch: 4/8, Batch: 2270/3444, Loss: 0.01642748713493347\n",
      "Epoch: 4/8, Batch: 2280/3444, Loss: 0.02302601933479309\n",
      "Epoch: 4/8, Batch: 2290/3444, Loss: 0.012552407570183277\n",
      "Epoch: 4/8, Batch: 2300/3444, Loss: 0.020876344293355942\n",
      "Epoch: 4/8, Batch: 2310/3444, Loss: 0.020864464342594147\n",
      "Epoch: 4/8, Batch: 2320/3444, Loss: 0.008087299764156342\n",
      "Epoch: 4/8, Batch: 2330/3444, Loss: 0.009393508546054363\n",
      "Epoch: 4/8, Batch: 2340/3444, Loss: 0.017287209630012512\n",
      "Epoch: 4/8, Batch: 2350/3444, Loss: 0.005221070256084204\n",
      "Epoch: 4/8, Batch: 2360/3444, Loss: 0.023227188736200333\n",
      "Epoch: 4/8, Batch: 2370/3444, Loss: 0.016218852251768112\n",
      "Epoch: 4/8, Batch: 2380/3444, Loss: 0.02479233592748642\n",
      "Epoch: 4/8, Batch: 2390/3444, Loss: 0.011444625444710255\n",
      "Epoch: 4/8, Batch: 2400/3444, Loss: 0.007962910458445549\n",
      "Epoch: 4/8, Batch: 2410/3444, Loss: 0.010437089949846268\n",
      "Epoch: 4/8, Batch: 2420/3444, Loss: 0.01233013067394495\n",
      "Epoch: 4/8, Batch: 2430/3444, Loss: 0.034169889986515045\n",
      "Epoch: 4/8, Batch: 2440/3444, Loss: 0.00902580376714468\n",
      "Epoch: 4/8, Batch: 2450/3444, Loss: 0.013799827545881271\n",
      "Epoch: 4/8, Batch: 2460/3444, Loss: 0.016677629202604294\n",
      "Epoch: 4/8, Batch: 2470/3444, Loss: 0.006248554214835167\n",
      "Epoch: 4/8, Batch: 2480/3444, Loss: 0.012322361581027508\n",
      "Epoch: 4/8, Batch: 2490/3444, Loss: 0.01260371319949627\n",
      "Epoch: 4/8, Batch: 2500/3444, Loss: 0.02317940443754196\n",
      "Epoch: 4/8, Batch: 2510/3444, Loss: 0.012633291073143482\n",
      "Epoch: 4/8, Batch: 2520/3444, Loss: 0.0035630008205771446\n",
      "Epoch: 4/8, Batch: 2530/3444, Loss: 0.013485440984368324\n",
      "Epoch: 4/8, Batch: 2540/3444, Loss: 0.022101465612649918\n",
      "Epoch: 4/8, Batch: 2550/3444, Loss: 0.012489390559494495\n",
      "Epoch: 4/8, Batch: 2560/3444, Loss: 0.01552866492420435\n",
      "Epoch: 4/8, Batch: 2570/3444, Loss: 0.010558802634477615\n",
      "Epoch: 4/8, Batch: 2580/3444, Loss: 0.01567508839070797\n",
      "Epoch: 4/8, Batch: 2590/3444, Loss: 0.00787366647273302\n",
      "Epoch: 4/8, Batch: 2600/3444, Loss: 0.01983923651278019\n",
      "Epoch: 4/8, Batch: 2610/3444, Loss: 0.015896853059530258\n",
      "Epoch: 4/8, Batch: 2620/3444, Loss: 0.011467919684946537\n",
      "Epoch: 4/8, Batch: 2630/3444, Loss: 0.009086028672754765\n",
      "Epoch: 4/8, Batch: 2640/3444, Loss: 0.011830256320536137\n",
      "Epoch: 4/8, Batch: 2650/3444, Loss: 0.015876801684498787\n",
      "Epoch: 4/8, Batch: 2660/3444, Loss: 0.01668788678944111\n",
      "Epoch: 4/8, Batch: 2670/3444, Loss: 0.011853796429932117\n",
      "Epoch: 4/8, Batch: 2680/3444, Loss: 0.006804235745221376\n",
      "Epoch: 4/8, Batch: 2690/3444, Loss: 0.022163569927215576\n",
      "Epoch: 4/8, Batch: 2700/3444, Loss: 0.008246378973126411\n",
      "Epoch: 4/8, Batch: 2710/3444, Loss: 0.016139011830091476\n",
      "Epoch: 4/8, Batch: 2720/3444, Loss: 0.005789926275610924\n",
      "Epoch: 4/8, Batch: 2730/3444, Loss: 0.027901796624064445\n",
      "Epoch: 4/8, Batch: 2740/3444, Loss: 0.006639369763433933\n",
      "Epoch: 4/8, Batch: 2750/3444, Loss: 0.017862316220998764\n",
      "Epoch: 4/8, Batch: 2760/3444, Loss: 0.006013089325278997\n",
      "Epoch: 4/8, Batch: 2770/3444, Loss: 0.012660529464483261\n",
      "Epoch: 4/8, Batch: 2780/3444, Loss: 0.02273249626159668\n",
      "Epoch: 4/8, Batch: 2790/3444, Loss: 0.010590794496238232\n",
      "Epoch: 4/8, Batch: 2800/3444, Loss: 0.01203275378793478\n",
      "Epoch: 4/8, Batch: 2810/3444, Loss: 0.014835577458143234\n",
      "Epoch: 4/8, Batch: 2820/3444, Loss: 0.010257051326334476\n",
      "Epoch: 4/8, Batch: 2830/3444, Loss: 0.015014958567917347\n",
      "Epoch: 4/8, Batch: 2840/3444, Loss: 0.0278957337141037\n",
      "Epoch: 4/8, Batch: 2850/3444, Loss: 0.003491681767627597\n",
      "Epoch: 4/8, Batch: 2860/3444, Loss: 0.017810335382819176\n",
      "Epoch: 4/8, Batch: 2870/3444, Loss: 0.025954438373446465\n",
      "Epoch: 4/8, Batch: 2880/3444, Loss: 0.018234318122267723\n",
      "Epoch: 4/8, Batch: 2890/3444, Loss: 0.01331570278853178\n",
      "Epoch: 4/8, Batch: 2900/3444, Loss: 0.006873493082821369\n",
      "Epoch: 4/8, Batch: 2910/3444, Loss: 0.013397092930972576\n",
      "Epoch: 4/8, Batch: 2920/3444, Loss: 0.004159781150519848\n",
      "Epoch: 4/8, Batch: 2930/3444, Loss: 0.05138620734214783\n",
      "Epoch: 4/8, Batch: 2940/3444, Loss: 0.018096495419740677\n",
      "Epoch: 4/8, Batch: 2950/3444, Loss: 0.00745578296482563\n",
      "Epoch: 4/8, Batch: 2960/3444, Loss: 0.020674072206020355\n",
      "Epoch: 4/8, Batch: 2970/3444, Loss: 0.016547182574868202\n",
      "Epoch: 4/8, Batch: 2980/3444, Loss: 0.02002151682972908\n",
      "Epoch: 4/8, Batch: 2990/3444, Loss: 0.014047847129404545\n",
      "Epoch: 4/8, Batch: 3000/3444, Loss: 0.015522362664341927\n",
      "Epoch: 4/8, Batch: 3010/3444, Loss: 0.014510258100926876\n",
      "Epoch: 4/8, Batch: 3020/3444, Loss: 0.01790064200758934\n",
      "Epoch: 4/8, Batch: 3030/3444, Loss: 0.024656936526298523\n",
      "Epoch: 4/8, Batch: 3040/3444, Loss: 0.0211073849350214\n",
      "Epoch: 4/8, Batch: 3050/3444, Loss: 0.017361272126436234\n",
      "Epoch: 4/8, Batch: 3060/3444, Loss: 0.010469555854797363\n",
      "Epoch: 4/8, Batch: 3070/3444, Loss: 0.005614581052213907\n",
      "Epoch: 4/8, Batch: 3080/3444, Loss: 0.0057970331981778145\n",
      "Epoch: 4/8, Batch: 3090/3444, Loss: 0.013255085796117783\n",
      "Epoch: 4/8, Batch: 3100/3444, Loss: 0.01846463419497013\n",
      "Epoch: 4/8, Batch: 3110/3444, Loss: 0.041586216539144516\n",
      "Epoch: 4/8, Batch: 3120/3444, Loss: 0.007279983256012201\n",
      "Epoch: 4/8, Batch: 3130/3444, Loss: 0.010229699313640594\n",
      "Epoch: 4/8, Batch: 3140/3444, Loss: 0.012818333692848682\n",
      "Epoch: 4/8, Batch: 3150/3444, Loss: 0.017425062134861946\n",
      "Epoch: 4/8, Batch: 3160/3444, Loss: 0.03524857386946678\n",
      "Epoch: 4/8, Batch: 3170/3444, Loss: 0.010845810174942017\n",
      "Epoch: 4/8, Batch: 3180/3444, Loss: 0.016311336308717728\n",
      "Epoch: 4/8, Batch: 3190/3444, Loss: 0.012190231122076511\n",
      "Epoch: 4/8, Batch: 3200/3444, Loss: 0.04772552102804184\n",
      "Epoch: 4/8, Batch: 3210/3444, Loss: 0.007192640099674463\n",
      "Epoch: 4/8, Batch: 3220/3444, Loss: 0.010904490016400814\n",
      "Epoch: 4/8, Batch: 3230/3444, Loss: 0.013956654816865921\n",
      "Epoch: 4/8, Batch: 3240/3444, Loss: 0.022693060338497162\n",
      "Epoch: 4/8, Batch: 3250/3444, Loss: 0.03349249064922333\n",
      "Epoch: 4/8, Batch: 3260/3444, Loss: 0.011640507727861404\n",
      "Epoch: 4/8, Batch: 3270/3444, Loss: 0.021999942138791084\n",
      "Epoch: 4/8, Batch: 3280/3444, Loss: 0.008225450292229652\n",
      "Epoch: 4/8, Batch: 3290/3444, Loss: 0.030997389927506447\n",
      "Epoch: 4/8, Batch: 3300/3444, Loss: 0.009396206587553024\n",
      "Epoch: 4/8, Batch: 3310/3444, Loss: 0.015227085910737514\n",
      "Epoch: 4/8, Batch: 3320/3444, Loss: 0.00980259571224451\n",
      "Epoch: 4/8, Batch: 3330/3444, Loss: 0.05527932569384575\n",
      "Epoch: 4/8, Batch: 3340/3444, Loss: 0.011713419109582901\n",
      "Epoch: 4/8, Batch: 3350/3444, Loss: 0.017962515354156494\n",
      "Epoch: 4/8, Batch: 3360/3444, Loss: 0.006983076687902212\n",
      "Epoch: 4/8, Batch: 3370/3444, Loss: 0.015590189024806023\n",
      "Epoch: 4/8, Batch: 3380/3444, Loss: 0.020470773801207542\n",
      "Epoch: 4/8, Batch: 3390/3444, Loss: 0.015763448551297188\n",
      "Epoch: 4/8, Batch: 3400/3444, Loss: 0.012450399808585644\n",
      "Epoch: 4/8, Batch: 3410/3444, Loss: 0.018835419788956642\n",
      "Epoch: 4/8, Batch: 3420/3444, Loss: 0.011377321556210518\n",
      "Epoch: 4/8, Batch: 3430/3444, Loss: 0.016065912321209908\n",
      "Epoch: 4/8, Batch: 3440/3444, Loss: 0.005681816954165697\n",
      "Epoch: 4/8, Val Loss: 0.02605473131112296\n",
      "Epoch: 5/8, Batch: 10/3444, Loss: 0.023928513750433922\n",
      "Epoch: 5/8, Batch: 20/3444, Loss: 0.01397708710283041\n",
      "Epoch: 5/8, Batch: 30/3444, Loss: 0.00688190758228302\n",
      "Epoch: 5/8, Batch: 40/3444, Loss: 0.01606469787657261\n",
      "Epoch: 5/8, Batch: 50/3444, Loss: 0.011598990298807621\n",
      "Epoch: 5/8, Batch: 60/3444, Loss: 0.020185161381959915\n",
      "Epoch: 5/8, Batch: 70/3444, Loss: 0.03232719376683235\n",
      "Epoch: 5/8, Batch: 80/3444, Loss: 0.016463622450828552\n",
      "Epoch: 5/8, Batch: 90/3444, Loss: 0.005003785248845816\n",
      "Epoch: 5/8, Batch: 100/3444, Loss: 0.014075931161642075\n",
      "Epoch: 5/8, Batch: 110/3444, Loss: 0.009492435492575169\n",
      "Epoch: 5/8, Batch: 120/3444, Loss: 0.015329208225011826\n",
      "Epoch: 5/8, Batch: 130/3444, Loss: 0.00884074904024601\n",
      "Epoch: 5/8, Batch: 140/3444, Loss: 0.010082479566335678\n",
      "Epoch: 5/8, Batch: 150/3444, Loss: 0.031202204525470734\n",
      "Epoch: 5/8, Batch: 160/3444, Loss: 0.020744070410728455\n",
      "Epoch: 5/8, Batch: 170/3444, Loss: 0.022180970758199692\n",
      "Epoch: 5/8, Batch: 180/3444, Loss: 0.015190592035651207\n",
      "Epoch: 5/8, Batch: 190/3444, Loss: 0.007897197268903255\n",
      "Epoch: 5/8, Batch: 200/3444, Loss: 0.01079990528523922\n",
      "Epoch: 5/8, Batch: 210/3444, Loss: 0.021157823503017426\n",
      "Epoch: 5/8, Batch: 220/3444, Loss: 0.00843735970556736\n",
      "Epoch: 5/8, Batch: 230/3444, Loss: 0.013729851692914963\n",
      "Epoch: 5/8, Batch: 240/3444, Loss: 0.006890471559017897\n",
      "Epoch: 5/8, Batch: 250/3444, Loss: 0.02976800687611103\n",
      "Epoch: 5/8, Batch: 260/3444, Loss: 0.025074506178498268\n",
      "Epoch: 5/8, Batch: 270/3444, Loss: 0.02227768301963806\n",
      "Epoch: 5/8, Batch: 280/3444, Loss: 0.026401817798614502\n",
      "Epoch: 5/8, Batch: 290/3444, Loss: 0.010545703582465649\n",
      "Epoch: 5/8, Batch: 300/3444, Loss: 0.025881469249725342\n",
      "Epoch: 5/8, Batch: 310/3444, Loss: 0.008866974152624607\n",
      "Epoch: 5/8, Batch: 320/3444, Loss: 0.011622767895460129\n",
      "Epoch: 5/8, Batch: 330/3444, Loss: 0.019495058804750443\n",
      "Epoch: 5/8, Batch: 340/3444, Loss: 0.012974840588867664\n",
      "Epoch: 5/8, Batch: 350/3444, Loss: 0.03418169543147087\n",
      "Epoch: 5/8, Batch: 360/3444, Loss: 0.005468748975545168\n",
      "Epoch: 5/8, Batch: 370/3444, Loss: 0.016033414751291275\n",
      "Epoch: 5/8, Batch: 380/3444, Loss: 0.022848257794976234\n",
      "Epoch: 5/8, Batch: 390/3444, Loss: 0.018066227436065674\n",
      "Epoch: 5/8, Batch: 400/3444, Loss: 0.008927824907004833\n",
      "Epoch: 5/8, Batch: 410/3444, Loss: 0.03686630725860596\n",
      "Epoch: 5/8, Batch: 420/3444, Loss: 0.021375250071287155\n",
      "Epoch: 5/8, Batch: 430/3444, Loss: 0.016316555440425873\n",
      "Epoch: 5/8, Batch: 440/3444, Loss: 0.012357545085251331\n",
      "Epoch: 5/8, Batch: 450/3444, Loss: 0.01509912684559822\n",
      "Epoch: 5/8, Batch: 460/3444, Loss: 0.012017211876809597\n",
      "Epoch: 5/8, Batch: 470/3444, Loss: 0.031189419329166412\n",
      "Epoch: 5/8, Batch: 480/3444, Loss: 0.02927261032164097\n",
      "Epoch: 5/8, Batch: 490/3444, Loss: 0.01359399314969778\n",
      "Epoch: 5/8, Batch: 500/3444, Loss: 0.024093937128782272\n",
      "Epoch: 5/8, Batch: 510/3444, Loss: 0.03288166597485542\n",
      "Epoch: 5/8, Batch: 520/3444, Loss: 0.021056298166513443\n",
      "Epoch: 5/8, Batch: 530/3444, Loss: 0.005780975800007582\n",
      "Epoch: 5/8, Batch: 540/3444, Loss: 0.007694268133491278\n",
      "Epoch: 5/8, Batch: 550/3444, Loss: 0.023964200168848038\n",
      "Epoch: 5/8, Batch: 560/3444, Loss: 0.017623193562030792\n",
      "Epoch: 5/8, Batch: 570/3444, Loss: 0.018731608986854553\n",
      "Epoch: 5/8, Batch: 580/3444, Loss: 0.011670299805700779\n",
      "Epoch: 5/8, Batch: 590/3444, Loss: 0.011288260109722614\n",
      "Epoch: 5/8, Batch: 600/3444, Loss: 0.021098585799336433\n",
      "Epoch: 5/8, Batch: 610/3444, Loss: 0.028050998225808144\n",
      "Epoch: 5/8, Batch: 620/3444, Loss: 0.015781475231051445\n",
      "Epoch: 5/8, Batch: 630/3444, Loss: 0.04147186130285263\n",
      "Epoch: 5/8, Batch: 640/3444, Loss: 0.01375960186123848\n",
      "Epoch: 5/8, Batch: 650/3444, Loss: 0.054376304149627686\n",
      "Epoch: 5/8, Batch: 660/3444, Loss: 0.017136555165052414\n",
      "Epoch: 5/8, Batch: 670/3444, Loss: 0.008571124635636806\n",
      "Epoch: 5/8, Batch: 680/3444, Loss: 0.006972437724471092\n",
      "Epoch: 5/8, Batch: 690/3444, Loss: 0.006995855830609798\n",
      "Epoch: 5/8, Batch: 700/3444, Loss: 0.009331861510872841\n",
      "Epoch: 5/8, Batch: 710/3444, Loss: 0.016162855550646782\n",
      "Epoch: 5/8, Batch: 720/3444, Loss: 0.01174953579902649\n",
      "Epoch: 5/8, Batch: 730/3444, Loss: 0.007822558283805847\n",
      "Epoch: 5/8, Batch: 740/3444, Loss: 0.008614057675004005\n",
      "Epoch: 5/8, Batch: 750/3444, Loss: 0.018515242263674736\n",
      "Epoch: 5/8, Batch: 760/3444, Loss: 0.006943139247596264\n",
      "Epoch: 5/8, Batch: 770/3444, Loss: 0.011833996511995792\n",
      "Epoch: 5/8, Batch: 780/3444, Loss: 0.01090999599546194\n",
      "Epoch: 5/8, Batch: 790/3444, Loss: 0.020660990849137306\n",
      "Epoch: 5/8, Batch: 800/3444, Loss: 0.011223590932786465\n",
      "Epoch: 5/8, Batch: 810/3444, Loss: 0.01899498701095581\n",
      "Epoch: 5/8, Batch: 820/3444, Loss: 0.012830247171223164\n",
      "Epoch: 5/8, Batch: 830/3444, Loss: 0.01988786645233631\n",
      "Epoch: 5/8, Batch: 840/3444, Loss: 0.014356698840856552\n",
      "Epoch: 5/8, Batch: 850/3444, Loss: 0.008608931675553322\n",
      "Epoch: 5/8, Batch: 860/3444, Loss: 0.014645756222307682\n",
      "Epoch: 5/8, Batch: 870/3444, Loss: 0.0155786769464612\n",
      "Epoch: 5/8, Batch: 880/3444, Loss: 0.1141025647521019\n",
      "Epoch: 5/8, Batch: 890/3444, Loss: 0.010137475095689297\n",
      "Epoch: 5/8, Batch: 900/3444, Loss: 0.006618895567953587\n",
      "Epoch: 5/8, Batch: 910/3444, Loss: 0.00993359461426735\n",
      "Epoch: 5/8, Batch: 920/3444, Loss: 0.0060845669358968735\n",
      "Epoch: 5/8, Batch: 930/3444, Loss: 0.01856829598546028\n",
      "Epoch: 5/8, Batch: 940/3444, Loss: 0.025604601949453354\n",
      "Epoch: 5/8, Batch: 950/3444, Loss: 0.014186285436153412\n",
      "Epoch: 5/8, Batch: 960/3444, Loss: 0.010963507927954197\n",
      "Epoch: 5/8, Batch: 970/3444, Loss: 0.015732716768980026\n",
      "Epoch: 5/8, Batch: 980/3444, Loss: 0.007865924388170242\n",
      "Epoch: 5/8, Batch: 990/3444, Loss: 0.008092353120446205\n",
      "Epoch: 5/8, Batch: 1000/3444, Loss: 0.024980848655104637\n",
      "Epoch: 5/8, Batch: 1010/3444, Loss: 0.007985011674463749\n",
      "Epoch: 5/8, Batch: 1020/3444, Loss: 0.013336953707039356\n",
      "Epoch: 5/8, Batch: 1030/3444, Loss: 0.012575020082294941\n",
      "Epoch: 5/8, Batch: 1040/3444, Loss: 0.008055297657847404\n",
      "Epoch: 5/8, Batch: 1050/3444, Loss: 0.016060231253504753\n",
      "Epoch: 5/8, Batch: 1060/3444, Loss: 0.012816458940505981\n",
      "Epoch: 5/8, Batch: 1070/3444, Loss: 0.0062723588198423386\n",
      "Epoch: 5/8, Batch: 1080/3444, Loss: 0.003396417712792754\n",
      "Epoch: 5/8, Batch: 1090/3444, Loss: 0.010161340236663818\n",
      "Epoch: 5/8, Batch: 1100/3444, Loss: 0.05913630872964859\n",
      "Epoch: 5/8, Batch: 1110/3444, Loss: 0.013620632700622082\n",
      "Epoch: 5/8, Batch: 1120/3444, Loss: 0.016803359612822533\n",
      "Epoch: 5/8, Batch: 1130/3444, Loss: 0.011255424469709396\n",
      "Epoch: 5/8, Batch: 1140/3444, Loss: 0.016885891556739807\n",
      "Epoch: 5/8, Batch: 1150/3444, Loss: 0.030723759904503822\n",
      "Epoch: 5/8, Batch: 1160/3444, Loss: 0.018013300374150276\n",
      "Epoch: 5/8, Batch: 1170/3444, Loss: 0.01402590237557888\n",
      "Epoch: 5/8, Batch: 1180/3444, Loss: 0.02589470148086548\n",
      "Epoch: 5/8, Batch: 1190/3444, Loss: 0.010271363891661167\n",
      "Epoch: 5/8, Batch: 1200/3444, Loss: 0.012648725882172585\n",
      "Epoch: 5/8, Batch: 1210/3444, Loss: 0.017888378351926804\n",
      "Epoch: 5/8, Batch: 1220/3444, Loss: 0.015092973597347736\n",
      "Epoch: 5/8, Batch: 1230/3444, Loss: 0.011575466021895409\n",
      "Epoch: 5/8, Batch: 1240/3444, Loss: 0.011478334665298462\n",
      "Epoch: 5/8, Batch: 1250/3444, Loss: 0.010612432844936848\n",
      "Epoch: 5/8, Batch: 1260/3444, Loss: 0.01142064854502678\n",
      "Epoch: 5/8, Batch: 1270/3444, Loss: 0.010887674055993557\n",
      "Epoch: 5/8, Batch: 1280/3444, Loss: 0.011250934563577175\n",
      "Epoch: 5/8, Batch: 1290/3444, Loss: 0.008892412297427654\n",
      "Epoch: 5/8, Batch: 1300/3444, Loss: 0.007044128607958555\n",
      "Epoch: 5/8, Batch: 1310/3444, Loss: 0.011907663196325302\n",
      "Epoch: 5/8, Batch: 1320/3444, Loss: 0.018901674076914787\n",
      "Epoch: 5/8, Batch: 1330/3444, Loss: 0.024656377732753754\n",
      "Epoch: 5/8, Batch: 1340/3444, Loss: 0.03031538613140583\n",
      "Epoch: 5/8, Batch: 1350/3444, Loss: 0.010151872411370277\n",
      "Epoch: 5/8, Batch: 1360/3444, Loss: 0.01986129768192768\n",
      "Epoch: 5/8, Batch: 1370/3444, Loss: 0.05173284187912941\n",
      "Epoch: 5/8, Batch: 1380/3444, Loss: 0.01679927296936512\n",
      "Epoch: 5/8, Batch: 1390/3444, Loss: 0.005363226868212223\n",
      "Epoch: 5/8, Batch: 1400/3444, Loss: 0.01395219936966896\n",
      "Epoch: 5/8, Batch: 1410/3444, Loss: 0.012752242386341095\n",
      "Epoch: 5/8, Batch: 1420/3444, Loss: 0.01479997020214796\n",
      "Epoch: 5/8, Batch: 1430/3444, Loss: 0.018744654953479767\n",
      "Epoch: 5/8, Batch: 1440/3444, Loss: 0.018521606922149658\n",
      "Epoch: 5/8, Batch: 1450/3444, Loss: 0.012526125647127628\n",
      "Epoch: 5/8, Batch: 1460/3444, Loss: 0.008744887076318264\n",
      "Epoch: 5/8, Batch: 1470/3444, Loss: 0.00703780259937048\n",
      "Epoch: 5/8, Batch: 1480/3444, Loss: 0.00949039775878191\n",
      "Epoch: 5/8, Batch: 1490/3444, Loss: 0.011252970434725285\n",
      "Epoch: 5/8, Batch: 1500/3444, Loss: 0.022398119792342186\n",
      "Epoch: 5/8, Batch: 1510/3444, Loss: 0.008502913638949394\n",
      "Epoch: 5/8, Batch: 1520/3444, Loss: 0.012621034868061543\n",
      "Epoch: 5/8, Batch: 1530/3444, Loss: 0.011125123128294945\n",
      "Epoch: 5/8, Batch: 1540/3444, Loss: 0.024097677320241928\n",
      "Epoch: 5/8, Batch: 1550/3444, Loss: 0.0060319192707538605\n",
      "Epoch: 5/8, Batch: 1560/3444, Loss: 0.007846005260944366\n",
      "Epoch: 5/8, Batch: 1570/3444, Loss: 0.010848754085600376\n",
      "Epoch: 5/8, Batch: 1580/3444, Loss: 0.008415395393967628\n",
      "Epoch: 5/8, Batch: 1590/3444, Loss: 0.013894171454012394\n",
      "Epoch: 5/8, Batch: 1600/3444, Loss: 0.013956279493868351\n",
      "Epoch: 5/8, Batch: 1610/3444, Loss: 0.014785896986722946\n",
      "Epoch: 5/8, Batch: 1620/3444, Loss: 0.004722344223409891\n",
      "Epoch: 5/8, Batch: 1630/3444, Loss: 0.019482674077153206\n",
      "Epoch: 5/8, Batch: 1640/3444, Loss: 0.009362028911709785\n",
      "Epoch: 5/8, Batch: 1650/3444, Loss: 0.010991116985678673\n",
      "Epoch: 5/8, Batch: 1660/3444, Loss: 0.006425056606531143\n",
      "Epoch: 5/8, Batch: 1670/3444, Loss: 0.003643995150923729\n",
      "Epoch: 5/8, Batch: 1680/3444, Loss: 0.012457618489861488\n",
      "Epoch: 5/8, Batch: 1690/3444, Loss: 0.012091687880456448\n",
      "Epoch: 5/8, Batch: 1700/3444, Loss: 0.04046749696135521\n",
      "Epoch: 5/8, Batch: 1710/3444, Loss: 0.02007053606212139\n",
      "Epoch: 5/8, Batch: 1720/3444, Loss: 0.010159452445805073\n",
      "Epoch: 5/8, Batch: 1730/3444, Loss: 0.008102450519800186\n",
      "Epoch: 5/8, Batch: 1740/3444, Loss: 0.022812524810433388\n",
      "Epoch: 5/8, Batch: 1750/3444, Loss: 0.00864992756396532\n",
      "Epoch: 5/8, Batch: 1760/3444, Loss: 0.009255818091332912\n",
      "Epoch: 5/8, Batch: 1770/3444, Loss: 0.011618267744779587\n",
      "Epoch: 5/8, Batch: 1780/3444, Loss: 0.016002025455236435\n",
      "Epoch: 5/8, Batch: 1790/3444, Loss: 0.011381666176021099\n",
      "Epoch: 5/8, Batch: 1800/3444, Loss: 0.007413577288389206\n",
      "Epoch: 5/8, Batch: 1810/3444, Loss: 0.014267277903854847\n",
      "Epoch: 5/8, Batch: 1820/3444, Loss: 0.012848113663494587\n",
      "Epoch: 5/8, Batch: 1830/3444, Loss: 0.0075875744223594666\n",
      "Epoch: 5/8, Batch: 1840/3444, Loss: 0.008954256772994995\n",
      "Epoch: 5/8, Batch: 1850/3444, Loss: 0.012307988479733467\n",
      "Epoch: 5/8, Batch: 1860/3444, Loss: 0.008578147739171982\n",
      "Epoch: 5/8, Batch: 1870/3444, Loss: 0.007719743065536022\n",
      "Epoch: 5/8, Batch: 1880/3444, Loss: 0.00884270016103983\n",
      "Epoch: 5/8, Batch: 1890/3444, Loss: 0.01366342417895794\n",
      "Epoch: 5/8, Batch: 1900/3444, Loss: 0.008533438667654991\n",
      "Epoch: 5/8, Batch: 1910/3444, Loss: 0.015005325898528099\n",
      "Epoch: 5/8, Batch: 1920/3444, Loss: 0.017987718805670738\n",
      "Epoch: 5/8, Batch: 1930/3444, Loss: 0.008833790197968483\n",
      "Epoch: 5/8, Batch: 1940/3444, Loss: 0.017650896683335304\n",
      "Epoch: 5/8, Batch: 1950/3444, Loss: 0.013669612817466259\n",
      "Epoch: 5/8, Batch: 1960/3444, Loss: 0.01481504738330841\n",
      "Epoch: 5/8, Batch: 1970/3444, Loss: 0.008912074379622936\n",
      "Epoch: 5/8, Batch: 1980/3444, Loss: 0.008672851137816906\n",
      "Epoch: 5/8, Batch: 1990/3444, Loss: 0.0040597859770059586\n",
      "Epoch: 5/8, Batch: 2000/3444, Loss: 0.011209463700652122\n",
      "Epoch: 5/8, Batch: 2010/3444, Loss: 0.017093945294618607\n",
      "Epoch: 5/8, Batch: 2020/3444, Loss: 0.012458054348826408\n",
      "Epoch: 5/8, Batch: 2030/3444, Loss: 0.01277933269739151\n",
      "Epoch: 5/8, Batch: 2040/3444, Loss: 0.005763791035860777\n",
      "Epoch: 5/8, Batch: 2050/3444, Loss: 0.01676545850932598\n",
      "Epoch: 5/8, Batch: 2060/3444, Loss: 0.006950312294065952\n",
      "Epoch: 5/8, Batch: 2070/3444, Loss: 0.007846475578844547\n",
      "Epoch: 5/8, Batch: 2080/3444, Loss: 0.012995388358831406\n",
      "Epoch: 5/8, Batch: 2090/3444, Loss: 0.016394855454564095\n",
      "Epoch: 5/8, Batch: 2100/3444, Loss: 0.009463310241699219\n",
      "Epoch: 5/8, Batch: 2110/3444, Loss: 0.02565157040953636\n",
      "Epoch: 5/8, Batch: 2120/3444, Loss: 0.020021595060825348\n",
      "Epoch: 5/8, Batch: 2130/3444, Loss: 0.035496752709150314\n",
      "Epoch: 5/8, Batch: 2140/3444, Loss: 0.027811545878648758\n",
      "Epoch: 5/8, Batch: 2150/3444, Loss: 0.008362448774278164\n",
      "Epoch: 5/8, Batch: 2160/3444, Loss: 0.01569746434688568\n",
      "Epoch: 5/8, Batch: 2170/3444, Loss: 0.004569586366415024\n",
      "Epoch: 5/8, Batch: 2180/3444, Loss: 0.015517587773501873\n",
      "Epoch: 5/8, Batch: 2190/3444, Loss: 0.0031020366586744785\n",
      "Epoch: 5/8, Batch: 2200/3444, Loss: 0.01133664883673191\n",
      "Epoch: 5/8, Batch: 2210/3444, Loss: 0.019892729818820953\n",
      "Epoch: 5/8, Batch: 2220/3444, Loss: 0.011321368627250195\n",
      "Epoch: 5/8, Batch: 2230/3444, Loss: 0.009304162114858627\n",
      "Epoch: 5/8, Batch: 2240/3444, Loss: 0.011074738577008247\n",
      "Epoch: 5/8, Batch: 2250/3444, Loss: 0.012400646694004536\n",
      "Epoch: 5/8, Batch: 2260/3444, Loss: 0.008262252435088158\n",
      "Epoch: 5/8, Batch: 2270/3444, Loss: 0.014569921419024467\n",
      "Epoch: 5/8, Batch: 2280/3444, Loss: 0.00781572237610817\n",
      "Epoch: 5/8, Batch: 2290/3444, Loss: 0.010953773744404316\n",
      "Epoch: 5/8, Batch: 2300/3444, Loss: 0.005510922521352768\n",
      "Epoch: 5/8, Batch: 2310/3444, Loss: 0.007982809096574783\n",
      "Epoch: 5/8, Batch: 2320/3444, Loss: 0.02588900923728943\n",
      "Epoch: 5/8, Batch: 2330/3444, Loss: 0.04818098992109299\n",
      "Epoch: 5/8, Batch: 2340/3444, Loss: 0.007110385689884424\n",
      "Epoch: 5/8, Batch: 2350/3444, Loss: 0.008087597787380219\n",
      "Epoch: 5/8, Batch: 2360/3444, Loss: 0.03705883026123047\n",
      "Epoch: 5/8, Batch: 2370/3444, Loss: 0.01777465268969536\n",
      "Epoch: 5/8, Batch: 2380/3444, Loss: 0.00668509304523468\n",
      "Epoch: 5/8, Batch: 2390/3444, Loss: 0.003861797973513603\n",
      "Epoch: 5/8, Batch: 2400/3444, Loss: 0.015332255512475967\n",
      "Epoch: 5/8, Batch: 2410/3444, Loss: 0.017335552722215652\n",
      "Epoch: 5/8, Batch: 2420/3444, Loss: 0.009264959953725338\n",
      "Epoch: 5/8, Batch: 2430/3444, Loss: 0.011409481056034565\n",
      "Epoch: 5/8, Batch: 2440/3444, Loss: 0.015630299225449562\n",
      "Epoch: 5/8, Batch: 2450/3444, Loss: 0.005026976112276316\n",
      "Epoch: 5/8, Batch: 2460/3444, Loss: 0.00920369103550911\n",
      "Epoch: 5/8, Batch: 2470/3444, Loss: 0.008218925446271896\n",
      "Epoch: 5/8, Batch: 2480/3444, Loss: 0.015133536420762539\n",
      "Epoch: 5/8, Batch: 2490/3444, Loss: 0.020676452666521072\n",
      "Epoch: 5/8, Batch: 2500/3444, Loss: 0.02178160287439823\n",
      "Epoch: 5/8, Batch: 2510/3444, Loss: 0.019788505509495735\n",
      "Epoch: 5/8, Batch: 2520/3444, Loss: 0.004429468885064125\n",
      "Epoch: 5/8, Batch: 2530/3444, Loss: 0.026358576491475105\n",
      "Epoch: 5/8, Batch: 2540/3444, Loss: 0.013053340837359428\n",
      "Epoch: 5/8, Batch: 2550/3444, Loss: 0.03091544099152088\n",
      "Epoch: 5/8, Batch: 2560/3444, Loss: 0.040749263018369675\n",
      "Epoch: 5/8, Batch: 2570/3444, Loss: 0.022362766787409782\n",
      "Epoch: 5/8, Batch: 2580/3444, Loss: 0.004783083219081163\n",
      "Epoch: 5/8, Batch: 2590/3444, Loss: 0.031817834824323654\n",
      "Epoch: 5/8, Batch: 2600/3444, Loss: 0.008360943756997585\n",
      "Epoch: 5/8, Batch: 2610/3444, Loss: 0.02898462302982807\n",
      "Epoch: 5/8, Batch: 2620/3444, Loss: 0.012182580307126045\n",
      "Epoch: 5/8, Batch: 2630/3444, Loss: 0.012875140644609928\n",
      "Epoch: 5/8, Batch: 2640/3444, Loss: 0.017866795882582664\n",
      "Epoch: 5/8, Batch: 2650/3444, Loss: 0.014523045159876347\n",
      "Epoch: 5/8, Batch: 2660/3444, Loss: 0.016466988250613213\n",
      "Epoch: 5/8, Batch: 2670/3444, Loss: 0.01701630838215351\n",
      "Epoch: 5/8, Batch: 2680/3444, Loss: 0.00953013263642788\n",
      "Epoch: 5/8, Batch: 2690/3444, Loss: 0.014890742488205433\n",
      "Epoch: 5/8, Batch: 2700/3444, Loss: 0.024015596136450768\n",
      "Epoch: 5/8, Batch: 2710/3444, Loss: 0.005318459589034319\n",
      "Epoch: 5/8, Batch: 2720/3444, Loss: 0.027597980573773384\n",
      "Epoch: 5/8, Batch: 2730/3444, Loss: 0.012126009911298752\n",
      "Epoch: 5/8, Batch: 2740/3444, Loss: 0.007369535975158215\n",
      "Epoch: 5/8, Batch: 2750/3444, Loss: 0.0053086900152266026\n",
      "Epoch: 5/8, Batch: 2760/3444, Loss: 0.017078593373298645\n",
      "Epoch: 5/8, Batch: 2770/3444, Loss: 0.006788463797420263\n",
      "Epoch: 5/8, Batch: 2780/3444, Loss: 0.014299779199063778\n",
      "Epoch: 5/8, Batch: 2790/3444, Loss: 0.009043262340128422\n",
      "Epoch: 5/8, Batch: 2800/3444, Loss: 0.014696229249238968\n",
      "Epoch: 5/8, Batch: 2810/3444, Loss: 0.010623871348798275\n",
      "Epoch: 5/8, Batch: 2820/3444, Loss: 0.016721069812774658\n",
      "Epoch: 5/8, Batch: 2830/3444, Loss: 0.004595959093421698\n",
      "Epoch: 5/8, Batch: 2840/3444, Loss: 0.04566424340009689\n",
      "Epoch: 5/8, Batch: 2850/3444, Loss: 0.015424508601427078\n",
      "Epoch: 5/8, Batch: 2860/3444, Loss: 0.010757802054286003\n",
      "Epoch: 5/8, Batch: 2870/3444, Loss: 0.008005587384104729\n",
      "Epoch: 5/8, Batch: 2880/3444, Loss: 0.025700589641928673\n",
      "Epoch: 5/8, Batch: 2890/3444, Loss: 0.023201819509267807\n",
      "Epoch: 5/8, Batch: 2900/3444, Loss: 0.007844522595405579\n",
      "Epoch: 5/8, Batch: 2910/3444, Loss: 0.012935907579958439\n",
      "Epoch: 5/8, Batch: 2920/3444, Loss: 0.02158648706972599\n",
      "Epoch: 5/8, Batch: 2930/3444, Loss: 0.009192036464810371\n",
      "Epoch: 5/8, Batch: 2940/3444, Loss: 0.013780981302261353\n",
      "Epoch: 5/8, Batch: 2950/3444, Loss: 0.015223674476146698\n",
      "Epoch: 5/8, Batch: 2960/3444, Loss: 0.008055847138166428\n",
      "Epoch: 5/8, Batch: 2970/3444, Loss: 0.010697566904127598\n",
      "Epoch: 5/8, Batch: 2980/3444, Loss: 0.01468120701611042\n",
      "Epoch: 5/8, Batch: 2990/3444, Loss: 0.015066199004650116\n",
      "Epoch: 5/8, Batch: 3000/3444, Loss: 0.033785417675971985\n",
      "Epoch: 5/8, Batch: 3010/3444, Loss: 0.010456860065460205\n",
      "Epoch: 5/8, Batch: 3020/3444, Loss: 0.01675155572593212\n",
      "Epoch: 5/8, Batch: 3030/3444, Loss: 0.012870864942669868\n",
      "Epoch: 5/8, Batch: 3040/3444, Loss: 0.01935364492237568\n",
      "Epoch: 5/8, Batch: 3050/3444, Loss: 0.008159889839589596\n",
      "Epoch: 5/8, Batch: 3060/3444, Loss: 0.015277840197086334\n",
      "Epoch: 5/8, Batch: 3070/3444, Loss: 0.037417057901620865\n",
      "Epoch: 5/8, Batch: 3080/3444, Loss: 0.019111357629299164\n",
      "Epoch: 5/8, Batch: 3090/3444, Loss: 0.02507253922522068\n",
      "Epoch: 5/8, Batch: 3100/3444, Loss: 0.01222333125770092\n",
      "Epoch: 5/8, Batch: 3110/3444, Loss: 0.010912972502410412\n",
      "Epoch: 5/8, Batch: 3120/3444, Loss: 0.011287164874374866\n",
      "Epoch: 5/8, Batch: 3130/3444, Loss: 0.010445055551826954\n",
      "Epoch: 5/8, Batch: 3140/3444, Loss: 0.008830145001411438\n",
      "Epoch: 5/8, Batch: 3150/3444, Loss: 0.010824435390532017\n",
      "Epoch: 5/8, Batch: 3160/3444, Loss: 0.010506867431104183\n",
      "Epoch: 5/8, Batch: 3170/3444, Loss: 0.01598924770951271\n",
      "Epoch: 5/8, Batch: 3180/3444, Loss: 0.0066290549002587795\n",
      "Epoch: 5/8, Batch: 3190/3444, Loss: 0.006216805428266525\n",
      "Epoch: 5/8, Batch: 3200/3444, Loss: 0.01449902355670929\n",
      "Epoch: 5/8, Batch: 3210/3444, Loss: 0.013765236362814903\n",
      "Epoch: 5/8, Batch: 3220/3444, Loss: 0.004399323370307684\n",
      "Epoch: 5/8, Batch: 3230/3444, Loss: 0.009173324331641197\n",
      "Epoch: 5/8, Batch: 3240/3444, Loss: 0.03097626380622387\n",
      "Epoch: 5/8, Batch: 3250/3444, Loss: 0.02283456362783909\n",
      "Epoch: 5/8, Batch: 3260/3444, Loss: 0.025062667205929756\n",
      "Epoch: 5/8, Batch: 3270/3444, Loss: 0.011632047593593597\n",
      "Epoch: 5/8, Batch: 3280/3444, Loss: 0.012252788990736008\n",
      "Epoch: 5/8, Batch: 3290/3444, Loss: 0.007759020198136568\n",
      "Epoch: 5/8, Batch: 3300/3444, Loss: 0.020781245082616806\n",
      "Epoch: 5/8, Batch: 3310/3444, Loss: 0.022958554327487946\n",
      "Epoch: 5/8, Batch: 3320/3444, Loss: 0.018427865579724312\n",
      "Epoch: 5/8, Batch: 3330/3444, Loss: 0.016918251290917397\n",
      "Epoch: 5/8, Batch: 3340/3444, Loss: 0.03151446953415871\n",
      "Epoch: 5/8, Batch: 3350/3444, Loss: 0.008691553957760334\n",
      "Epoch: 5/8, Batch: 3360/3444, Loss: 0.00997526291757822\n",
      "Epoch: 5/8, Batch: 3370/3444, Loss: 0.006621563341468573\n",
      "Epoch: 5/8, Batch: 3380/3444, Loss: 0.026131827384233475\n",
      "Epoch: 5/8, Batch: 3390/3444, Loss: 0.02076704613864422\n",
      "Epoch: 5/8, Batch: 3400/3444, Loss: 0.010796059854328632\n",
      "Epoch: 5/8, Batch: 3410/3444, Loss: 0.015056963078677654\n",
      "Epoch: 5/8, Batch: 3420/3444, Loss: 0.0193635281175375\n",
      "Epoch: 5/8, Batch: 3430/3444, Loss: 0.014277628622949123\n",
      "Epoch: 5/8, Batch: 3440/3444, Loss: 0.01564101316034794\n",
      "Epoch: 5/8, Val Loss: 0.006562763502990067\n",
      "Epoch: 6/8, Batch: 10/3444, Loss: 0.015084565617144108\n",
      "Epoch: 6/8, Batch: 20/3444, Loss: 0.014364226721227169\n",
      "Epoch: 6/8, Batch: 30/3444, Loss: 0.05232168361544609\n",
      "Epoch: 6/8, Batch: 40/3444, Loss: 0.012146783992648125\n",
      "Epoch: 6/8, Batch: 50/3444, Loss: 0.013007854111492634\n",
      "Epoch: 6/8, Batch: 60/3444, Loss: 0.0163764338940382\n",
      "Epoch: 6/8, Batch: 70/3444, Loss: 0.0070711467415094376\n",
      "Epoch: 6/8, Batch: 80/3444, Loss: 0.010597276501357555\n",
      "Epoch: 6/8, Batch: 90/3444, Loss: 0.014536275528371334\n",
      "Epoch: 6/8, Batch: 100/3444, Loss: 0.030520465224981308\n",
      "Epoch: 6/8, Batch: 110/3444, Loss: 0.006499714218080044\n",
      "Epoch: 6/8, Batch: 120/3444, Loss: 0.013296780176460743\n",
      "Epoch: 6/8, Batch: 130/3444, Loss: 0.03280341625213623\n",
      "Epoch: 6/8, Batch: 140/3444, Loss: 0.022346392273902893\n",
      "Epoch: 6/8, Batch: 150/3444, Loss: 0.007599078584462404\n",
      "Epoch: 6/8, Batch: 160/3444, Loss: 0.027492649853229523\n",
      "Epoch: 6/8, Batch: 170/3444, Loss: 0.04758176952600479\n",
      "Epoch: 6/8, Batch: 180/3444, Loss: 0.010895834304392338\n",
      "Epoch: 6/8, Batch: 190/3444, Loss: 0.009488148614764214\n",
      "Epoch: 6/8, Batch: 200/3444, Loss: 0.010255787521600723\n",
      "Epoch: 6/8, Batch: 210/3444, Loss: 0.009052562527358532\n",
      "Epoch: 6/8, Batch: 220/3444, Loss: 0.023056713864207268\n",
      "Epoch: 6/8, Batch: 230/3444, Loss: 0.02499300241470337\n",
      "Epoch: 6/8, Batch: 240/3444, Loss: 0.019157247617840767\n",
      "Epoch: 6/8, Batch: 250/3444, Loss: 0.01147415116429329\n",
      "Epoch: 6/8, Batch: 260/3444, Loss: 0.011248098686337471\n",
      "Epoch: 6/8, Batch: 270/3444, Loss: 0.010984078980982304\n",
      "Epoch: 6/8, Batch: 280/3444, Loss: 0.01562021765857935\n",
      "Epoch: 6/8, Batch: 290/3444, Loss: 0.015708645805716515\n",
      "Epoch: 6/8, Batch: 300/3444, Loss: 0.019439931958913803\n",
      "Epoch: 6/8, Batch: 310/3444, Loss: 0.03218972682952881\n",
      "Epoch: 6/8, Batch: 320/3444, Loss: 0.01070311851799488\n",
      "Epoch: 6/8, Batch: 330/3444, Loss: 0.020269714295864105\n",
      "Epoch: 6/8, Batch: 340/3444, Loss: 0.04067237675189972\n",
      "Epoch: 6/8, Batch: 350/3444, Loss: 0.004918783437460661\n",
      "Epoch: 6/8, Batch: 360/3444, Loss: 0.007867103442549706\n",
      "Epoch: 6/8, Batch: 370/3444, Loss: 0.008581995964050293\n",
      "Epoch: 6/8, Batch: 380/3444, Loss: 0.018725281581282616\n",
      "Epoch: 6/8, Batch: 390/3444, Loss: 0.011432085186243057\n",
      "Epoch: 6/8, Batch: 400/3444, Loss: 0.030797790735960007\n",
      "Epoch: 6/8, Batch: 410/3444, Loss: 0.018225396052002907\n",
      "Epoch: 6/8, Batch: 420/3444, Loss: 0.013005129061639309\n",
      "Epoch: 6/8, Batch: 430/3444, Loss: 0.010410495102405548\n",
      "Epoch: 6/8, Batch: 440/3444, Loss: 0.0068914326839149\n",
      "Epoch: 6/8, Batch: 450/3444, Loss: 0.008101428858935833\n",
      "Epoch: 6/8, Batch: 460/3444, Loss: 0.03173798695206642\n",
      "Epoch: 6/8, Batch: 470/3444, Loss: 0.008822254836559296\n",
      "Epoch: 6/8, Batch: 480/3444, Loss: 0.00972686242312193\n",
      "Epoch: 6/8, Batch: 490/3444, Loss: 0.02895970270037651\n",
      "Epoch: 6/8, Batch: 500/3444, Loss: 0.009200174361467361\n",
      "Epoch: 6/8, Batch: 510/3444, Loss: 0.005360965151339769\n",
      "Epoch: 6/8, Batch: 520/3444, Loss: 0.011366959661245346\n",
      "Epoch: 6/8, Batch: 530/3444, Loss: 0.008168952539563179\n",
      "Epoch: 6/8, Batch: 540/3444, Loss: 0.009142091497778893\n",
      "Epoch: 6/8, Batch: 550/3444, Loss: 0.033792342990636826\n",
      "Epoch: 6/8, Batch: 560/3444, Loss: 0.03378411754965782\n",
      "Epoch: 6/8, Batch: 570/3444, Loss: 0.007375252898782492\n",
      "Epoch: 6/8, Batch: 580/3444, Loss: 0.008554873056709766\n",
      "Epoch: 6/8, Batch: 590/3444, Loss: 0.018051698803901672\n",
      "Epoch: 6/8, Batch: 600/3444, Loss: 0.03158273547887802\n",
      "Epoch: 6/8, Batch: 610/3444, Loss: 0.009238689206540585\n",
      "Epoch: 6/8, Batch: 620/3444, Loss: 0.006805941462516785\n",
      "Epoch: 6/8, Batch: 630/3444, Loss: 0.010441438294947147\n",
      "Epoch: 6/8, Batch: 640/3444, Loss: 0.011599614284932613\n",
      "Epoch: 6/8, Batch: 650/3444, Loss: 0.014615186490118504\n",
      "Epoch: 6/8, Batch: 660/3444, Loss: 0.020870259031653404\n",
      "Epoch: 6/8, Batch: 670/3444, Loss: 0.013159137219190598\n",
      "Epoch: 6/8, Batch: 680/3444, Loss: 0.006774639245122671\n",
      "Epoch: 6/8, Batch: 690/3444, Loss: 0.017544027417898178\n",
      "Epoch: 6/8, Batch: 700/3444, Loss: 0.009468347765505314\n",
      "Epoch: 6/8, Batch: 710/3444, Loss: 0.017965424805879593\n",
      "Epoch: 6/8, Batch: 720/3444, Loss: 0.006449483335018158\n",
      "Epoch: 6/8, Batch: 730/3444, Loss: 0.00458740396425128\n",
      "Epoch: 6/8, Batch: 740/3444, Loss: 0.006984971929341555\n",
      "Epoch: 6/8, Batch: 750/3444, Loss: 0.011402744799852371\n",
      "Epoch: 6/8, Batch: 760/3444, Loss: 0.007536306977272034\n",
      "Epoch: 6/8, Batch: 770/3444, Loss: 0.02094811201095581\n",
      "Epoch: 6/8, Batch: 780/3444, Loss: 0.03457172214984894\n",
      "Epoch: 6/8, Batch: 790/3444, Loss: 0.024932557716965675\n",
      "Epoch: 6/8, Batch: 800/3444, Loss: 0.009085542522370815\n",
      "Epoch: 6/8, Batch: 810/3444, Loss: 0.03098861686885357\n",
      "Epoch: 6/8, Batch: 820/3444, Loss: 0.019754789769649506\n",
      "Epoch: 6/8, Batch: 830/3444, Loss: 0.007090521510690451\n",
      "Epoch: 6/8, Batch: 840/3444, Loss: 0.009396416135132313\n",
      "Epoch: 6/8, Batch: 850/3444, Loss: 0.009668604470789433\n",
      "Epoch: 6/8, Batch: 860/3444, Loss: 0.01741519197821617\n",
      "Epoch: 6/8, Batch: 870/3444, Loss: 0.014657357707619667\n",
      "Epoch: 6/8, Batch: 880/3444, Loss: 0.01981760747730732\n",
      "Epoch: 6/8, Batch: 890/3444, Loss: 0.015515640377998352\n",
      "Epoch: 6/8, Batch: 900/3444, Loss: 0.009066849015653133\n",
      "Epoch: 6/8, Batch: 910/3444, Loss: 0.004780553746968508\n",
      "Epoch: 6/8, Batch: 920/3444, Loss: 0.020953930914402008\n",
      "Epoch: 6/8, Batch: 930/3444, Loss: 0.008443416096270084\n",
      "Epoch: 6/8, Batch: 940/3444, Loss: 0.014711351133883\n",
      "Epoch: 6/8, Batch: 950/3444, Loss: 0.019421150907874107\n",
      "Epoch: 6/8, Batch: 960/3444, Loss: 0.02604069374501705\n",
      "Epoch: 6/8, Batch: 970/3444, Loss: 0.01569090597331524\n",
      "Epoch: 6/8, Batch: 980/3444, Loss: 0.023025905713438988\n",
      "Epoch: 6/8, Batch: 990/3444, Loss: 0.005061535630375147\n",
      "Epoch: 6/8, Batch: 1000/3444, Loss: 0.01779031753540039\n",
      "Epoch: 6/8, Batch: 1010/3444, Loss: 0.020228179171681404\n",
      "Epoch: 6/8, Batch: 1020/3444, Loss: 0.00614716624841094\n",
      "Epoch: 6/8, Batch: 1030/3444, Loss: 0.00805444922298193\n",
      "Epoch: 6/8, Batch: 1040/3444, Loss: 0.01359846442937851\n",
      "Epoch: 6/8, Batch: 1050/3444, Loss: 0.0033021685667335987\n",
      "Epoch: 6/8, Batch: 1060/3444, Loss: 0.01114856731146574\n",
      "Epoch: 6/8, Batch: 1070/3444, Loss: 0.010426190681755543\n",
      "Epoch: 6/8, Batch: 1080/3444, Loss: 0.012792791239917278\n",
      "Epoch: 6/8, Batch: 1090/3444, Loss: 0.015460238792002201\n",
      "Epoch: 6/8, Batch: 1100/3444, Loss: 0.02573985606431961\n",
      "Epoch: 6/8, Batch: 1110/3444, Loss: 0.010307561606168747\n",
      "Epoch: 6/8, Batch: 1120/3444, Loss: 0.017282577231526375\n",
      "Epoch: 6/8, Batch: 1130/3444, Loss: 0.009067371487617493\n",
      "Epoch: 6/8, Batch: 1140/3444, Loss: 0.02526789717376232\n",
      "Epoch: 6/8, Batch: 1150/3444, Loss: 0.007647410035133362\n",
      "Epoch: 6/8, Batch: 1160/3444, Loss: 0.020746542140841484\n",
      "Epoch: 6/8, Batch: 1170/3444, Loss: 0.0130376685410738\n",
      "Epoch: 6/8, Batch: 1180/3444, Loss: 0.01123577356338501\n",
      "Epoch: 6/8, Batch: 1190/3444, Loss: 0.011077502742409706\n",
      "Epoch: 6/8, Batch: 1200/3444, Loss: 0.01701568253338337\n",
      "Epoch: 6/8, Batch: 1210/3444, Loss: 0.015531521290540695\n",
      "Epoch: 6/8, Batch: 1220/3444, Loss: 0.018336255103349686\n",
      "Epoch: 6/8, Batch: 1230/3444, Loss: 0.029285866767168045\n",
      "Epoch: 6/8, Batch: 1240/3444, Loss: 0.016817623749375343\n",
      "Epoch: 6/8, Batch: 1250/3444, Loss: 0.00837567076086998\n",
      "Epoch: 6/8, Batch: 1260/3444, Loss: 0.014725017361342907\n",
      "Epoch: 6/8, Batch: 1270/3444, Loss: 0.012705874629318714\n",
      "Epoch: 6/8, Batch: 1280/3444, Loss: 0.016743546351790428\n",
      "Epoch: 6/8, Batch: 1290/3444, Loss: 0.005250022280961275\n",
      "Epoch: 6/8, Batch: 1300/3444, Loss: 0.03120495192706585\n",
      "Epoch: 6/8, Batch: 1310/3444, Loss: 0.01521687675267458\n",
      "Epoch: 6/8, Batch: 1320/3444, Loss: 0.01877046748995781\n",
      "Epoch: 6/8, Batch: 1330/3444, Loss: 0.01108792144805193\n",
      "Epoch: 6/8, Batch: 1340/3444, Loss: 0.009199981577694416\n",
      "Epoch: 6/8, Batch: 1350/3444, Loss: 0.027959467843174934\n",
      "Epoch: 6/8, Batch: 1360/3444, Loss: 0.011900917626917362\n",
      "Epoch: 6/8, Batch: 1370/3444, Loss: 0.013622824102640152\n",
      "Epoch: 6/8, Batch: 1380/3444, Loss: 0.022884175181388855\n",
      "Epoch: 6/8, Batch: 1390/3444, Loss: 0.006872536148875952\n",
      "Epoch: 6/8, Batch: 1400/3444, Loss: 0.014189545065164566\n",
      "Epoch: 6/8, Batch: 1410/3444, Loss: 0.01601310260593891\n",
      "Epoch: 6/8, Batch: 1420/3444, Loss: 0.007189954165369272\n",
      "Epoch: 6/8, Batch: 1430/3444, Loss: 0.009273862466216087\n",
      "Epoch: 6/8, Batch: 1440/3444, Loss: 0.012125581502914429\n",
      "Epoch: 6/8, Batch: 1450/3444, Loss: 0.004187718033790588\n",
      "Epoch: 6/8, Batch: 1460/3444, Loss: 0.016654787585139275\n",
      "Epoch: 6/8, Batch: 1470/3444, Loss: 0.006354359909892082\n",
      "Epoch: 6/8, Batch: 1480/3444, Loss: 0.05567394942045212\n",
      "Epoch: 6/8, Batch: 1490/3444, Loss: 0.02823169343173504\n",
      "Epoch: 6/8, Batch: 1500/3444, Loss: 0.0064607709646224976\n",
      "Epoch: 6/8, Batch: 1510/3444, Loss: 0.00910209771245718\n",
      "Epoch: 6/8, Batch: 1520/3444, Loss: 0.016520006582140923\n",
      "Epoch: 6/8, Batch: 1530/3444, Loss: 0.03873692452907562\n",
      "Epoch: 6/8, Batch: 1540/3444, Loss: 0.008120821788907051\n",
      "Epoch: 6/8, Batch: 1550/3444, Loss: 0.012300146743655205\n",
      "Epoch: 6/8, Batch: 1560/3444, Loss: 0.00945736188441515\n",
      "Epoch: 6/8, Batch: 1570/3444, Loss: 0.03793419525027275\n",
      "Epoch: 6/8, Batch: 1580/3444, Loss: 0.02389821596443653\n",
      "Epoch: 6/8, Batch: 1590/3444, Loss: 0.024697741493582726\n",
      "Epoch: 6/8, Batch: 1600/3444, Loss: 0.014104201458394527\n",
      "Epoch: 6/8, Batch: 1610/3444, Loss: 0.00468088872730732\n",
      "Epoch: 6/8, Batch: 1620/3444, Loss: 0.017624737694859505\n",
      "Epoch: 6/8, Batch: 1630/3444, Loss: 0.016129694879055023\n",
      "Epoch: 6/8, Batch: 1640/3444, Loss: 0.014806387014687061\n",
      "Epoch: 6/8, Batch: 1650/3444, Loss: 0.012503370642662048\n",
      "Epoch: 6/8, Batch: 1660/3444, Loss: 0.033945050090551376\n",
      "Epoch: 6/8, Batch: 1670/3444, Loss: 0.012651825323700905\n",
      "Epoch: 6/8, Batch: 1680/3444, Loss: 0.008240600116550922\n",
      "Epoch: 6/8, Batch: 1690/3444, Loss: 0.014516094699501991\n",
      "Epoch: 6/8, Batch: 1700/3444, Loss: 0.011808652430772781\n",
      "Epoch: 6/8, Batch: 1710/3444, Loss: 0.01541855651885271\n",
      "Epoch: 6/8, Batch: 1720/3444, Loss: 0.008773324079811573\n",
      "Epoch: 6/8, Batch: 1730/3444, Loss: 0.0030485233291983604\n",
      "Epoch: 6/8, Batch: 1740/3444, Loss: 0.018439069390296936\n",
      "Epoch: 6/8, Batch: 1750/3444, Loss: 0.009636618196964264\n",
      "Epoch: 6/8, Batch: 1760/3444, Loss: 0.012952887453138828\n",
      "Epoch: 6/8, Batch: 1770/3444, Loss: 0.02613626793026924\n",
      "Epoch: 6/8, Batch: 1780/3444, Loss: 0.006637856364250183\n",
      "Epoch: 6/8, Batch: 1790/3444, Loss: 0.01707983762025833\n",
      "Epoch: 6/8, Batch: 1800/3444, Loss: 0.010362623259425163\n",
      "Epoch: 6/8, Batch: 1810/3444, Loss: 0.03353678435087204\n",
      "Epoch: 6/8, Batch: 1820/3444, Loss: 0.010623371228575706\n",
      "Epoch: 6/8, Batch: 1830/3444, Loss: 0.025600101798772812\n",
      "Epoch: 6/8, Batch: 1840/3444, Loss: 0.014224592596292496\n",
      "Epoch: 6/8, Batch: 1850/3444, Loss: 0.01922866888344288\n",
      "Epoch: 6/8, Batch: 1860/3444, Loss: 0.009645058773458004\n",
      "Epoch: 6/8, Batch: 1870/3444, Loss: 0.013376089744269848\n",
      "Epoch: 6/8, Batch: 1880/3444, Loss: 0.022847043350338936\n",
      "Epoch: 6/8, Batch: 1890/3444, Loss: 0.034534238278865814\n",
      "Epoch: 6/8, Batch: 1900/3444, Loss: 0.013860054314136505\n",
      "Epoch: 6/8, Batch: 1910/3444, Loss: 0.019178481772542\n",
      "Epoch: 6/8, Batch: 1920/3444, Loss: 0.020449692383408546\n",
      "Epoch: 6/8, Batch: 1930/3444, Loss: 0.013088083826005459\n",
      "Epoch: 6/8, Batch: 1940/3444, Loss: 0.03496241196990013\n",
      "Epoch: 6/8, Batch: 1950/3444, Loss: 0.018804341554641724\n",
      "Epoch: 6/8, Batch: 1960/3444, Loss: 0.010496231727302074\n",
      "Epoch: 6/8, Batch: 1970/3444, Loss: 0.009906439110636711\n",
      "Epoch: 6/8, Batch: 1980/3444, Loss: 0.011520220898091793\n",
      "Epoch: 6/8, Batch: 1990/3444, Loss: 0.004636411089450121\n",
      "Epoch: 6/8, Batch: 2000/3444, Loss: 0.012780984863638878\n",
      "Epoch: 6/8, Batch: 2010/3444, Loss: 0.006368828006088734\n",
      "Epoch: 6/8, Batch: 2020/3444, Loss: 0.011529403738677502\n",
      "Epoch: 6/8, Batch: 2030/3444, Loss: 0.008217782713472843\n",
      "Epoch: 6/8, Batch: 2040/3444, Loss: 0.0031536458991467953\n",
      "Epoch: 6/8, Batch: 2050/3444, Loss: 0.01937771774828434\n",
      "Epoch: 6/8, Batch: 2060/3444, Loss: 0.010429003275930882\n",
      "Epoch: 6/8, Batch: 2070/3444, Loss: 0.011958938091993332\n",
      "Epoch: 6/8, Batch: 2080/3444, Loss: 0.008449860848486423\n",
      "Epoch: 6/8, Batch: 2090/3444, Loss: 0.012698203325271606\n",
      "Epoch: 6/8, Batch: 2100/3444, Loss: 0.028623685240745544\n",
      "Epoch: 6/8, Batch: 2110/3444, Loss: 0.015099174343049526\n",
      "Epoch: 6/8, Batch: 2120/3444, Loss: 0.014027420431375504\n",
      "Epoch: 6/8, Batch: 2130/3444, Loss: 0.011269357055425644\n",
      "Epoch: 6/8, Batch: 2140/3444, Loss: 0.006550772115588188\n",
      "Epoch: 6/8, Batch: 2150/3444, Loss: 0.013335984200239182\n",
      "Epoch: 6/8, Batch: 2160/3444, Loss: 0.012143325991928577\n",
      "Epoch: 6/8, Batch: 2170/3444, Loss: 0.006271818652749062\n",
      "Epoch: 6/8, Batch: 2180/3444, Loss: 0.01770664006471634\n",
      "Epoch: 6/8, Batch: 2190/3444, Loss: 0.01941571943461895\n",
      "Epoch: 6/8, Batch: 2200/3444, Loss: 0.00937129557132721\n",
      "Epoch: 6/8, Batch: 2210/3444, Loss: 0.008641920052468777\n",
      "Epoch: 6/8, Batch: 2220/3444, Loss: 0.012814628891646862\n",
      "Epoch: 6/8, Batch: 2230/3444, Loss: 0.010248962789773941\n",
      "Epoch: 6/8, Batch: 2240/3444, Loss: 0.017724834382534027\n",
      "Epoch: 6/8, Batch: 2250/3444, Loss: 0.008465725928544998\n",
      "Epoch: 6/8, Batch: 2260/3444, Loss: 0.024858027696609497\n",
      "Epoch: 6/8, Batch: 2270/3444, Loss: 0.02925187721848488\n",
      "Epoch: 6/8, Batch: 2280/3444, Loss: 0.027502307668328285\n",
      "Epoch: 6/8, Batch: 2290/3444, Loss: 0.028077412396669388\n",
      "Epoch: 6/8, Batch: 2300/3444, Loss: 0.005769210867583752\n",
      "Epoch: 6/8, Batch: 2310/3444, Loss: 0.00983485672622919\n",
      "Epoch: 6/8, Batch: 2320/3444, Loss: 0.08799664676189423\n",
      "Epoch: 6/8, Batch: 2330/3444, Loss: 0.011545094661414623\n",
      "Epoch: 6/8, Batch: 2340/3444, Loss: 0.022235926240682602\n",
      "Epoch: 6/8, Batch: 2350/3444, Loss: 0.02033989131450653\n",
      "Epoch: 6/8, Batch: 2360/3444, Loss: 0.009336920455098152\n",
      "Epoch: 6/8, Batch: 2370/3444, Loss: 0.02394985593855381\n",
      "Epoch: 6/8, Batch: 2380/3444, Loss: 0.018944313749670982\n",
      "Epoch: 6/8, Batch: 2390/3444, Loss: 0.02168460749089718\n",
      "Epoch: 6/8, Batch: 2400/3444, Loss: 0.031563032418489456\n",
      "Epoch: 6/8, Batch: 2410/3444, Loss: 0.008204451762139797\n",
      "Epoch: 6/8, Batch: 2420/3444, Loss: 0.018864866346120834\n",
      "Epoch: 6/8, Batch: 2430/3444, Loss: 0.022658495232462883\n",
      "Epoch: 6/8, Batch: 2440/3444, Loss: 0.012589165940880775\n",
      "Epoch: 6/8, Batch: 2450/3444, Loss: 0.03192251920700073\n",
      "Epoch: 6/8, Batch: 2460/3444, Loss: 0.013788005337119102\n",
      "Epoch: 6/8, Batch: 2470/3444, Loss: 0.01714458502829075\n",
      "Epoch: 6/8, Batch: 2480/3444, Loss: 0.0058349850587546825\n",
      "Epoch: 6/8, Batch: 2490/3444, Loss: 0.05249534547328949\n",
      "Epoch: 6/8, Batch: 2500/3444, Loss: 0.01649777777493\n",
      "Epoch: 6/8, Batch: 2510/3444, Loss: 0.0064935158006846905\n",
      "Epoch: 6/8, Batch: 2520/3444, Loss: 0.007352855056524277\n",
      "Epoch: 6/8, Batch: 2530/3444, Loss: 0.008410143665969372\n",
      "Epoch: 6/8, Batch: 2540/3444, Loss: 0.017766378819942474\n",
      "Epoch: 6/8, Batch: 2550/3444, Loss: 0.0077782138250768185\n",
      "Epoch: 6/8, Batch: 2560/3444, Loss: 0.01412596832960844\n",
      "Epoch: 6/8, Batch: 2570/3444, Loss: 0.006100822240114212\n",
      "Epoch: 6/8, Batch: 2580/3444, Loss: 0.012389570474624634\n",
      "Epoch: 6/8, Batch: 2590/3444, Loss: 0.008881102316081524\n",
      "Epoch: 6/8, Batch: 2600/3444, Loss: 0.009741066955029964\n",
      "Epoch: 6/8, Batch: 2610/3444, Loss: 0.01011630892753601\n",
      "Epoch: 6/8, Batch: 2620/3444, Loss: 0.008910946547985077\n",
      "Epoch: 6/8, Batch: 2630/3444, Loss: 0.0146297886967659\n",
      "Epoch: 6/8, Batch: 2640/3444, Loss: 0.032967615872621536\n",
      "Epoch: 6/8, Batch: 2650/3444, Loss: 0.019583338871598244\n",
      "Epoch: 6/8, Batch: 2660/3444, Loss: 0.01318885013461113\n",
      "Epoch: 6/8, Batch: 2670/3444, Loss: 0.030774682760238647\n",
      "Epoch: 6/8, Batch: 2680/3444, Loss: 0.021956058219075203\n",
      "Epoch: 6/8, Batch: 2690/3444, Loss: 0.00811857357621193\n",
      "Epoch: 6/8, Batch: 2700/3444, Loss: 0.03281908482313156\n",
      "Epoch: 6/8, Batch: 2710/3444, Loss: 0.03541043773293495\n",
      "Epoch: 6/8, Batch: 2720/3444, Loss: 0.01978226564824581\n",
      "Epoch: 6/8, Batch: 2730/3444, Loss: 0.006271754391491413\n",
      "Epoch: 6/8, Batch: 2740/3444, Loss: 0.009526493027806282\n",
      "Epoch: 6/8, Batch: 2750/3444, Loss: 0.014226562343537807\n",
      "Epoch: 6/8, Batch: 2760/3444, Loss: 0.028045622631907463\n",
      "Epoch: 6/8, Batch: 2770/3444, Loss: 0.015639623627066612\n",
      "Epoch: 6/8, Batch: 2780/3444, Loss: 0.015199068002402782\n",
      "Epoch: 6/8, Batch: 2790/3444, Loss: 0.014197592623531818\n",
      "Epoch: 6/8, Batch: 2800/3444, Loss: 0.010196943767368793\n",
      "Epoch: 6/8, Batch: 2810/3444, Loss: 0.007904846221208572\n",
      "Epoch: 6/8, Batch: 2820/3444, Loss: 0.01516543049365282\n",
      "Epoch: 6/8, Batch: 2830/3444, Loss: 0.01055633183568716\n",
      "Epoch: 6/8, Batch: 2840/3444, Loss: 0.006830626167356968\n",
      "Epoch: 6/8, Batch: 2850/3444, Loss: 0.015313259325921535\n",
      "Epoch: 6/8, Batch: 2860/3444, Loss: 0.01567891426384449\n",
      "Epoch: 6/8, Batch: 2870/3444, Loss: 0.03232578560709953\n",
      "Epoch: 6/8, Batch: 2880/3444, Loss: 0.011834580451250076\n",
      "Epoch: 6/8, Batch: 2890/3444, Loss: 0.015729451552033424\n",
      "Epoch: 6/8, Batch: 2900/3444, Loss: 0.011322196573019028\n",
      "Epoch: 6/8, Batch: 2910/3444, Loss: 0.014441917650401592\n",
      "Epoch: 6/8, Batch: 2920/3444, Loss: 0.01364757027477026\n",
      "Epoch: 6/8, Batch: 2930/3444, Loss: 0.012627046555280685\n",
      "Epoch: 6/8, Batch: 2940/3444, Loss: 0.010729764588177204\n",
      "Epoch: 6/8, Batch: 2950/3444, Loss: 0.004615890793502331\n",
      "Epoch: 6/8, Batch: 2960/3444, Loss: 0.007991894148290157\n",
      "Epoch: 6/8, Batch: 2970/3444, Loss: 0.012754876166582108\n",
      "Epoch: 6/8, Batch: 2980/3444, Loss: 0.005808355286717415\n",
      "Epoch: 6/8, Batch: 2990/3444, Loss: 0.012153230607509613\n",
      "Epoch: 6/8, Batch: 3000/3444, Loss: 0.004671337548643351\n",
      "Epoch: 6/8, Batch: 3010/3444, Loss: 0.01571224257349968\n",
      "Epoch: 6/8, Batch: 3020/3444, Loss: 0.00945460144430399\n",
      "Epoch: 6/8, Batch: 3030/3444, Loss: 0.009263457730412483\n",
      "Epoch: 6/8, Batch: 3040/3444, Loss: 0.023336131125688553\n",
      "Epoch: 6/8, Batch: 3050/3444, Loss: 0.026565974578261375\n",
      "Epoch: 6/8, Batch: 3060/3444, Loss: 0.012997368350625038\n",
      "Epoch: 6/8, Batch: 3070/3444, Loss: 0.008933573961257935\n",
      "Epoch: 6/8, Batch: 3080/3444, Loss: 0.08725299686193466\n",
      "Epoch: 6/8, Batch: 3090/3444, Loss: 0.011910589411854744\n",
      "Epoch: 6/8, Batch: 3100/3444, Loss: 0.00813786219805479\n",
      "Epoch: 6/8, Batch: 3110/3444, Loss: 0.008999361656606197\n",
      "Epoch: 6/8, Batch: 3120/3444, Loss: 0.0088908476755023\n",
      "Epoch: 6/8, Batch: 3130/3444, Loss: 0.009039308875799179\n",
      "Epoch: 6/8, Batch: 3140/3444, Loss: 0.0117120873183012\n",
      "Epoch: 6/8, Batch: 3150/3444, Loss: 0.01766631193459034\n",
      "Epoch: 6/8, Batch: 3160/3444, Loss: 0.012611376121640205\n",
      "Epoch: 6/8, Batch: 3170/3444, Loss: 0.00813919398933649\n",
      "Epoch: 6/8, Batch: 3180/3444, Loss: 0.023883013054728508\n",
      "Epoch: 6/8, Batch: 3190/3444, Loss: 0.006262024864554405\n",
      "Epoch: 6/8, Batch: 3200/3444, Loss: 0.009736904874444008\n",
      "Epoch: 6/8, Batch: 3210/3444, Loss: 0.013824407011270523\n",
      "Epoch: 6/8, Batch: 3220/3444, Loss: 0.007857803255319595\n",
      "Epoch: 6/8, Batch: 3230/3444, Loss: 0.010434862226247787\n",
      "Epoch: 6/8, Batch: 3240/3444, Loss: 0.019242502748966217\n",
      "Epoch: 6/8, Batch: 3250/3444, Loss: 0.010031414218246937\n",
      "Epoch: 6/8, Batch: 3260/3444, Loss: 0.012482750229537487\n",
      "Epoch: 6/8, Batch: 3270/3444, Loss: 0.012222396209836006\n",
      "Epoch: 6/8, Batch: 3280/3444, Loss: 0.012096788734197617\n",
      "Epoch: 6/8, Batch: 3290/3444, Loss: 0.01622227020561695\n",
      "Epoch: 6/8, Batch: 3300/3444, Loss: 0.029635010287165642\n",
      "Epoch: 6/8, Batch: 3310/3444, Loss: 0.00924240704625845\n",
      "Epoch: 6/8, Batch: 3320/3444, Loss: 0.017821619287133217\n",
      "Epoch: 6/8, Batch: 3330/3444, Loss: 0.009461216628551483\n",
      "Epoch: 6/8, Batch: 3340/3444, Loss: 0.005991663783788681\n",
      "Epoch: 6/8, Batch: 3350/3444, Loss: 0.012902393005788326\n",
      "Epoch: 6/8, Batch: 3360/3444, Loss: 0.02301338128745556\n",
      "Epoch: 6/8, Batch: 3370/3444, Loss: 0.016142385080456734\n",
      "Epoch: 6/8, Batch: 3380/3444, Loss: 0.018876662477850914\n",
      "Epoch: 6/8, Batch: 3390/3444, Loss: 0.02265448495745659\n",
      "Epoch: 6/8, Batch: 3400/3444, Loss: 0.010720081627368927\n",
      "Epoch: 6/8, Batch: 3410/3444, Loss: 0.0296376571059227\n",
      "Epoch: 6/8, Batch: 3420/3444, Loss: 0.008285644464194775\n",
      "Epoch: 6/8, Batch: 3430/3444, Loss: 0.011117569170892239\n",
      "Epoch: 6/8, Batch: 3440/3444, Loss: 0.01114946510642767\n",
      "Epoch: 6/8, Val Loss: 0.014089061046272309\n",
      "Epoch: 7/8, Batch: 10/3444, Loss: 0.015085438266396523\n",
      "Epoch: 7/8, Batch: 20/3444, Loss: 0.017035748809576035\n",
      "Epoch: 7/8, Batch: 30/3444, Loss: 0.03203462436795235\n",
      "Epoch: 7/8, Batch: 40/3444, Loss: 0.006723501719534397\n",
      "Epoch: 7/8, Batch: 50/3444, Loss: 0.013862076215445995\n",
      "Epoch: 7/8, Batch: 60/3444, Loss: 0.016918445006012917\n",
      "Epoch: 7/8, Batch: 70/3444, Loss: 0.018491560593247414\n",
      "Epoch: 7/8, Batch: 80/3444, Loss: 0.01499697845429182\n",
      "Epoch: 7/8, Batch: 90/3444, Loss: 0.008240030147135258\n",
      "Epoch: 7/8, Batch: 100/3444, Loss: 0.008103548549115658\n",
      "Epoch: 7/8, Batch: 110/3444, Loss: 0.011034032329916954\n",
      "Epoch: 7/8, Batch: 120/3444, Loss: 0.0185373667627573\n",
      "Epoch: 7/8, Batch: 130/3444, Loss: 0.007711321581155062\n",
      "Epoch: 7/8, Batch: 140/3444, Loss: 0.012040437199175358\n",
      "Epoch: 7/8, Batch: 150/3444, Loss: 0.007819974794983864\n",
      "Epoch: 7/8, Batch: 160/3444, Loss: 0.008236152119934559\n",
      "Epoch: 7/8, Batch: 170/3444, Loss: 0.007001322694122791\n",
      "Epoch: 7/8, Batch: 180/3444, Loss: 0.01292270328849554\n",
      "Epoch: 7/8, Batch: 190/3444, Loss: 0.048429541289806366\n",
      "Epoch: 7/8, Batch: 200/3444, Loss: 0.017451269552111626\n",
      "Epoch: 7/8, Batch: 210/3444, Loss: 0.008490518666803837\n",
      "Epoch: 7/8, Batch: 220/3444, Loss: 0.026889527216553688\n",
      "Epoch: 7/8, Batch: 230/3444, Loss: 0.007514328230172396\n",
      "Epoch: 7/8, Batch: 240/3444, Loss: 0.01661870814859867\n",
      "Epoch: 7/8, Batch: 250/3444, Loss: 0.010786193422973156\n",
      "Epoch: 7/8, Batch: 260/3444, Loss: 0.008927511051297188\n",
      "Epoch: 7/8, Batch: 270/3444, Loss: 0.013933710753917694\n",
      "Epoch: 7/8, Batch: 280/3444, Loss: 0.008860759437084198\n",
      "Epoch: 7/8, Batch: 290/3444, Loss: 0.007442448753863573\n",
      "Epoch: 7/8, Batch: 300/3444, Loss: 0.019270647317171097\n",
      "Epoch: 7/8, Batch: 310/3444, Loss: 0.022392062470316887\n",
      "Epoch: 7/8, Batch: 320/3444, Loss: 0.0041604661382734776\n",
      "Epoch: 7/8, Batch: 330/3444, Loss: 0.023845665156841278\n",
      "Epoch: 7/8, Batch: 340/3444, Loss: 0.009039100259542465\n",
      "Epoch: 7/8, Batch: 350/3444, Loss: 0.04239863529801369\n",
      "Epoch: 7/8, Batch: 360/3444, Loss: 0.030823446810245514\n",
      "Epoch: 7/8, Batch: 370/3444, Loss: 0.02685573510825634\n",
      "Epoch: 7/8, Batch: 380/3444, Loss: 0.0145083237439394\n",
      "Epoch: 7/8, Batch: 390/3444, Loss: 0.04488496109843254\n",
      "Epoch: 7/8, Batch: 400/3444, Loss: 0.009925010614097118\n",
      "Epoch: 7/8, Batch: 410/3444, Loss: 0.0115286186337471\n",
      "Epoch: 7/8, Batch: 420/3444, Loss: 0.020114853978157043\n",
      "Epoch: 7/8, Batch: 430/3444, Loss: 0.017512574791908264\n",
      "Epoch: 7/8, Batch: 440/3444, Loss: 0.01851341314613819\n",
      "Epoch: 7/8, Batch: 450/3444, Loss: 0.012353640049695969\n",
      "Epoch: 7/8, Batch: 460/3444, Loss: 0.006826419848948717\n",
      "Epoch: 7/8, Batch: 470/3444, Loss: 0.0063034906052052975\n",
      "Epoch: 7/8, Batch: 480/3444, Loss: 0.013049041852355003\n",
      "Epoch: 7/8, Batch: 490/3444, Loss: 0.008281338959932327\n",
      "Epoch: 7/8, Batch: 500/3444, Loss: 0.011277545243501663\n",
      "Epoch: 7/8, Batch: 510/3444, Loss: 0.009750330820679665\n",
      "Epoch: 7/8, Batch: 520/3444, Loss: 0.011012351140379906\n",
      "Epoch: 7/8, Batch: 530/3444, Loss: 0.014967896044254303\n",
      "Epoch: 7/8, Batch: 540/3444, Loss: 0.01527341827750206\n",
      "Epoch: 7/8, Batch: 550/3444, Loss: 0.006791327148675919\n",
      "Epoch: 7/8, Batch: 560/3444, Loss: 0.009776705875992775\n",
      "Epoch: 7/8, Batch: 570/3444, Loss: 0.02537422813475132\n",
      "Epoch: 7/8, Batch: 580/3444, Loss: 0.013622976839542389\n",
      "Epoch: 7/8, Batch: 590/3444, Loss: 0.005566868931055069\n",
      "Epoch: 7/8, Batch: 600/3444, Loss: 0.010530284605920315\n",
      "Epoch: 7/8, Batch: 610/3444, Loss: 0.01944592595100403\n",
      "Epoch: 7/8, Batch: 620/3444, Loss: 0.0055681075900793076\n",
      "Epoch: 7/8, Batch: 630/3444, Loss: 0.03599875047802925\n",
      "Epoch: 7/8, Batch: 640/3444, Loss: 0.01339914184063673\n",
      "Epoch: 7/8, Batch: 650/3444, Loss: 0.007334633730351925\n",
      "Epoch: 7/8, Batch: 660/3444, Loss: 0.01622922718524933\n",
      "Epoch: 7/8, Batch: 670/3444, Loss: 0.0039275214076042175\n",
      "Epoch: 7/8, Batch: 680/3444, Loss: 0.00403261324390769\n",
      "Epoch: 7/8, Batch: 690/3444, Loss: 0.010351277887821198\n",
      "Epoch: 7/8, Batch: 700/3444, Loss: 0.027590494602918625\n",
      "Epoch: 7/8, Batch: 710/3444, Loss: 0.017829598858952522\n",
      "Epoch: 7/8, Batch: 720/3444, Loss: 0.019287830218672752\n",
      "Epoch: 7/8, Batch: 730/3444, Loss: 0.010012347251176834\n",
      "Epoch: 7/8, Batch: 740/3444, Loss: 0.007225675508379936\n",
      "Epoch: 7/8, Batch: 750/3444, Loss: 0.01303705945611\n",
      "Epoch: 7/8, Batch: 760/3444, Loss: 0.007793370168656111\n",
      "Epoch: 7/8, Batch: 770/3444, Loss: 0.005201852414757013\n",
      "Epoch: 7/8, Batch: 780/3444, Loss: 0.01455669105052948\n",
      "Epoch: 7/8, Batch: 790/3444, Loss: 0.012809705920517445\n",
      "Epoch: 7/8, Batch: 800/3444, Loss: 0.022354327142238617\n",
      "Epoch: 7/8, Batch: 810/3444, Loss: 0.012670806609094143\n",
      "Epoch: 7/8, Batch: 820/3444, Loss: 0.023557787761092186\n",
      "Epoch: 7/8, Batch: 830/3444, Loss: 0.013600778765976429\n",
      "Epoch: 7/8, Batch: 840/3444, Loss: 0.0037075518630445004\n",
      "Epoch: 7/8, Batch: 850/3444, Loss: 0.008917576633393764\n",
      "Epoch: 7/8, Batch: 860/3444, Loss: 0.01108944695442915\n",
      "Epoch: 7/8, Batch: 870/3444, Loss: 0.028903903439641\n",
      "Epoch: 7/8, Batch: 880/3444, Loss: 0.005840091500431299\n",
      "Epoch: 7/8, Batch: 890/3444, Loss: 0.013951592147350311\n",
      "Epoch: 7/8, Batch: 900/3444, Loss: 0.010690180584788322\n",
      "Epoch: 7/8, Batch: 910/3444, Loss: 0.014921638183295727\n",
      "Epoch: 7/8, Batch: 920/3444, Loss: 0.016527613624930382\n",
      "Epoch: 7/8, Batch: 930/3444, Loss: 0.009430318139493465\n",
      "Epoch: 7/8, Batch: 940/3444, Loss: 0.019193459302186966\n",
      "Epoch: 7/8, Batch: 950/3444, Loss: 0.02819228731095791\n",
      "Epoch: 7/8, Batch: 960/3444, Loss: 0.0075007239356637\n",
      "Epoch: 7/8, Batch: 970/3444, Loss: 0.017312096431851387\n",
      "Epoch: 7/8, Batch: 980/3444, Loss: 0.009755170904099941\n",
      "Epoch: 7/8, Batch: 990/3444, Loss: 0.01458249893039465\n",
      "Epoch: 7/8, Batch: 1000/3444, Loss: 0.006075756624341011\n",
      "Epoch: 7/8, Batch: 1010/3444, Loss: 0.01101075392216444\n",
      "Epoch: 7/8, Batch: 1020/3444, Loss: 0.01353419292718172\n",
      "Epoch: 7/8, Batch: 1030/3444, Loss: 0.03261060640215874\n",
      "Epoch: 7/8, Batch: 1040/3444, Loss: 0.011077768169343472\n",
      "Epoch: 7/8, Batch: 1050/3444, Loss: 0.005907218437641859\n",
      "Epoch: 7/8, Batch: 1060/3444, Loss: 0.008581902831792831\n",
      "Epoch: 7/8, Batch: 1070/3444, Loss: 0.00825409684330225\n",
      "Epoch: 7/8, Batch: 1080/3444, Loss: 0.012826681137084961\n",
      "Epoch: 7/8, Batch: 1090/3444, Loss: 0.012854151427745819\n",
      "Epoch: 7/8, Batch: 1100/3444, Loss: 0.014634925872087479\n",
      "Epoch: 7/8, Batch: 1110/3444, Loss: 0.009279480203986168\n",
      "Epoch: 7/8, Batch: 1120/3444, Loss: 0.008161126635968685\n",
      "Epoch: 7/8, Batch: 1130/3444, Loss: 0.009873089380562305\n",
      "Epoch: 7/8, Batch: 1140/3444, Loss: 0.021228935569524765\n",
      "Epoch: 7/8, Batch: 1150/3444, Loss: 0.01399770937860012\n",
      "Epoch: 7/8, Batch: 1160/3444, Loss: 0.009459082037210464\n",
      "Epoch: 7/8, Batch: 1170/3444, Loss: 0.014856268651783466\n",
      "Epoch: 7/8, Batch: 1180/3444, Loss: 0.006782072596251965\n",
      "Epoch: 7/8, Batch: 1190/3444, Loss: 0.010306749492883682\n",
      "Epoch: 7/8, Batch: 1200/3444, Loss: 0.031057942658662796\n",
      "Epoch: 7/8, Batch: 1210/3444, Loss: 0.0290814395993948\n",
      "Epoch: 7/8, Batch: 1220/3444, Loss: 0.015515138395130634\n",
      "Epoch: 7/8, Batch: 1230/3444, Loss: 0.02001374214887619\n",
      "Epoch: 7/8, Batch: 1240/3444, Loss: 0.017130760475993156\n",
      "Epoch: 7/8, Batch: 1250/3444, Loss: 0.022343970835208893\n",
      "Epoch: 7/8, Batch: 1260/3444, Loss: 0.018555467948317528\n",
      "Epoch: 7/8, Batch: 1270/3444, Loss: 0.007750759832561016\n",
      "Epoch: 7/8, Batch: 1280/3444, Loss: 0.008979282341897488\n",
      "Epoch: 7/8, Batch: 1290/3444, Loss: 0.04608399420976639\n",
      "Epoch: 7/8, Batch: 1300/3444, Loss: 0.010885498486459255\n",
      "Epoch: 7/8, Batch: 1310/3444, Loss: 0.03210199251770973\n",
      "Epoch: 7/8, Batch: 1320/3444, Loss: 0.025768104940652847\n",
      "Epoch: 7/8, Batch: 1330/3444, Loss: 0.04732381924986839\n",
      "Epoch: 7/8, Batch: 1340/3444, Loss: 0.016698496416211128\n",
      "Epoch: 7/8, Batch: 1350/3444, Loss: 0.014782740734517574\n",
      "Epoch: 7/8, Batch: 1360/3444, Loss: 0.006439358927309513\n",
      "Epoch: 7/8, Batch: 1370/3444, Loss: 0.02168223075568676\n",
      "Epoch: 7/8, Batch: 1380/3444, Loss: 0.021297279745340347\n",
      "Epoch: 7/8, Batch: 1390/3444, Loss: 0.015966715291142464\n",
      "Epoch: 7/8, Batch: 1400/3444, Loss: 0.008097702637314796\n",
      "Epoch: 7/8, Batch: 1410/3444, Loss: 0.007107453420758247\n",
      "Epoch: 7/8, Batch: 1420/3444, Loss: 0.01073756255209446\n",
      "Epoch: 7/8, Batch: 1430/3444, Loss: 0.011313444003462791\n",
      "Epoch: 7/8, Batch: 1440/3444, Loss: 0.03275654837489128\n",
      "Epoch: 7/8, Batch: 1450/3444, Loss: 0.012610518373548985\n",
      "Epoch: 7/8, Batch: 1460/3444, Loss: 0.007425157353281975\n",
      "Epoch: 7/8, Batch: 1470/3444, Loss: 0.02635391429066658\n",
      "Epoch: 7/8, Batch: 1480/3444, Loss: 0.026347791776061058\n",
      "Epoch: 7/8, Batch: 1490/3444, Loss: 0.01097305677831173\n",
      "Epoch: 7/8, Batch: 1500/3444, Loss: 0.012430724687874317\n",
      "Epoch: 7/8, Batch: 1510/3444, Loss: 0.007734023500233889\n",
      "Epoch: 7/8, Batch: 1520/3444, Loss: 0.01344650611281395\n",
      "Epoch: 7/8, Batch: 1530/3444, Loss: 0.013856424950063229\n",
      "Epoch: 7/8, Batch: 1540/3444, Loss: 0.009848556481301785\n",
      "Epoch: 7/8, Batch: 1550/3444, Loss: 0.01172907929867506\n",
      "Epoch: 7/8, Batch: 1560/3444, Loss: 0.009831876493990421\n",
      "Epoch: 7/8, Batch: 1570/3444, Loss: 0.009137611836194992\n",
      "Epoch: 7/8, Batch: 1580/3444, Loss: 0.014449452050030231\n",
      "Epoch: 7/8, Batch: 1590/3444, Loss: 0.013795091770589352\n",
      "Epoch: 7/8, Batch: 1600/3444, Loss: 0.01213134080171585\n",
      "Epoch: 7/8, Batch: 1610/3444, Loss: 0.020203234627842903\n",
      "Epoch: 7/8, Batch: 1620/3444, Loss: 0.009260316379368305\n",
      "Epoch: 7/8, Batch: 1630/3444, Loss: 0.012539560906589031\n",
      "Epoch: 7/8, Batch: 1640/3444, Loss: 0.013496003113687038\n",
      "Epoch: 7/8, Batch: 1650/3444, Loss: 0.028730204328894615\n",
      "Epoch: 7/8, Batch: 1660/3444, Loss: 0.0038717191200703382\n",
      "Epoch: 7/8, Batch: 1670/3444, Loss: 0.010011622682213783\n",
      "Epoch: 7/8, Batch: 1680/3444, Loss: 0.010895018465816975\n",
      "Epoch: 7/8, Batch: 1690/3444, Loss: 0.005094665102660656\n",
      "Epoch: 7/8, Batch: 1700/3444, Loss: 0.005516434088349342\n",
      "Epoch: 7/8, Batch: 1710/3444, Loss: 0.0057988655753433704\n",
      "Epoch: 7/8, Batch: 1720/3444, Loss: 0.006875383201986551\n",
      "Epoch: 7/8, Batch: 1730/3444, Loss: 0.013066943734884262\n",
      "Epoch: 7/8, Batch: 1740/3444, Loss: 0.034895364195108414\n",
      "Epoch: 7/8, Batch: 1750/3444, Loss: 0.010967857204377651\n",
      "Epoch: 7/8, Batch: 1760/3444, Loss: 0.009990224614739418\n",
      "Epoch: 7/8, Batch: 1770/3444, Loss: 0.013602562248706818\n",
      "Epoch: 7/8, Batch: 1780/3444, Loss: 0.025771675631403923\n",
      "Epoch: 7/8, Batch: 1790/3444, Loss: 0.007013625930994749\n",
      "Epoch: 7/8, Batch: 1800/3444, Loss: 0.04179030656814575\n",
      "Epoch: 7/8, Batch: 1810/3444, Loss: 0.010524882934987545\n",
      "Epoch: 7/8, Batch: 1820/3444, Loss: 0.013624836690723896\n",
      "Epoch: 7/8, Batch: 1830/3444, Loss: 0.006043091882020235\n",
      "Epoch: 7/8, Batch: 1840/3444, Loss: 0.008459452539682388\n",
      "Epoch: 7/8, Batch: 1850/3444, Loss: 0.013995429500937462\n",
      "Epoch: 7/8, Batch: 1860/3444, Loss: 0.04033268615603447\n",
      "Epoch: 7/8, Batch: 1870/3444, Loss: 0.010812239721417427\n",
      "Epoch: 7/8, Batch: 1880/3444, Loss: 0.05038246512413025\n",
      "Epoch: 7/8, Batch: 1890/3444, Loss: 0.02305011823773384\n",
      "Epoch: 7/8, Batch: 1900/3444, Loss: 0.0064301262609660625\n",
      "Epoch: 7/8, Batch: 1910/3444, Loss: 0.009152146987617016\n",
      "Epoch: 7/8, Batch: 1920/3444, Loss: 0.009867356158792973\n",
      "Epoch: 7/8, Batch: 1930/3444, Loss: 0.01191193051636219\n",
      "Epoch: 7/8, Batch: 1940/3444, Loss: 0.023285290226340294\n",
      "Epoch: 7/8, Batch: 1950/3444, Loss: 0.010789494961500168\n",
      "Epoch: 7/8, Batch: 1960/3444, Loss: 0.00881156325340271\n",
      "Epoch: 7/8, Batch: 1970/3444, Loss: 0.025088198482990265\n",
      "Epoch: 7/8, Batch: 1980/3444, Loss: 0.017979763448238373\n",
      "Epoch: 7/8, Batch: 1990/3444, Loss: 0.02033422142267227\n",
      "Epoch: 7/8, Batch: 2000/3444, Loss: 0.03929126635193825\n",
      "Epoch: 7/8, Batch: 2010/3444, Loss: 0.02456078864634037\n",
      "Epoch: 7/8, Batch: 2020/3444, Loss: 0.008575388230383396\n",
      "Epoch: 7/8, Batch: 2030/3444, Loss: 0.008400609716773033\n",
      "Epoch: 7/8, Batch: 2040/3444, Loss: 0.009693826548755169\n",
      "Epoch: 7/8, Batch: 2050/3444, Loss: 0.006391393952071667\n",
      "Epoch: 7/8, Batch: 2060/3444, Loss: 0.005962654948234558\n",
      "Epoch: 7/8, Batch: 2070/3444, Loss: 0.005806014873087406\n",
      "Epoch: 7/8, Batch: 2080/3444, Loss: 0.014244923368096352\n",
      "Epoch: 7/8, Batch: 2090/3444, Loss: 0.023994706571102142\n",
      "Epoch: 7/8, Batch: 2100/3444, Loss: 0.043436434119939804\n",
      "Epoch: 7/8, Batch: 2110/3444, Loss: 0.01281664241105318\n",
      "Epoch: 7/8, Batch: 2120/3444, Loss: 0.016067372635006905\n",
      "Epoch: 7/8, Batch: 2130/3444, Loss: 0.031090781092643738\n",
      "Epoch: 7/8, Batch: 2140/3444, Loss: 0.009668777696788311\n",
      "Epoch: 7/8, Batch: 2150/3444, Loss: 0.007944103330373764\n",
      "Epoch: 7/8, Batch: 2160/3444, Loss: 0.008872057311236858\n",
      "Epoch: 7/8, Batch: 2170/3444, Loss: 0.015311900526285172\n",
      "Epoch: 7/8, Batch: 2180/3444, Loss: 0.017361795529723167\n",
      "Epoch: 7/8, Batch: 2190/3444, Loss: 0.006146034225821495\n",
      "Epoch: 7/8, Batch: 2200/3444, Loss: 0.0069917943328619\n",
      "Epoch: 7/8, Batch: 2210/3444, Loss: 0.012605229392647743\n",
      "Epoch: 7/8, Batch: 2220/3444, Loss: 0.014274142682552338\n",
      "Epoch: 7/8, Batch: 2230/3444, Loss: 0.010059111751616001\n",
      "Epoch: 7/8, Batch: 2240/3444, Loss: 0.01584094949066639\n",
      "Epoch: 7/8, Batch: 2250/3444, Loss: 0.013698739930987358\n",
      "Epoch: 7/8, Batch: 2260/3444, Loss: 0.01133060734719038\n",
      "Epoch: 7/8, Batch: 2270/3444, Loss: 0.018029890954494476\n",
      "Epoch: 7/8, Batch: 2280/3444, Loss: 0.00948682427406311\n",
      "Epoch: 7/8, Batch: 2290/3444, Loss: 0.029679622501134872\n",
      "Epoch: 7/8, Batch: 2300/3444, Loss: 0.013834579847753048\n",
      "Epoch: 7/8, Batch: 2310/3444, Loss: 0.002922732150182128\n",
      "Epoch: 7/8, Batch: 2320/3444, Loss: 0.009065568447113037\n",
      "Epoch: 7/8, Batch: 2330/3444, Loss: 0.01627715677022934\n",
      "Epoch: 7/8, Batch: 2340/3444, Loss: 0.022955724969506264\n",
      "Epoch: 7/8, Batch: 2350/3444, Loss: 0.020005645230412483\n",
      "Epoch: 7/8, Batch: 2360/3444, Loss: 0.014885279349982738\n",
      "Epoch: 7/8, Batch: 2370/3444, Loss: 0.00665781507268548\n",
      "Epoch: 7/8, Batch: 2380/3444, Loss: 0.017279373481869698\n",
      "Epoch: 7/8, Batch: 2390/3444, Loss: 0.014566147699952126\n",
      "Epoch: 7/8, Batch: 2400/3444, Loss: 0.011150442995131016\n",
      "Epoch: 7/8, Batch: 2410/3444, Loss: 0.013208682648837566\n",
      "Epoch: 7/8, Batch: 2420/3444, Loss: 0.00925647746771574\n",
      "Epoch: 7/8, Batch: 2430/3444, Loss: 0.015251656994223595\n",
      "Epoch: 7/8, Batch: 2440/3444, Loss: 0.008697082288563251\n",
      "Epoch: 7/8, Batch: 2450/3444, Loss: 0.019050126895308495\n",
      "Epoch: 7/8, Batch: 2460/3444, Loss: 0.008529388345777988\n",
      "Epoch: 7/8, Batch: 2470/3444, Loss: 0.004062287509441376\n",
      "Epoch: 7/8, Batch: 2480/3444, Loss: 0.04084673523902893\n",
      "Epoch: 7/8, Batch: 2490/3444, Loss: 0.013200243934988976\n",
      "Epoch: 7/8, Batch: 2500/3444, Loss: 0.006187967956066132\n",
      "Epoch: 7/8, Batch: 2510/3444, Loss: 0.008175847120583057\n",
      "Epoch: 7/8, Batch: 2520/3444, Loss: 0.010694283992052078\n",
      "Epoch: 7/8, Batch: 2530/3444, Loss: 0.016655104234814644\n",
      "Epoch: 7/8, Batch: 2540/3444, Loss: 0.008609728887677193\n",
      "Epoch: 7/8, Batch: 2550/3444, Loss: 0.007706472650170326\n",
      "Epoch: 7/8, Batch: 2560/3444, Loss: 0.021332809701561928\n",
      "Epoch: 7/8, Batch: 2570/3444, Loss: 0.02168308012187481\n",
      "Epoch: 7/8, Batch: 2580/3444, Loss: 0.010045599192380905\n",
      "Epoch: 7/8, Batch: 2590/3444, Loss: 0.013622201047837734\n",
      "Epoch: 7/8, Batch: 2600/3444, Loss: 0.0184733048081398\n",
      "Epoch: 7/8, Batch: 2610/3444, Loss: 0.017711548134684563\n",
      "Epoch: 7/8, Batch: 2620/3444, Loss: 0.01376552227884531\n",
      "Epoch: 7/8, Batch: 2630/3444, Loss: 0.02717328630387783\n",
      "Epoch: 7/8, Batch: 2640/3444, Loss: 0.014561295509338379\n",
      "Epoch: 7/8, Batch: 2650/3444, Loss: 0.023547537624835968\n",
      "Epoch: 7/8, Batch: 2660/3444, Loss: 0.005568412132561207\n",
      "Epoch: 7/8, Batch: 2670/3444, Loss: 0.016097279265522957\n",
      "Epoch: 7/8, Batch: 2680/3444, Loss: 0.025867903605103493\n",
      "Epoch: 7/8, Batch: 2690/3444, Loss: 0.006367413327097893\n",
      "Epoch: 7/8, Batch: 2700/3444, Loss: 0.028696348890662193\n",
      "Epoch: 7/8, Batch: 2710/3444, Loss: 0.015060062520205975\n",
      "Epoch: 7/8, Batch: 2720/3444, Loss: 0.011578855104744434\n",
      "Epoch: 7/8, Batch: 2730/3444, Loss: 0.010671327821910381\n",
      "Epoch: 7/8, Batch: 2740/3444, Loss: 0.0281368438154459\n",
      "Epoch: 7/8, Batch: 2750/3444, Loss: 0.01239194069057703\n",
      "Epoch: 7/8, Batch: 2760/3444, Loss: 0.009850617498159409\n",
      "Epoch: 7/8, Batch: 2770/3444, Loss: 0.009291515685617924\n",
      "Epoch: 7/8, Batch: 2780/3444, Loss: 0.008934389799833298\n",
      "Epoch: 7/8, Batch: 2790/3444, Loss: 0.01701255515217781\n",
      "Epoch: 7/8, Batch: 2800/3444, Loss: 0.004573836922645569\n",
      "Epoch: 7/8, Batch: 2810/3444, Loss: 0.011026688851416111\n",
      "Epoch: 7/8, Batch: 2820/3444, Loss: 0.019942913204431534\n",
      "Epoch: 7/8, Batch: 2830/3444, Loss: 0.01770307496190071\n",
      "Epoch: 7/8, Batch: 2840/3444, Loss: 0.010560153983533382\n",
      "Epoch: 7/8, Batch: 2850/3444, Loss: 0.017489813268184662\n",
      "Epoch: 7/8, Batch: 2860/3444, Loss: 0.010258790105581284\n",
      "Epoch: 7/8, Batch: 2870/3444, Loss: 0.011008811183273792\n",
      "Epoch: 7/8, Batch: 2880/3444, Loss: 0.005760041065514088\n",
      "Epoch: 7/8, Batch: 2890/3444, Loss: 0.0112338587641716\n",
      "Epoch: 7/8, Batch: 2900/3444, Loss: 0.009904029779136181\n",
      "Epoch: 7/8, Batch: 2910/3444, Loss: 0.01534937508404255\n",
      "Epoch: 7/8, Batch: 2920/3444, Loss: 0.022226227447390556\n",
      "Epoch: 7/8, Batch: 2930/3444, Loss: 0.007585874292999506\n",
      "Epoch: 7/8, Batch: 2940/3444, Loss: 0.019901065155863762\n",
      "Epoch: 7/8, Batch: 2950/3444, Loss: 0.014345218427479267\n",
      "Epoch: 7/8, Batch: 2960/3444, Loss: 0.015512673184275627\n",
      "Epoch: 7/8, Batch: 2970/3444, Loss: 0.02690095826983452\n",
      "Epoch: 7/8, Batch: 2980/3444, Loss: 0.009382006712257862\n",
      "Epoch: 7/8, Batch: 2990/3444, Loss: 0.01396216545253992\n",
      "Epoch: 7/8, Batch: 3000/3444, Loss: 0.02777652069926262\n",
      "Epoch: 7/8, Batch: 3010/3444, Loss: 0.009565681219100952\n",
      "Epoch: 7/8, Batch: 3020/3444, Loss: 0.033899884670972824\n",
      "Epoch: 7/8, Batch: 3030/3444, Loss: 0.030707158148288727\n",
      "Epoch: 7/8, Batch: 3040/3444, Loss: 0.015454267151653767\n",
      "Epoch: 7/8, Batch: 3050/3444, Loss: 0.007463838439434767\n",
      "Epoch: 7/8, Batch: 3060/3444, Loss: 0.00891860481351614\n",
      "Epoch: 7/8, Batch: 3070/3444, Loss: 0.01781713031232357\n",
      "Epoch: 7/8, Batch: 3080/3444, Loss: 0.012885212898254395\n",
      "Epoch: 7/8, Batch: 3090/3444, Loss: 0.012177242897450924\n",
      "Epoch: 7/8, Batch: 3100/3444, Loss: 0.012930401600897312\n",
      "Epoch: 7/8, Batch: 3110/3444, Loss: 0.008681809529662132\n",
      "Epoch: 7/8, Batch: 3120/3444, Loss: 0.017827153205871582\n",
      "Epoch: 7/8, Batch: 3130/3444, Loss: 0.016153080388903618\n",
      "Epoch: 7/8, Batch: 3140/3444, Loss: 0.006061669904738665\n",
      "Epoch: 7/8, Batch: 3150/3444, Loss: 0.009749706834554672\n",
      "Epoch: 7/8, Batch: 3160/3444, Loss: 0.01444950606673956\n",
      "Epoch: 7/8, Batch: 3170/3444, Loss: 0.09607921540737152\n",
      "Epoch: 7/8, Batch: 3180/3444, Loss: 0.011646526865661144\n",
      "Epoch: 7/8, Batch: 3190/3444, Loss: 0.019035596400499344\n",
      "Epoch: 7/8, Batch: 3200/3444, Loss: 0.024040378630161285\n",
      "Epoch: 7/8, Batch: 3210/3444, Loss: 0.011589054949581623\n",
      "Epoch: 7/8, Batch: 3220/3444, Loss: 0.005208828020840883\n",
      "Epoch: 7/8, Batch: 3230/3444, Loss: 0.010585707612335682\n",
      "Epoch: 7/8, Batch: 3240/3444, Loss: 0.014228926040232182\n",
      "Epoch: 7/8, Batch: 3250/3444, Loss: 0.012070439755916595\n",
      "Epoch: 7/8, Batch: 3260/3444, Loss: 0.030026625841856003\n",
      "Epoch: 7/8, Batch: 3270/3444, Loss: 0.01441184338182211\n",
      "Epoch: 7/8, Batch: 3280/3444, Loss: 0.018953433260321617\n",
      "Epoch: 7/8, Batch: 3290/3444, Loss: 0.0071545615792274475\n",
      "Epoch: 7/8, Batch: 3300/3444, Loss: 0.01062853541225195\n",
      "Epoch: 7/8, Batch: 3310/3444, Loss: 0.011392985470592976\n",
      "Epoch: 7/8, Batch: 3320/3444, Loss: 0.006876340135931969\n",
      "Epoch: 7/8, Batch: 3330/3444, Loss: 0.012263786047697067\n",
      "Epoch: 7/8, Batch: 3340/3444, Loss: 0.02260586805641651\n",
      "Epoch: 7/8, Batch: 3350/3444, Loss: 0.013101345859467983\n",
      "Epoch: 7/8, Batch: 3360/3444, Loss: 0.01409817859530449\n",
      "Epoch: 7/8, Batch: 3370/3444, Loss: 0.021930938586592674\n",
      "Epoch: 7/8, Batch: 3380/3444, Loss: 0.012539937160909176\n",
      "Epoch: 7/8, Batch: 3390/3444, Loss: 0.016994625329971313\n",
      "Epoch: 7/8, Batch: 3400/3444, Loss: 0.00795001070946455\n",
      "Epoch: 7/8, Batch: 3410/3444, Loss: 0.023177381604909897\n",
      "Epoch: 7/8, Batch: 3420/3444, Loss: 0.014126178808510303\n",
      "Epoch: 7/8, Batch: 3430/3444, Loss: 0.024338217452168465\n",
      "Epoch: 7/8, Batch: 3440/3444, Loss: 0.016078513115644455\n",
      "Epoch 00008: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch: 7/8, Val Loss: 0.03365027459292877\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "mlp = MLP()\n",
    "mlp.to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.25, verbose=True)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mlp.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output = mlp(inp.float())\n",
    "        # Reshape output from [batch_size, 120] to [batch_size, 60, 60]\n",
    "        output = output.view(output.size(0), -1, 2)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    mlp.train(False)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output = mlp(inp.float())\n",
    "            output = output.view(output.size(0), -1, 2)\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch: {epoch}/{num_epochs}, Val Loss: {val_loss}\")\n",
    "            \n",
    "torch.save(mlp.state_dict(), \"models/austin_mlp.pt\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae6203",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "de312802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=256, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mlp.load_state_dict(torch.load(\"models/austin_mlp.pt\", map_location=device))\n",
    "mlp.to(device)\n",
    "mlp.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac0370",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a571d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        # if i == 0:\n",
    "        #     print(x[0][40:-1], output[0][40:-1])\n",
    "        elem = output[:, -1, :]\n",
    "        x = elem.unsqueeze(1)\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9c395",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15b2920a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(original_inp[\u001b[39m0\u001b[39m,:,\u001b[39m0\u001b[39m], original_inp[\u001b[39m0\u001b[39m,:,\u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, s\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(output[\u001b[39m0\u001b[39m,:,\u001b[39m0\u001b[39m], output[\u001b[39m0\u001b[39m,:,\u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, s\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39;49msavefig(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutputs/austin_mlp_prediction_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\pyplot.py:959\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/pyplot.py?line=956'>957</a>\u001b[0m fig \u001b[39m=\u001b[39m gcf()\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/pyplot.py?line=957'>958</a>\u001b[0m res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39msavefig(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/pyplot.py?line=958'>959</a>\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()   \u001b[39m# need this if 'transparent=True' to reset colors\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/pyplot.py?line=959'>960</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\backend_bases.py:2060\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backend_bases.py?line=2057'>2058</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backend_bases.py?line=2058'>2059</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backend_bases.py?line=2059'>2060</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdraw(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=431'>432</a>\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=432'>433</a>\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=433'>434</a>\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=434'>435</a>\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=435'>436</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=436'>437</a>\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=437'>438</a>\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=438'>439</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=70'>71</a>\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=72'>73</a>\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=73'>74</a>\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=74'>75</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2806'>2807</a>\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2808'>2809</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2809'>2810</a>\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2810'>2811</a>\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2812'>2813</a>\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/figure.py?line=2813'>2814</a>\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=130'>131</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=131'>132</a>\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=133'>134</a>\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=134'>135</a>\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\axes\\_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3078'>3079</a>\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3079'>3080</a>\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3081'>3082</a>\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3082'>3083</a>\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3084'>3085</a>\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axes/_base.py?line=3085'>3086</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=130'>131</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=131'>132</a>\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=133'>134</a>\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/image.py?line=134'>135</a>\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\axis.py:1163\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1158'>1159</a>\u001b[0m ticklabelBoxes, ticklabelBoxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1159'>1160</a>\u001b[0m                                                         renderer)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1161'>1162</a>\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1162'>1163</a>\u001b[0m     tick\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1164'>1165</a>\u001b[0m \u001b[39m# scale up the axis label box to also find the neighbors, not\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1165'>1166</a>\u001b[0m \u001b[39m# just the tick labels that actually overlap note we need a\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1166'>1167</a>\u001b[0m \u001b[39m# *copy* of the axis label box because we don't want to scale\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1167'>1168</a>\u001b[0m \u001b[39m# the actual bbox\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=1169'>1170</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_label_position(renderer)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\axis.py:299\u001b[0m, in \u001b[0;36mTick.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=295'>296</a>\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=296'>297</a>\u001b[0m \u001b[39mfor\u001b[39;00m artist \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick1line, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick2line,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=297'>298</a>\u001b[0m                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel2]:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=298'>299</a>\u001b[0m     artist\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=299'>300</a>\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/axis.py?line=300'>301</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\text.py:733\u001b[0m, in \u001b[0;36mText.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=728'>729</a>\u001b[0m             textrenderer\u001b[39m.\u001b[39mdraw_tex(gc, x, y, clean_line,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=729'>730</a>\u001b[0m                                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fontproperties, angle,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=730'>731</a>\u001b[0m                                   mtext\u001b[39m=\u001b[39mmtext)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=731'>732</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=732'>733</a>\u001b[0m             textrenderer\u001b[39m.\u001b[39;49mdraw_text(gc, x, y, clean_line,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=733'>734</a>\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties, angle,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=734'>735</a>\u001b[0m                                    ismath\u001b[39m=\u001b[39;49mismath, mtext\u001b[39m=\u001b[39;49mmtext)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=736'>737</a>\u001b[0m gc\u001b[39m.\u001b[39mrestore()\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/text.py?line=737'>738</a>\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:237\u001b[0m, in \u001b[0;36mRendererAgg.draw_text\u001b[1;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=233'>234</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=234'>235</a>\u001b[0m \u001b[39m# We pass '0' for angle here, since it will be rotated (in raster\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=235'>236</a>\u001b[0m \u001b[39m# space) in the following call to draw_text_image).\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=236'>237</a>\u001b[0m font\u001b[39m.\u001b[39;49mset_text(s, \u001b[39m0\u001b[39;49m, flags\u001b[39m=\u001b[39;49mflags)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=237'>238</a>\u001b[0m font\u001b[39m.\u001b[39mdraw_glyphs_to_bitmap(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=238'>239</a>\u001b[0m     antialiased\u001b[39m=\u001b[39mmpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mtext.antialiased\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/matplotlib/backends/backend_agg.py?line=239'>240</a>\u001b[0m d \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_descent() \u001b[39m/\u001b[39m \u001b[39m64.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, inp in enumerate(test_loader):\n",
    "    original_inp = inp\n",
    "    inp = inp.to(device)\n",
    "    inp = (inp - austin_mean) / austin_std\n",
    "    inp = inp.float()\n",
    "    output = mlp(inp)\n",
    "    output = output.view(output.size(0), -1, 2)\n",
    "    output = output.detach().cpu().numpy()\n",
    "\n",
    "    output = output * austin_std + austin_mean     \n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.scatter(original_inp[0,:,0], original_inp[0,:,1], c='b', s=20)\n",
    "    plt.scatter(output[0,:,0], output[0,:,1], c='r', s=20)\n",
    "    plt.savefig(f\"outputs/austin_mlp_prediction_{i}.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
