{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9791bc6e",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8cf13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1d132",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6df1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11993, 50, 2) (11993, 60, 2)\n",
      "(1686, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\"):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        # trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        # trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        # trajectories = trajectories.astype(np.float32)\n",
    "            \n",
    "        # inputs = []\n",
    "        # outputs = []\n",
    "        # for trajectory in trajectories:\n",
    "        #     inputs.append(trajectory[0:109])\n",
    "        #     outputs.append(trajectory[1:110])\n",
    "                \n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "curr_city = cities[5]\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=curr_city, split=\"train\")\n",
    "test_dataset = ArgoverseDataset(city=curr_city, split=\"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbacf98",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13a6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4e2ea",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d040b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='r', s=20)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='b', s=20)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852f474",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855d92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.output_size = 60\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=256, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(256, 128)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(128, self.output_size*2)\n",
    "\n",
    "    def forward(self, x, steps=60):\n",
    "        input_offset =  x[:,0,:].unsqueeze(1).repeat(1,x.size(1),1)\n",
    "        output_offset = x[:,-1,:].unsqueeze(1).repeat(1,self.output_size,1)\n",
    "        x = x - input_offset\n",
    "        x, (h, c) = self.lstm(x)  \n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        # Take last element of the sequence\n",
    "        x = x[:,-1,:]\n",
    "        x = x.view(-1, self.output_size, 2)\n",
    "        x = x + output_offset\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9639d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609e6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Batch: 10/2399, Loss: 18.077434539794922\n",
      "Epoch: 1/200, Batch: 20/2399, Loss: 17.434528350830078\n",
      "Epoch: 1/200, Batch: 30/2399, Loss: 16.906457901000977\n",
      "Epoch: 1/200, Batch: 40/2399, Loss: 16.232725143432617\n",
      "Epoch: 1/200, Batch: 50/2399, Loss: 1.9270943403244019\n",
      "Epoch: 1/200, Batch: 60/2399, Loss: 15.173589706420898\n",
      "Epoch: 1/200, Batch: 70/2399, Loss: 21.04612159729004\n",
      "Epoch: 1/200, Batch: 80/2399, Loss: 12.745139122009277\n",
      "Epoch: 1/200, Batch: 90/2399, Loss: 14.944354057312012\n",
      "Epoch: 1/200, Batch: 100/2399, Loss: 7.2426676750183105\n",
      "Epoch: 1/200, Batch: 110/2399, Loss: 12.082841873168945\n",
      "Epoch: 1/200, Batch: 120/2399, Loss: 17.472129821777344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.25, verbose=True)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1, 1):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output = lstm(inp.float())\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output = lstm(inp.float())\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch: {epoch}/{num_epochs}, Val Loss: {val_loss}\")\n",
    "\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "torch.save(lstm.state_dict(), f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e9c24",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(f, map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c1a47",
   "metadata": {},
   "source": [
    "## Validation Data Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_outputs = []\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, label = sample_batch\n",
    "    inp = inp.to(device)\n",
    "    output = lstm(inp.float())\n",
    "    validation_outputs.append((inp.cpu().numpy(), output.detach().cpu().numpy(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation results     \n",
    "data = validation_outputs[0]\n",
    "inp, output, label = data\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "plt.plot(label[0,:,0], label[0,:,1], c='b', label=\"Ground Truth\")\n",
    "plt.plot(output[0,:,0], output[0,:,1], c='g', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21917c88",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbb2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m austin_mean) \u001b[39m/\u001b[39m austin_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m austin_std \u001b[39m+\u001b[39m austin_mean     \n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=3'>4</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=5'>6</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=6'>7</a>\u001b[0m     \u001b[39m# if i == 0:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=7'>8</a>\u001b[0m     \u001b[39m#     print(x[0][40:-1], output[0][40:-1])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = f\"{curr_city}_trajectory.csv\"\n",
    "\n",
    "with open(f, \"w\") as f:\n",
    "    for i, inp in enumerate(test_loader):\n",
    "        inp = inp.to(device)\n",
    "        inp = inp.float()\n",
    "        output = lstm(inp)\n",
    "\n",
    "        output = np.array(output)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        inp = inp.squeeze().detach().cpu().numpy()\n",
    "        output = output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            plt.figure(figsize=(15, 3))\n",
    "            plt.scatter(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "            plt.scatter(output[:,0], output[:,1], c='g', label=\"Prediction\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{curr_city}_trajectory_{i}.png\")\n",
    "\n",
    "        f.write(f\"{i}_{curr_city}\")\n",
    "        for pos in output:\n",
    "            f.write(f\",{pos[0]},{pos[1]}\")\n",
    "        f.write(\"\\n\")\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(test_loader)}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
