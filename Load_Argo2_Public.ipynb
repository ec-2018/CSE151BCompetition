{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43041, 50, 2) (43041, 60, 2)\n",
      "(29843, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        if normalized:\n",
    "            mean = np.mean(trajectories, axis=0)\n",
    "            std = np.std(trajectories, axis=0)\n",
    "            trajectories = (trajectories - mean) / std\n",
    "\n",
    "        inputs = trajectories[:, :50, :]\n",
    "        outputs = trajectories[:, 50:, :]\n",
    "        \n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=\"austin\", split=\"train\")\n",
    "# train_austin = ArgoverseDataset(city = \"austin\", split = \"train\")\n",
    "# train_miami = ArgoverseDataset(city = \"miami\", split = \"train\")\n",
    "# train_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"train\")\n",
    "# train_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"train\")\n",
    "# train_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"train\")\n",
    "# train_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"train\")\n",
    "\n",
    "data_mean, data_std = train_dataset.get_mean_std()[0][0]\n",
    "# austin_mean, austin_std = train_austin.get_mean_std()[0][0]\n",
    "# miami_mean, miami_std = train_miami.get_mean_std()[0][0]\n",
    "# palo_alto_mean, palo_alto_std = train_palo_alto.get_mean_std()[0][0]\n",
    "# pittsburgh_mean, pittsburgh_std = train_pittsburgh.get_mean_std()[0][0]\n",
    "# dearborn_mean, dearborn_std = train_dearborn.get_mean_std()[0][0]\n",
    "# washington_dc_mean, washington_dc_std = train_washington_dc.get_mean_std()[0][0]\n",
    "\n",
    "test_dataset = ArgoverseDataset(city=\"all\", split=\"test\")\n",
    "# test_austin = ArgoverseDataset(city = \"austin\", split = \"test\")\n",
    "# test_miami = ArgoverseDataset(city = \"miami\", split = \"test\")\n",
    "# test_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"test\")\n",
    "# test_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"test\")\n",
    "# test_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"test\")\n",
    "# test_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "# train_austin, val_austin = torch.utils.data.random_split(train_austin, [len(train_austin) - len(train_austin)//5, len(train_austin)//5])\n",
    "# train_miami, val_miami = torch.utils.data.random_split(train_miami, [len(train_miami) - len(train_miami)//5, len(train_miami)//5])\n",
    "# train_palo_alto, val_palo_alto = torch.utils.data.random_split(train_palo_alto, [len(train_palo_alto) - len(train_palo_alto)//5, len(train_palo_alto)//5])\n",
    "# train_pittsburgh, val_pittsburgh = torch.utils.data.random_split(train_pittsburgh, [len(train_pittsburgh) - len(train_pittsburgh)//5, len(train_pittsburgh)//5])\n",
    "# train_dearborn, val_dearborn = torch.utils.data.random_split(train_dearborn, [len(train_dearborn) - len(train_dearborn)//5, len(train_dearborn)//5])\n",
    "# train_washington_dc, val_washington_dc = torch.utils.data.random_split(train_washington_dc, [len(train_washington_dc) - len(train_washington_dc)//5, len(train_washington_dc)//5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 10  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='blue', s=10)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='orange', s=10)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a53b5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56c6a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=512, num_layers=3, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(512, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(256, 2)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, h, c\n",
    "\n",
    "    def predict(self, x, h=None, c=None):\n",
    "        output, h, c = self.forward(x, h, c)\n",
    "        output = output[-1]\n",
    "        output = output.cpu().detach().numpy()\n",
    "            \n",
    "        return output, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf38ed7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e605e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            output = output[:, -1, :]\n",
    "            loss = loss_fn(output, label)\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(val_loader)}, Loss: {loss.item()}\")\n",
    "            break\n",
    "\n",
    "torch.save(lstm.state_dict(), \"models/palo_alto_model.pt\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae6203",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de312802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=3, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(\"models/palo_alto_model.pt\", map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac0370",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    x = x.to(device)\n",
    "    x = x.float()\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        elem = output[:, -1, :]\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "        x = output\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9c395",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2920a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=2'>3</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m palo_alto_mean) \u001b[39m/\u001b[39m palo_alto_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=3'>4</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000020?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m palo_alto_std \u001b[39m+\u001b[39m palo_alto_mean\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=5'>6</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=9'>10</a>\u001b[0m     elem \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=19'>20</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, inp in enumerate(test_loader):\n",
    "    inp = inp.to(device)\n",
    "    inp = (inp - palo_alto_mean) / palo_alto_std\n",
    "    inp = inp.float()\n",
    "    output = sample(inp, lstm)\n",
    "\n",
    "    output = np.array(output)\n",
    "    output = output * palo_alto_std + palo_alto_mean\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(output[:, 0], output[:, 1], c='r')\n",
    "    plt.savefig(f\"outputs/palo_alto_prediction_{i}.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e29fbf03db329727dad78c9f26053fabfa9b2ead348090a9805a8744123bd7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
