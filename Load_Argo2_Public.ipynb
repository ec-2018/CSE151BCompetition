{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9791bc6e",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8cf13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1d132",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6df1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14420, 50, 2) (14420, 50, 2)\n",
      "(1686, 50, 2) ()\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_data(city, split, type):\n",
    "    f = ROOT_PATH + split + \"/\" + city + \"_\" + type\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    data = np.asarray(data)\n",
    "    return data\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\"):\n",
    "    if city != \"all\":\n",
    "        inputs = get_data(city, split, \"inputs\")\n",
    "    else:\n",
    "        inputs = []\n",
    "        for place in cities:\n",
    "            inputs.append(get_data(place, split, \"inputs\"))\n",
    "        inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        if city != \"all\":\n",
    "            outputs = get_data(city, split, \"outputs\")\n",
    "        else:\n",
    "            outputs = []\n",
    "            for place in cities:\n",
    "                outputs.append(get_data(place, split, \"outputs\"))\n",
    "            outputs = np.concatenate(outputs, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        mean = np.mean(trajectories, axis=0)[0]\n",
    "        std = np.std(trajectories, axis=0)[0]\n",
    "        trajectories = (trajectories - mean) / std \n",
    "            \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for trajectory in trajectories:\n",
    "            rand_start = np.random.randint(0, 25)\n",
    "            for i in range(rand_start, trajectory.shape[0] - 55, 50):\n",
    "                inputs.append(trajectory[i:i+50])\n",
    "                outputs.append(trajectory[i+1:i+51])\n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city, self.split = city, split\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "curr_city = cities[5]\n",
    "\n",
    "# intialize each dataset\n",
    "train_dataset = ArgoverseDataset(city=curr_city, split=\"train\")\n",
    "data_mean, data_std = train_dataset.get_mean_std()\n",
    "test_dataset = ArgoverseDataset(city=curr_city, split=\"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbacf98",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13a6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 256  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4e2ea",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d040b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1], c='r', s=20)\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1], c='b', s=20)\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 4: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852f474",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855d92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=256, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(256)\n",
    "        self.linear = nn.Linear(256, 128)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9639d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "609e6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Batch: 10/46, Loss: 0.09522546082735062\n",
      "Epoch: 1/200, Batch: 20/46, Loss: 0.02969931811094284\n",
      "Epoch: 1/200, Batch: 30/46, Loss: 0.02206568233668804\n",
      "Epoch: 1/200, Batch: 40/46, Loss: 0.02018623985350132\n",
      "Epoch: 1/200, Val Loss: 0.5344917625188828\n",
      "Epoch: 2/200, Batch: 10/46, Loss: 0.008664325810968876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i_batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.25, verbose=True)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, num_epochs, 1):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch: {epoch}/{num_epochs}, Val Loss: {val_loss}\")\n",
    "\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "torch.save(lstm.state_dict(), f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e9c24",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(2, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = (f\"models/{curr_city}_model.pt\")\n",
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load(f, map_location=device))\n",
    "lstm.to(device)\n",
    "lstm.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c1a47",
   "metadata": {},
   "source": [
    "## Validation Data Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_outputs = []\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, label = sample_batch\n",
    "    inp = inp.to(device)\n",
    "    output, h, c = lstm(inp.float())\n",
    "    validation_outputs.append((inp.cpu().numpy(), output.detach().cpu().numpy(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation results     \n",
    "data = validation_outputs[0]\n",
    "inp, output, label = data\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(inp[0,:,0], inp[0,:,1], c='r', label=\"Input\")\n",
    "plt.plot(label[0,:,0], label[0,:,1], c='b', label=\"Ground Truth\")\n",
    "plt.plot(output[0,:,0], output[0,:,1], c='g', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b363f4",
   "metadata": {},
   "source": [
    "## Sample Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e551d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, model, steps=60):\n",
    "    h = None\n",
    "    c = None\n",
    "    arr = []\n",
    "    for i in range(steps):\n",
    "        output, h, c = model(x, h, c)\n",
    "        # if i == 0:\n",
    "        #     print(x[0][40:-1], output[0][40:-1])\n",
    "        elem = output[:, -1, :]\n",
    "        x = elem.unsqueeze(1)\n",
    "        elem = elem.squeeze().detach().cpu().numpy()\n",
    "        arr.append(elem)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21917c88",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbb2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=6'>7</a>\u001b[0m inp \u001b[39m=\u001b[39m (inp \u001b[39m-\u001b[39m austin_mean) \u001b[39m/\u001b[39m austin_std\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=7'>8</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=8'>9</a>\u001b[0m output \u001b[39m=\u001b[39m sample(inp, lstm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000017?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39m austin_std \u001b[39m+\u001b[39m austin_mean     \n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 16'\u001b[0m in \u001b[0;36msample\u001b[1;34m(x, model, steps)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=3'>4</a>\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=5'>6</a>\u001b[0m     output, h, c \u001b[39m=\u001b[39m model(x, h, c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=6'>7</a>\u001b[0m     \u001b[39m# if i == 0:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=7'>8</a>\u001b[0m     \u001b[39m#     print(x[0][40:-1], output[0][40:-1])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000015?line=8'>9</a>\u001b[0m     elem \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m (h \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (c \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=16'>17</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m         x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\OneDrive\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/OneDrive/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = f\"{curr_city}_trajectory.csv\"\n",
    "\n",
    "with open(f, \"w\") as f:\n",
    "    for i, inp in enumerate(test_loader):\n",
    "        original_inp = inp\n",
    "        inp = (inp - data_mean) / data_std\n",
    "        inp = inp.to(device)\n",
    "        inp = inp.float()\n",
    "        output = sample(inp, lstm)\n",
    "\n",
    "        output = np.array(output)\n",
    "        output = output * data_std + data_mean     \n",
    "        output = output.squeeze()\n",
    "\n",
    "        f.write(f\"{i}_{curr_city}\")\n",
    "        for pos in output:\n",
    "            f.write(f\",{pos[0]},{pos[1]}\")\n",
    "        f.write(\"\\n\")\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(test_loader)}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87ba6bd9f893c5edd952261490a68d848fd18fab6461935b7e2aa5577e0f4319"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
