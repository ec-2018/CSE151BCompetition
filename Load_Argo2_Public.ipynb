{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    mean, std = None, None\n",
    "\n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        trajectories = np.concatenate((inputs, outputs), axis=1)\n",
    "        trajectories = trajectories.reshape(-1, trajectories.shape[1], trajectories.shape[2])\n",
    "        trajectories = trajectories.astype(np.float32)\n",
    "\n",
    "        if normalized:\n",
    "            mean = np.mean(trajectories, axis=0)\n",
    "            std = np.std(trajectories, axis=0)\n",
    "            trajectories = (trajectories - mean) / std\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for trajectory in trajectories:\n",
    "            for i in range(trajectory.shape[0] - 50):\n",
    "                inputs.append(trajectory[i:i+50])\n",
    "                outputs.append(trajectory[i+50])\n",
    "\n",
    "    inputs, outputs = np.asarray(inputs), np.asarray(outputs)\n",
    "    return inputs, outputs, mean, std\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "\n",
    "        self.inputs, self.outputs, self.mean, self.std = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "# intialize each dataset\n",
    "train_austin = ArgoverseDataset(city = \"austin\", split = \"train\")\n",
    "train_miami = ArgoverseDataset(city = \"miami\", split = \"train\")\n",
    "train_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"train\")\n",
    "train_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"train\")\n",
    "train_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"train\")\n",
    "train_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"train\")\n",
    "\n",
    "austin_mean, austin_std = train_austin.get_mean_std()[0][0]\n",
    "miami_mean, miami_std = train_miami.get_mean_std()[0][0]\n",
    "palo_alto_mean, palo_alto_std = train_palo_alto.get_mean_std()[0][0]\n",
    "pittsburgh_mean, pittsburgh_std = train_pittsburgh.get_mean_std()[0][0]\n",
    "dearborn_mean, dearborn_std = train_dearborn.get_mean_std()[0][0]\n",
    "washington_dc_mean, washington_dc_std = train_washington_dc.get_mean_std()[0][0]\n",
    "\n",
    "test_austin = ArgoverseDataset(city = \"austin\", split = \"test\")\n",
    "test_miami = ArgoverseDataset(city = \"miami\", split = \"test\")\n",
    "test_palo_alto = ArgoverseDataset(city = \"palo-alto\", split = \"test\")\n",
    "test_pittsburgh = ArgoverseDataset(city = \"pittsburgh\", split = \"test\")\n",
    "test_dearborn = ArgoverseDataset(city = \"dearborn\", split = \"test\")\n",
    "test_washington_dc = ArgoverseDataset(city = \"washington-dc\", split = \"test\")\n",
    "\n",
    "# Train Validation Split\n",
    "train_austin, val_austin = torch.utils.data.random_split(train_austin, [len(train_austin) - len(train_austin)//5, len(train_austin)//5])\n",
    "train_miami, val_miami = torch.utils.data.random_split(train_miami, [len(train_miami) - len(train_miami)//5, len(train_miami)//5])\n",
    "train_palo_alto, val_palo_alto = torch.utils.data.random_split(train_palo_alto, [len(train_palo_alto) - len(train_palo_alto)//5, len(train_palo_alto)//5])\n",
    "train_pittsburgh, val_pittsburgh = torch.utils.data.random_split(train_pittsburgh, [len(train_pittsburgh) - len(train_pittsburgh)//5, len(train_pittsburgh)//5])\n",
    "train_dearborn, val_dearborn = torch.utils.data.random_split(train_dearborn, [len(train_dearborn) - len(train_dearborn)//5, len(train_dearborn)//5])\n",
    "train_washington_dc, val_washington_dc = torch.utils.data.random_split(train_washington_dc, [len(train_washington_dc) - len(train_washington_dc)//5, len(train_washington_dc)//5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 10  # batch size \n",
    "train_loader = DataLoader(train_palo_alto,batch_size=batch_sz,shuffle=True)\n",
    "val_loader = DataLoader(val_palo_alto,batch_size=batch_sz,shuffle=True)\n",
    "test_loader = DataLoader(test_palo_alto,batch_size=batch_sz,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,0], out[i,1], c='r')\n",
    "    \n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    if i_batch != 50: continue\n",
    "    inputs, outputs = sample_batch\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a53b5",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c6a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=512, num_layers=3, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(512, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(256, 2)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if (h is not None) and (c is not None):\n",
    "            x, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, h, c\n",
    "\n",
    "    def predict(self, x, h=None, c=None):\n",
    "        output, h, c = self.forward(x, h, c)\n",
    "        output = output[-1]\n",
    "        output = output.cpu().detach().numpy()\n",
    "            \n",
    "        return output, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf38ed7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e605e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5, Batch: 0/57567, Loss: 0.5454278588294983\n",
      "Epoch: 0/5, Batch: 10/57567, Loss: 0.13322672247886658\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=11'>12</a>\u001b[0m inp, label \u001b[39m=\u001b[39m sample_batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=13'>14</a>\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=14'>15</a>\u001b[0m output, h, c \u001b[39m=\u001b[39m lstm(inp\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000011?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\Load_Argo2_Public.ipynb Cell 10'\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, h, c)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=17'>18</a>\u001b[0m     x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x, (h, c))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=18'>19</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=19'>20</a>\u001b[0m     x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=20'>21</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ec201/Desktop/CSE151BCompetition/Load_Argo2_Public.ipynb#ch0000009?line=21'>22</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ec201\\Desktop\\CSE151BCompetition\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=758'>759</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=759'>760</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=760'>761</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=761'>762</a>\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=762'>763</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=763'>764</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    <a href='file:///c%3A/Users/ec201/Desktop/CSE151BCompetition/env/lib/site-packages/torch/nn/modules/rnn.py?line=764'>765</a>\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm = LSTM()\n",
    "lstm.to(device)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train(True)\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, label = sample_batch\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        output, h, c = lstm(inp.float())\n",
    "\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 10000 == 0 and i_batch != 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    lstm.train(False)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(val_loader):\n",
    "            inp, label = sample_batch\n",
    "            inp = inp.to(device)\n",
    "            output, h, c = lstm(inp.float())\n",
    "            output = output[:, -1, :]\n",
    "            loss = loss_fn(output, label)\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Batch: {i_batch}/{len(val_loader)}, Loss: {loss.item()}\")\n",
    "            break\n",
    "\n",
    "torch.save(lstm.state_dict(), \"lstm_model.pt\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfaea13b2c70b10e61fc5114159871c988fdb8a8d57529e1e6239db333764196"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
